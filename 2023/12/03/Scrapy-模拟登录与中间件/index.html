<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Scrapy_模拟登录与中间件 | 山城冰荔枝</title>
  <meta name="description" content="模拟登录与中间件一. Scrapy处理cookie​		在requests中我们讲解处理cookie主要有两个方案. 第一个方案. 从浏览器里直接把cookie搞出来. 贴到heades里. 这种方案, 简单粗暴. 第二个方案是走正常的登录流程. 通过session来记录请求过程中的cookie. 那么到了scrapy中如何处理cookie?  其实也是这两个方案.  ​		首先, 我们依然是把目">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy_模拟登录与中间件">
<meta property="og:url" content="http://blog.ioimp.top/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/index.html">
<meta property="og:site_name" content="山城冰荔枝">
<meta property="og:description" content="模拟登录与中间件一. Scrapy处理cookie​		在requests中我们讲解处理cookie主要有两个方案. 第一个方案. 从浏览器里直接把cookie搞出来. 贴到heades里. 这种方案, 简单粗暴. 第二个方案是走正常的登录流程. 通过session来记录请求过程中的cookie. 那么到了scrapy中如何处理cookie?  其实也是这两个方案.  ​		首先, 我们依然是把目">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.ioimp.top/images/scrapy01/image-20210805180841148.png">
<meta property="article:published_time" content="2023-12-03T03:57:12.000Z">
<meta property="article:modified_time" content="2023-12-03T03:58:19.284Z">
<meta property="article:author" content="山城冰荔枝">
<meta property="article:tag" content="Scrapy爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.ioimp.top/images/scrapy01/image-20210805180841148.png">
  <!-- Canonical links -->
  <link rel="canonical" href="http://blog.ioimp.top/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/index.html">
  
    <link rel="alternate" href="/atom.xml" title="山城冰荔枝" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 6.3.0"></head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/SFYYH" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">山城冰荔枝</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Web Developer &amp; Designer</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> BeiJing, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">友链</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/SFYYH" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>跑起来会有风!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Java%E5%AD%A6%E4%B9%A0/">Java学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Jenkins/">Jenkins</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/K8s/">K8s</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ubuntu/">Ubuntu</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/proxy/">proxy</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/">实用技巧</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%80%E5%8F%91%E5%A5%87%E9%81%87%E8%AE%B0/">开发奇遇记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E6%9D%82%E7%83%A9/">数据杂烩</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E7%B1%BB%E5%AD%A6%E4%B9%A0/">杂类学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/">爬虫开发</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%96%91%E9%9A%BE%E8%A7%A3%E7%AD%94/">疑难解答</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/">网站搭建</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/">网络安全</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-body">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Boilerpipe/" rel="tag">Boilerpipe</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/" rel="tag">Docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ES6/" rel="tag">ES6</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GitHub/" rel="tag">GitHub</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grafana/" rel="tag">Grafana</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/" rel="tag">JavaScript</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java%E5%AD%A6%E4%B9%A0/" rel="tag">Java学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jenkins/" rel="tag">Jenkins</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jenkins%E5%AD%A6%E4%B9%A0/" rel="tag">Jenkins学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K8s%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/" rel="tag">K8s基础学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux%E5%AD%A6%E4%B9%A0/" rel="tag">Linux学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Node-js/" rel="tag">Node.js</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Rancher/" rel="tag">Rancher</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scrapy%E7%88%AC%E8%99%AB/" rel="tag">Scrapy爬虫</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Stack-Overflow/" rel="tag">Stack Overflow</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vue%E5%9F%BA%E7%A1%80/" rel="tag">Vue基础</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WebPack/" rel="tag">WebPack</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cAdvisor/" rel="tag">cAdvisor</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/clash/" rel="tag">clash</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dolphinscheduler/" rel="tag">dolphinscheduler</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/influxDB/" rel="tag">influxDB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kali-linux/" rel="tag">kali-linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/url%E5%9C%B0%E5%9D%80%E5%8F%98%E8%BF%81/" rel="tag">url地址变迁</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E2%80%9C%E7%9F%A5%E8%AF%86%E5%BA%93%E5%A4%87%E4%BB%BD/" rel="tag">“知识库备份&quot;</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/" rel="tag">前端学习</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/" rel="tag">博客搭建教程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0/" rel="tag">大数据分析平台</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF/" rel="tag">宝塔面板</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9C/" rel="tag">异步操作</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" rel="tag">微服务</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8B%AF%E6%95%91%E5%B0%8F%E7%99%BD%E7%B3%BB%E5%88%97/" rel="tag">拯救小白系列</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E7%AB%A0%E6%94%B6%E5%BD%95/" rel="tag">文章收录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%B8%B8%E5%B0%8FBUG/" rel="tag">日常小BUG</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%97%E9%80%8F%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/" rel="tag">渗透必知必会</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB%E6%95%B0%E6%8D%AE/" rel="tag">爬虫数据</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/" rel="tag">磁盘分区</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%81%E5%9F%9F/" rel="tag">私域</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B%E7%9F%A5%E8%AF%86/" rel="tag">编程知识</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E5%AE%89/" rel="tag">网安</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E8%AF%BE/" rel="tag">网课</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Boilerpipe/" style="font-size: 13px;">Boilerpipe</a> <a href="/tags/Docker/" style="font-size: 13px;">Docker</a> <a href="/tags/ES6/" style="font-size: 14px;">ES6</a> <a href="/tags/GitHub/" style="font-size: 13.14px;">GitHub</a> <a href="/tags/Grafana/" style="font-size: 13px;">Grafana</a> <a href="/tags/JavaScript/" style="font-size: 13px;">JavaScript</a> <a href="/tags/Java%E5%AD%A6%E4%B9%A0/" style="font-size: 13px;">Java学习</a> <a href="/tags/Jenkins/" style="font-size: 13px;">Jenkins</a> <a href="/tags/Jenkins%E5%AD%A6%E4%B9%A0/" style="font-size: 13px;">Jenkins学习</a> <a href="/tags/K8s%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/" style="font-size: 13px;">K8s基础学习</a> <a href="/tags/Linux%E5%AD%A6%E4%B9%A0/" style="font-size: 13px;">Linux学习</a> <a href="/tags/Node-js/" style="font-size: 13.86px;">Node.js</a> <a href="/tags/Rancher/" style="font-size: 13px;">Rancher</a> <a href="/tags/Scrapy%E7%88%AC%E8%99%AB/" style="font-size: 13.71px;">Scrapy爬虫</a> <a href="/tags/Stack-Overflow/" style="font-size: 13px;">Stack Overflow</a> <a href="/tags/Vue%E5%9F%BA%E7%A1%80/" style="font-size: 13.57px;">Vue基础</a> <a href="/tags/WebPack/" style="font-size: 13.29px;">WebPack</a> <a href="/tags/cAdvisor/" style="font-size: 13px;">cAdvisor</a> <a href="/tags/clash/" style="font-size: 13px;">clash</a> <a href="/tags/dolphinscheduler/" style="font-size: 13.14px;">dolphinscheduler</a> <a href="/tags/influxDB/" style="font-size: 13px;">influxDB</a> <a href="/tags/kali-linux/" style="font-size: 13px;">kali-linux</a> <a href="/tags/url%E5%9C%B0%E5%9D%80%E5%8F%98%E8%BF%81/" style="font-size: 13px;">url地址变迁</a> <a href="/tags/%E2%80%9C%E7%9F%A5%E8%AF%86%E5%BA%93%E5%A4%87%E4%BB%BD/" style="font-size: 13px;">“知识库备份"</a> <a href="/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/" style="font-size: 14px;">前端学习</a> <a href="/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/" style="font-size: 13px;">博客搭建教程</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0/" style="font-size: 13.14px;">大数据分析平台</a> <a href="/tags/%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF/" style="font-size: 13px;">宝塔面板</a> <a href="/tags/%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9C/" style="font-size: 13.14px;">异步操作</a> <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" style="font-size: 13px;">微服务</a> <a href="/tags/%E6%8B%AF%E6%95%91%E5%B0%8F%E7%99%BD%E7%B3%BB%E5%88%97/" style="font-size: 13.14px;">拯救小白系列</a> <a href="/tags/%E6%96%87%E7%AB%A0%E6%94%B6%E5%BD%95/" style="font-size: 13.14px;">文章收录</a> <a href="/tags/%E6%97%A5%E5%B8%B8%E5%B0%8FBUG/" style="font-size: 13.14px;">日常小BUG</a> <a href="/tags/%E6%B8%97%E9%80%8F%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/" style="font-size: 13px;">渗透必知必会</a> <a href="/tags/%E7%88%AC%E8%99%AB%E6%95%B0%E6%8D%AE/" style="font-size: 13px;">爬虫数据</a> <a href="/tags/%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/" style="font-size: 13px;">磁盘分区</a> <a href="/tags/%E7%A7%81%E5%9F%9F/" style="font-size: 13px;">私域</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E7%9F%A5%E8%AF%86/" style="font-size: 13px;">编程知识</a> <a href="/tags/%E7%BD%91%E5%AE%89/" style="font-size: 13.43px;">网安</a> <a href="/tags/%E7%BD%91%E8%AF%BE/" style="font-size: 13px;">网课</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">十一月 2023</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">十二月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a>
              </p>
              <p class="item-title">
                <a href="/2023/12/23/Vue%E4%B8%ADjs%E5%BC%95%E5%85%A5%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%B9%E6%B3%95/" class="title">Vue中js引入图片的方法</a>
              </p>
              <p class="item-date">
                <time datetime="2023-12-23T07:13:23.000Z" itemprop="datePublished">2023-12-23</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a>
              </p>
              <p class="item-title">
                <a href="/2023/12/23/Vue%E4%B8%ADv-model%E5%AF%B9%E5%BA%94%E4%B8%8D%E5%90%8C%E7%9A%84%E8%A1%A8%E5%8D%95%E6%A0%87%E7%AD%BE%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/" class="title">Vue中v-model对应不同的表单标签的处理方式</a>
              </p>
              <p class="item-date">
                <time datetime="2023-12-23T03:15:27.000Z" itemprop="datePublished">2023-12-23</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a>
              </p>
              <p class="item-title">
                <a href="/2023/12/23/JS%E4%B8%AD%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%8B%E4%BB%B6%E5%86%92%E6%B3%A1/" class="title">JS中什么是事件冒泡</a>
              </p>
              <p class="item-date">
                <time datetime="2023-12-22T16:33:50.000Z" itemprop="datePublished">2023-12-23</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a>
              </p>
              <p class="item-title">
                <a href="/2023/12/23/MVVM%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" class="title">MVVM设计模式</a>
              </p>
              <p class="item-date">
                <time datetime="2023-12-22T16:19:02.000Z" itemprop="datePublished">2023-12-23</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a>
              </p>
              <p class="item-title">
                <a href="/2023/12/22/Vue%E4%B8%AD-main-js-APP-vue%E5%92%8C-index-html-%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E5%85%B3%E7%B3%BB/" class="title">Vue中 main.js, APP.vue和 index.html 的作用和关系</a>
              </p>
              <p class="item-date">
                <time datetime="2023-12-22T15:47:51.000Z" itemprop="datePublished">2023-12-22</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-Scrapy-模拟登录与中间件" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      Scrapy_模拟登录与中间件
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" class="article-date">
	  <time datetime="2023-12-03T03:57:12.000Z" itemprop="datePublished">2023-12-03</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/">爬虫开发</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/Scrapy%E7%88%AC%E8%99%AB/" rel="tag">Scrapy爬虫</a>
  </span>


        
	<span class="article-read hidden-xs">
	    <i class="icon icon-eye-fill" aria-hidden="true"></i>
	    <span id="busuanzi_container_page_pv">
			<span id="busuanzi_value_page_pv">0</span>
		</span>
	</span>


        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/#comments" class="article-comment-link">评论</a></span>
        
	
		<span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 3.7k(字)</span>
	
	
		<span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 18(分)</span>
	

      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h1 id="模拟登录与中间件"><a href="#模拟登录与中间件" class="headerlink" title="模拟登录与中间件"></a>模拟登录与中间件</h1><h2 id="一-Scrapy处理cookie"><a href="#一-Scrapy处理cookie" class="headerlink" title="一. Scrapy处理cookie"></a>一. Scrapy处理cookie</h2><p>​		在requests中我们讲解处理cookie主要有两个方案. 第一个方案. 从浏览器里直接把cookie搞出来. 贴到heades里. 这种方案, 简单粗暴. 第二个方案是走正常的登录流程. 通过session来记录请求过程中的cookie. 那么到了scrapy中如何处理cookie?  其实也是这两个方案. </p>
<p>​		首先, 我们依然是把目标定好,  还是我们的老朋友, <a target="_blank" rel="noopener" href="https://user.17k.com/ck/author/shelf?page=1&appKey=2406394919">https://user.17k.com/ck/author/shelf?page=1&amp;appKey=2406394919</a></p>
<p>​		这个url必须要登录后才能访问(用户书架). &#x3D;&#x3D;对于该网页而言&#x3D;&#x3D;, 就必须要用到cookie了. 首先, 创建项目, 建立爬虫. 把该填的地方填上. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request, FormRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LoginSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;login&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;17k.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://user.17k.com/ck/author/shelf?page=1&amp;appKey=2406394919&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​		此时运行时, 显示的是该用户还未登录. 不论是哪个方案. 在请求到start_urls里面的url之前必须得获取到cookie. 但是默认情况下, scrapy会自动的帮我们完成其实request的创建. 此时, 我们需要自己去组装第一个请求. 这时就需要我们自己的爬虫中重写start_requests()方法. 该方法负责起始request的组装工作. 我们不妨先看看原来的start_requests()是如何工作的. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下是scrapy源码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">    cls = self.__class__</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.start_urls <span class="keyword">and</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;start_url&#x27;</span>):</span><br><span class="line">        <span class="keyword">raise</span> AttributeError(</span><br><span class="line">            <span class="string">&quot;Crawling could not start: &#x27;start_urls&#x27; not found &quot;</span></span><br><span class="line">            <span class="string">&quot;or empty (but found &#x27;start_url&#x27; attribute instead, &quot;</span></span><br><span class="line">            <span class="string">&quot;did you miss an &#x27;s&#x27;?)&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> method_is_overridden(cls, Spider, <span class="string">&#x27;make_requests_from_url&#x27;</span>):</span><br><span class="line">        warnings.warn(</span><br><span class="line">            <span class="string">&quot;Spider.make_requests_from_url method is deprecated; it &quot;</span></span><br><span class="line">            <span class="string">&quot;won&#x27;t be called in future Scrapy releases. Please &quot;</span></span><br><span class="line">            <span class="string">&quot;override Spider.start_requests method instead (see %s.%s).&quot;</span> % (</span><br><span class="line">                cls.__module__, cls.__name__</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">            <span class="keyword">yield</span> self.make_requests_from_url(url)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">            <span class="comment"># 核心就这么一句话. 组建一个Request对象.我们也可以这么干. </span></span><br><span class="line">            <span class="keyword">yield</span> Request(url, dont_filter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>自己写个start_requests()看看. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;我是万恶之源&quot;</span>)</span><br><span class="line">    <span class="keyword">yield</span> Request(</span><br><span class="line">        url=LoginSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">        callback=self.parse</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>



<p>接下来, 我们去处理cookie</p>
<h3 id="1-方案一-直接从浏览器复制cookie过来"><a href="#1-方案一-直接从浏览器复制cookie过来" class="headerlink" title="1. 方案一, 直接从浏览器复制cookie过来"></a>1. 方案一, 直接从浏览器复制cookie过来</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 直接从浏览器复制</span></span><br><span class="line">        cookies = <span class="string">&quot;GUID=bbb5f65a-2fa2-40a0-ac87-49840eae4ad1; c_channel=0; c_csc=web; Hm_lvt_9793f42b498361373512340937deb2a0=1627572532,1627711457,1627898858,1628144975; accessToken=avatarUrl%3Dhttps%253A%252F%252Fcdn.static.17k.com%252Fuser%252Favatar%252F16%252F16%252F64%252F75836416.jpg-88x88%253Fv%253D1610625030000%26id%3D75836416%26nickname%3D%25E5%25AD%25A4%25E9%25AD%2582%25E9%2587%258E%25E9%25AC%25BCsb%26e%3D1643697376%26s%3D73f8877e452e744c; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2275836416%22%2C%22%24device_id%22%3A%2217700ba9c71257-035a42ce449776-326d7006-2073600-17700ba9c728de%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_referrer%22%3A%22%22%2C%22%24latest_referrer_host%22%3A%22%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%7D%2C%22first_id%22%3A%22bbb5f65a-2fa2-40a0-ac87-49840eae4ad1%22%7D; Hm_lpvt_9793f42b498361373512340937deb2a0=1628145672&quot;</span></span><br><span class="line">        cookie_dic = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> cookies.split(<span class="string">&quot;; &quot;</span>):</span><br><span class="line">            k, v = c.split(<span class="string">&quot;=&quot;</span>)</span><br><span class="line">            cookie_dic[k] = v</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> Request(</span><br><span class="line">            url=LoginSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">            cookies=cookie_dic,</span><br><span class="line">            callback=self.parse</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<p>这种方案和原来的requests几乎一模一样.  需要注意的是: cookie需要通过cookies参数进行传递!</p>
<h3 id="2-方案二-完成登录过程"><a href="#2-方案二-完成登录过程" class="headerlink" title="2. 方案二, 完成登录过程."></a>2. 方案二, 完成登录过程.</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 登录流程</span></span><br><span class="line">    username = <span class="string">&quot;18614075987&quot;</span></span><br><span class="line">    password = <span class="string">&quot;q6035945&quot;</span></span><br><span class="line">    url = <span class="string">&quot;https://passport.17k.com/ck/user/login&quot;</span></span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 发送post请求</span></span><br><span class="line">    <span class="comment"># yield Request(</span></span><br><span class="line">    <span class="comment">#     url=url,</span></span><br><span class="line">    <span class="comment">#     method=&quot;post&quot;,</span></span><br><span class="line">    <span class="comment">#     body=&quot;loginName=18614075987&amp;password=q6035945&quot;,</span></span><br><span class="line">    <span class="comment">#     callback=self.parse</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 发送post请求</span></span><br><span class="line">    <span class="keyword">yield</span> FormRequest(</span><br><span class="line">        url=url,</span><br><span class="line">        formdata=&#123;</span><br><span class="line">            <span class="string">&quot;loginName&quot;</span>: username,</span><br><span class="line">            <span class="string">&quot;password&quot;</span>: password</span><br><span class="line">        &#125;,</span><br><span class="line">        callback=self.parse</span><br><span class="line">    )</span><br><span class="line">	</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">    <span class="comment"># 得到响应结果. 直接请求到默认的start_urls</span></span><br><span class="line">    <span class="keyword">yield</span> Request(</span><br><span class="line">        url=LoginSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">        callback=self.parse_detail</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self, resp</span>):</span><br><span class="line">    <span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>

<p>​	注意, 发送post请求有两个方案, </p>
<ol>
<li><p>Scrapy.Request(url&#x3D;url, method&#x3D;’post’, body&#x3D;数据)</p>
</li>
<li><p>Scarpy.FormRequest(url&#x3D;url, formdata&#x3D;数据)  -&gt; 推荐</p>
<p>区别: 方式1的数据只能是字符串. 这个就很难受. 所以推荐用第二种.</p>
</li>
</ol>
<h2 id="二-Scrapy的中间件"><a href="#二-Scrapy的中间件" class="headerlink" title="二. Scrapy的中间件"></a>二. Scrapy的中间件</h2><p>​		中间件的作用: 负责处理引擎和爬虫以及引擎和下载器之间的请求和响应. 主要是可以对request和response做预处理. 为后面的操作做好充足的准备工作. 在python中准备了两种中间件, 分别是下载器中间件和爬虫中间件. </p>
<h3 id="1-DownloaderMiddleware"><a href="#1-DownloaderMiddleware" class="headerlink" title="1. DownloaderMiddleware"></a>1. DownloaderMiddleware</h3><p>​	下载中间件, 它是介于引擎和下载器之间,  引擎在获取到request对象后, 会交给下载器去下载, 在这之间我们可以设置下载中间件. 它的执行流程:</p>
<p>​	引擎拿到request -&gt; 中间件1(process_request) -&gt; 中间件2(process_request) …..-&gt;      下载器-|<br>​    引擎拿到request &lt;- 中间件1(process_response) &lt;- 中间件2(process_response) ….. &lt;-下载器-|</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MidDownloaderMiddleware1</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_request&quot;</span>, <span class="string">&quot;ware1&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_response&quot;</span>, <span class="string">&quot;ware1&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_exception&quot;</span>, <span class="string">&quot;ware1&quot;</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MidDownloaderMiddleware2</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_request&quot;</span>, <span class="string">&quot;ware2&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_response&quot;</span>, <span class="string">&quot;ware2&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_exception&quot;</span>, <span class="string">&quot;ware2&quot;</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>设置中间件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="comment"># &#x27;mid.middlewares.MidDownloaderMiddleware&#x27;: 542,</span></span><br><span class="line">   <span class="string">&#x27;mid.middlewares.MidDownloaderMiddleware1&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">   <span class="string">&#x27;mid.middlewares.MidDownloaderMiddleware2&#x27;</span>: <span class="number">544</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>优先级参考管道. </p>
<p>运行效果;</p>
<p><img src="/images/scrapy01/image-20210805180841148.png" alt="images/scrapy01/image-20210805180841148"></p>
<p>接下来, 我们来说说这几个方法的返回值问题(难点)</p>
<ol>
<li><p>process_request(request, spider):  在每个请求到达下载器之前调用</p>
<p>一, return None  不拦截, 把请求继续向后传递给权重低的中间件或者下载器</p>
<p>二, return request 请求被拦截, 并将一个新的请求返回. 后续中间件以及下载器收不到本次请求</p>
<p>三, return response 请求被拦截, 下载器将获取不到请求, 但是引擎是可以接收到本次响应的内容, 也就是说在当前方法内就已经把响应内容获取到了. </p>
</li>
<li><p>proccess_response(request, response, spider): 每个请求从下载器出来调用</p>
<p>一, return response 通过引擎将响应内容继续传递给其他组件或传递给其他process_response()处理</p>
<p>二, return request  响应被拦截. 将返回内容直接回馈给调度器(通过引擎), 后续process_response()接收不到响应内容.</p>
</li>
</ol>
<p>OK, 至此, 中间件的含义算是完事儿了. 那这东西有啥用?  我们上案例!</p>
<h4 id="1-1-动态随机设置UA"><a href="#1-1-动态随机设置UA" class="headerlink" title="1.1. 动态随机设置UA"></a>1.1. 动态随机设置UA</h4><p>设置统一的UA很简单. 直接在settings里设置即可. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT = <span class="string">&#x27;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure>

<p>但是这个不够好, 我希望得到一个随机的UA.  此时就可以这样设计, 首先, 在settings里定义好一堆UserAgent.  <a target="_blank" rel="noopener" href="http://useragentstring.com/pages/useragentstring.php?name=Chrome">http://useragentstring.com/pages/useragentstring.php?name=Chrome</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT_LIST = [</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2919.83 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2866.71 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (X11; Ubuntu; Linux i686 on x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2820.59 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2762.73 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2656.18 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/44.0.2403.155 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2226.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.4; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.124 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 4.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​	中间件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyRandomUserAgentMiddleware</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        UA = choice(USER_AGENT_LIST)</span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = UA</span><br><span class="line">        <span class="comment"># 不要返回任何东西</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>



<h4 id="1-2-处理代理问题"><a href="#1-2-处理代理问题" class="headerlink" title="1.2 处理代理问题"></a>1.2 处理代理问题</h4><p>代理问题一直是我们作为一名爬虫工程师很蛋疼的问题. 不加容易被检测, 加了效率低, 免费的可用IP更是凤毛麟角. 没办法, 无论如何还是得面对它. 这里, 我们采用两个方案来给各位展示scrapy中添加代理的逻辑.</p>
<ol>
<li><p>免费代理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ProxyMiddleware</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;又来&quot;</span>)</span><br><span class="line">        proxy = choice(PROXY_LIST)</span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&quot;https://&quot;</span>+proxy  <span class="comment"># 设置代理</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;有么有结果???&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> response.status != <span class="number">200</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;尝试失败&quot;</span>)</span><br><span class="line">            request.dont_filter = <span class="literal">True</span>  <span class="comment"># 丢回调度器重新请求</span></span><br><span class="line">            <span class="keyword">return</span> request</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;出错了!&quot;</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>收费代理</p>
<p>免费代理实在太难用了. 我们这里直接选择一个收费代理. 依然选择<code>快代理</code>, 这个根据你自己的喜好进行调整. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MoneyProxyMiddleware</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_proxy</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        912831993520336	t12831993520578	每次请求换IP</span></span><br><span class="line"><span class="string">        tps138.kdlapi.com 15818</span></span><br><span class="line"><span class="string">        需实名认证	5次/s	5Mb/s	有效	续费|订单详情|实名认证</span></span><br><span class="line"><span class="string">        隧道用户名密码修改密码</span></span><br><span class="line"><span class="string">        用户名：t12831993520578密码：t72a13xu</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        url = <span class="string">&quot;http://tps138.kdlapi.com:15818&quot;</span></span><br><span class="line">        auth = basic_auth_header(username=<span class="string">&quot;t12831993520578&quot;</span>, password=<span class="string">&quot;t72a13xu&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> url, auth</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;......&quot;</span>)</span><br><span class="line">        url, auth = self._get_proxy()</span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = url</span><br><span class="line">        request.headers[<span class="string">&#x27;Proxy-Authorization&#x27;</span>] = auth</span><br><span class="line">        request.headers[<span class="string">&#x27;Connection&#x27;</span>] = <span class="string">&#x27;close&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(response.status, <span class="built_in">type</span>(response.status))</span><br><span class="line">        <span class="keyword">if</span> response.status != <span class="number">200</span>:</span><br><span class="line">            request.dont_filter = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">return</span> request</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="1-3-使用selenium完成数据抓取"><a href="#1-3-使用selenium完成数据抓取" class="headerlink" title="1.3 使用selenium完成数据抓取"></a>1.3 使用selenium完成数据抓取</h4><p>首先, 我们需要使用selenium作为下载器进行下载. 那么我们的请求应该也是特殊订制的. 所以, 在我的设计里, 我可以重新设计一个请求. 就叫SeleniumRequest</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.http.request <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SeleniumRequest</span>(<span class="title class_ inherited__">Request</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这里面不需要做任何操作. 整体还是用它父类的东西来进行操作. </p>
<p>接下来. 完善一下spider</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> boss.request <span class="keyword">import</span> SeleniumRequest</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BeijingSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;beijing&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;zhipin.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.zhipin.com/job_detail/?query=python&amp;city=101010100&amp;industry=&amp;position=&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">yield</span> SeleniumRequest(</span><br><span class="line">            url=BeijingSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">            callback=self.parse,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        li_list = resp.xpath(<span class="string">&#x27;//*[@id=&quot;main&quot;]/div/div[3]/ul/li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            href = li.xpath(<span class="string">&quot;./div[1]/div[1]/div[1]/div[1]/div[1]/span[1]/a[1]/@href&quot;</span>).extract_first()</span><br><span class="line">            name = li.xpath(<span class="string">&quot;./div[1]/div[1]/div[1]/div[1]/div[1]/span[1]/a[1]/text()&quot;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(name, href)</span><br><span class="line">            <span class="built_in">print</span>(resp.urljoin(href))</span><br><span class="line">            <span class="keyword">yield</span> SeleniumRequest(</span><br><span class="line">                url=resp.urljoin(href),</span><br><span class="line">                callback=self.parse_detail,</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 下一页.....</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;招聘人&quot;</span>, resp.xpath(<span class="string">&#x27;//*[@id=&quot;main&quot;]/div[3]/div/div[2]/div[1]/h2&#x27;</span>).extract())</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>中间件~</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BossDownloaderMiddleware</span>:</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        <span class="comment"># 这里很关键哦. </span></span><br><span class="line">        <span class="comment"># 在爬虫开始的时候. 执行spider_opened</span></span><br><span class="line">        <span class="comment"># 在爬虫结束的时候. 执行spider_closed</span></span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        crawler.signals.connect(s.spider_closed, signal=signals.spider_closed)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(request, SeleniumRequest):</span><br><span class="line">            self.web.get(request.url)</span><br><span class="line">            time.sleep(<span class="number">3</span>)</span><br><span class="line">            page_source = self.web.page_source</span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=request.url, encoding=<span class="string">&#x27;utf-8&#x27;</span>, request=request, body=page_source)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.web = Chrome()</span><br><span class="line">        self.web.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># 完成登录. 拿到cookie. 很容易...</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;创建浏览器&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_closed</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.web.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;关闭浏览器&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>settings</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="comment"># 怼在所有默认中间件前面. 只要是selenium后面所有的中间件都给我停</span></span><br><span class="line">   <span class="string">&#x27;boss.middlewares.BossDownloaderMiddleware&#x27;</span>: <span class="number">99</span>,  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="1-4-用selenium设置cookie"><a href="#1-4-用selenium设置cookie" class="headerlink" title="1.4 用selenium设置cookie"></a>1.4 用selenium设置cookie</h4><p>有了这个案例. 想要用selenium处理cookie也很容易了. 直接在spider_opened位置完成登录, 然后在process_request()中简单设置一下即可. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChaojiyingDownloaderMiddleware</span>:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request.cookies:</span><br><span class="line">            request.cookies = self.cookie</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        web = Chrome()</span><br><span class="line">        web.get(<span class="string">&quot;https://www.chaojiying.com/user/login/&quot;</span>)</span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[1]/input&#x27;</span>).send_keys(<span class="string">&quot;18614075987&quot;</span>)</span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[2]/input&#x27;</span>).send_keys(<span class="string">&#x27;q6035945&#x27;</span>)</span><br><span class="line">        img = web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/div/img&#x27;</span>)</span><br><span class="line">        verify_code = self.base64_api(<span class="string">&quot;q6035945&quot;</span>, <span class="string">&quot;q6035945&quot;</span>, img.screenshot_as_base64, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[3]/input&#x27;</span>).send_keys(verify_code)</span><br><span class="line"></span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[4]/input&#x27;</span>).click()</span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line">        cookies = web.get_cookies()</span><br><span class="line">        self.cookie = &#123;dic[<span class="string">&#x27;name&#x27;</span>]:dic[<span class="string">&#x27;value&#x27;</span>] <span class="keyword">for</span> dic <span class="keyword">in</span> cookies&#125;</span><br><span class="line">        web.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">base64_api</span>(<span class="params">self, uname, pwd, b64_img, typeid</span>):</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;username&quot;</span>: uname,</span><br><span class="line">            <span class="string">&quot;password&quot;</span>: pwd,</span><br><span class="line">            <span class="string">&quot;typeid&quot;</span>: typeid,</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: b64_img</span><br><span class="line">        &#125;</span><br><span class="line">        result = json.loads(requests.post(<span class="string">&quot;http://api.ttshitu.com/predict&quot;</span>, json=data).text)</span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">&#x27;success&#x27;</span>]:</span><br><span class="line">            <span class="keyword">return</span> result[<span class="string">&quot;data&quot;</span>][<span class="string">&quot;result&quot;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> result[<span class="string">&quot;message&quot;</span>]</span><br></pre></td></tr></table></figure>



<h3 id="2-SpiderMiddleware-了解"><a href="#2-SpiderMiddleware-了解" class="headerlink" title="2. SpiderMiddleware(了解)"></a>2. SpiderMiddleware(了解)</h3><p>​	爬虫中间件. 是处于引擎和spider之间的中间件. 里面常用的方法有:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CuowuSpiderMiddleware</span>:</span><br><span class="line">    <span class="comment"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class="line">    <span class="comment"># scrapy acts as if the spider middleware does not modify the</span></span><br><span class="line">    <span class="comment"># passed objects.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_input</span>(<span class="params">self, response, spider</span>):</span><br><span class="line">        <span class="comment"># 请求被返回, 即将进入到spider时调用</span></span><br><span class="line">        <span class="comment"># 要么返回None, 要么报错</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我是process_spider_input&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_output</span>(<span class="params">self, response, result, spider</span>):</span><br><span class="line">        <span class="comment"># 处理完spider中的数据. 返回数据后. 执行</span></span><br><span class="line">        <span class="comment"># 返回值要么是item, 要么是request.</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我是process_spider_output&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            <span class="keyword">yield</span> i</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我是process_spider_output&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_exception</span>(<span class="params">self, response, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_spider_exception&quot;</span>)</span><br><span class="line">        <span class="comment"># spider中报错 或者, process_spider_input() 方法报错</span></span><br><span class="line">        <span class="comment"># 返回None或者Request或者item.</span></span><br><span class="line">        it = ErrorItem()</span><br><span class="line">        it[<span class="string">&#x27;name&#x27;</span>] = <span class="string">&quot;exception&quot;</span></span><br><span class="line">        it[<span class="string">&#x27;url&#x27;</span>] = response.url</span><br><span class="line">        <span class="keyword">yield</span> it</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_start_requests</span>(<span class="params">self, start_requests, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_start_requests&quot;</span>)</span><br><span class="line">        <span class="comment"># 第一次启动爬虫时被调用.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must return only requests (not items).</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> start_requests:</span><br><span class="line">            <span class="keyword">yield</span> r</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>items</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ErrorItem</span>(scrapy.Item):</span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br></pre></td></tr></table></figure>

<p>spider:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaocuoSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;baocuo&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;baidu.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.baidu.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        name = resp.xpath(<span class="string">&#x27;//title/text()&#x27;</span>).extract_first()</span><br><span class="line">        <span class="comment"># print(1/0)  # 调整调整这个. 简单琢磨一下即可~~</span></span><br><span class="line">        it = CuowuItem()</span><br><span class="line">        it[<span class="string">&#x27;name&#x27;</span>] = name</span><br><span class="line">        <span class="built_in">print</span>(name)</span><br><span class="line">        <span class="keyword">yield</span> it</span><br></pre></td></tr></table></figure>

<p>pipeline:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cuowu.items <span class="keyword">import</span> ErrorItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CuowuPipeline</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(item, ErrorItem):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;错误&quot;</span>, item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;没错&quot;</span>, item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>目录结构:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cuowu</span><br><span class="line">├── cuowu</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── baocuo.py</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br></pre></td></tr></table></figure>






      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://blog.ioimp.top/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" title="Scrapy_模拟登录与中间件" target="_blank" rel="external">http://blog.ioimp.top/2023/12/03/Scrapy-模拟登录与中间件/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/SFYYH" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/SFYYH" target="_blank"><span class="text-dark">山城冰荔枝</span><small class="ml-1x">Web Developer &amp; Designer</small></a></h3>
        <div>个人简介。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2023/12/03/crawlSpider/" title="crawlSpider"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2023/12/03/09-Scrapy-%E7%AE%A1%E9%81%93/" title="Scrapy_管道"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="" data-mobile-sites="qq"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/SFYYH" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/SFYYH" target="_blank"> colincora </a>base on <a href="https://sfyyh.github.io/" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





   







<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":400,"vOffset":-38},"mobile":{"show":true},"react":"opacity:1","dialog":{"enable":true,"script":{"every idle 10s":"text1","tap face":"text2","tap body":"text3"}},"log":false});</script></body>
</html>