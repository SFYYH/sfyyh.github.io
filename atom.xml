<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>山城冰荔枝</title>
  
  
  <link href="http://blog.ioimp.top/atom.xml" rel="self"/>
  
  <link href="http://blog.ioimp.top/"/>
  <updated>2023-12-23T07:14:43.975Z</updated>
  <id>http://blog.ioimp.top/</id>
  
  <author>
    <name>山城冰荔枝</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Vue中js引入图片的方法</title>
    <link href="http://blog.ioimp.top/2023/12/23/Vue%E4%B8%ADjs%E5%BC%95%E5%85%A5%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://blog.ioimp.top/2023/12/23/Vue%E4%B8%ADjs%E5%BC%95%E5%85%A5%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%B9%E6%B3%95/</id>
    <published>2023-12-23T07:13:23.000Z</published>
    <updated>2023-12-23T07:14:43.975Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在Vue项目中，我们经常需要在页面中引入图片。本文将介绍在Vue中引入图片的几种方法。</p><h2 id="1-直接使用img标签"><a href="#1-直接使用img标签" class="headerlink" title="1. 直接使用img标签"></a>1. 直接使用img标签</h2><p>最简单的方法是直接使用HTML的img标签来引入图片。在Vue的模板中，我们可以使用以下方式引入图片：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;@/assets/image.png&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;图片&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure><p>其中，<code>@/</code>是Vue CLI中默认配置的别名，指向<code>src</code>目录。<code>assets</code>是存放静态资源的目录，可以根据实际项目结构进行调整。</p><h2 id="2-使用require引入图片"><a href="#2-使用require引入图片" class="headerlink" title="2. 使用require引入图片"></a>2. 使用require引入图片</h2><p>在Vue中，我们可以使用<code>require</code>函数来引入图片。在Vue的模板中，我们可以使用以下方式引入图片：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">:src</span>=<span class="string">&quot;require(&#x27;@/assets/image.png&#x27;)&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;图片&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意，这里使用了Vue的动态绑定语法<code>:src</code>，使得图片路径可以根据实际需要进行动态改变。</p><h2 id="3-使用import引入图片"><a href="#3-使用import引入图片" class="headerlink" title="3. 使用import引入图片"></a>3. 使用import引入图片</h2><p>在Vue的组件中，我们也可以使用ES6的<code>import</code>语法来引入图片。在Vue的组件中，我们可以使用以下方式引入图片：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> image <span class="keyword">from</span> <span class="string">&#x27;@/assets/image.png&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">      <span class="attr">imgSrc</span>: image</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后，在模板中使用动态绑定语法来显示图片：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">:src</span>=<span class="string">&quot;imgSrc&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;图片&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样，我们就可以通过<code>import</code>来引入图片，并将其赋值给组件的<code>data</code>属性，然后在模板中使用。</p><h2 id="4-使用CSS引入图片"><a href="#4-使用CSS引入图片" class="headerlink" title="4. 使用CSS引入图片"></a>4. 使用CSS引入图片</h2><p>在Vue中，我们也可以使用CSS的<code>background-image</code>属性来引入图片。在Vue的组件的样式中，我们可以使用以下方式引入图片：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.image</span> &#123;</span><br><span class="line">  <span class="attribute">background-image</span>: <span class="built_in">url</span>(<span class="string">&quot;@/assets/image.png&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后，在模板中使用该样式类：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;image&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样，我们就可以通过CSS的方式来引入图片。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了在Vue中引入图片的几种方法：直接使用img标签、使用require引入图片、使用import引入图片和使用CSS引入图片。根据实际项目的需求，可以选择适合的方法来引入图片。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Vue基础" scheme="http://blog.ioimp.top/tags/Vue%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Vue中v-model对应不同的表单标签的处理方式</title>
    <link href="http://blog.ioimp.top/2023/12/23/Vue%E4%B8%ADv-model%E5%AF%B9%E5%BA%94%E4%B8%8D%E5%90%8C%E7%9A%84%E8%A1%A8%E5%8D%95%E6%A0%87%E7%AD%BE%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/"/>
    <id>http://blog.ioimp.top/2023/12/23/Vue%E4%B8%ADv-model%E5%AF%B9%E5%BA%94%E4%B8%8D%E5%90%8C%E7%9A%84%E8%A1%A8%E5%8D%95%E6%A0%87%E7%AD%BE%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/</id>
    <published>2023-12-23T03:15:27.000Z</published>
    <updated>2023-12-23T07:14:40.830Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在Vue中，v-model是一个常用的指令，用于实现表单元素与Vue实例数据的双向绑定。通过v-model指令，我们可以轻松地将表单的输入值与Vue实例中的数据进行同步。</p><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>v-model指令可以用于不同类型的表单元素，包括输入框、复选框、单选框、下拉框等。下面是v-model的基本用法：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;message&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>&#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">message</span>: <span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在上面的例子中，我们创建了一个输入框，并通过v-model指令将输入框的值与Vue实例中的<code>message</code>数据进行绑定。当用户在输入框中输入内容时，<code>message</code>数据会自动更新，同时页面上的<code>p</code>标签中也会显示出输入框的值。</p><h2 id="绑定不同类型的表单标签"><a href="#绑定不同类型的表单标签" class="headerlink" title="绑定不同类型的表单标签"></a>绑定不同类型的表单标签</h2><h3 id="输入框"><a href="#输入框" class="headerlink" title="输入框"></a>输入框</h3><p>对于输入框，v-model会将输入的值作为数据进行绑定。例如，我们可以将输入框的值绑定到一个字符串类型的数据：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;message&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>&#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">message</span>: <span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="复选框"><a href="#复选框" class="headerlink" title="复选框"></a>复选框</h3><p>对于复选框，v-model会将选中状态作为数据进行绑定。例如，我们可以将复选框的选中状态绑定到一个布尔类型的数据：</p><p>复选框在使用v-model时，可以绑定到不同类型的变量上，主要区分为布尔型和数组型。</p><h3 id="布尔型（Boolean）"><a href="#布尔型（Boolean）" class="headerlink" title="布尔型（Boolean）"></a>布尔型（Boolean）</h3><p>当复选框绑定到布尔型变量时，选中和未选中状态将直接映射到布尔值<code>true</code>和<code>false</code>。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;isChecked&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>复选框选中状态：&#123;&#123; isChecked &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">isChecked</span>: <span class="literal">false</span></span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在上面的例子中，<code>isChecked</code>是一个布尔型变量，当复选框被选中时，<code>isChecked</code>变为<code>true</code>，反之为<code>false</code>。</p><h3 id="数组型（Array）"><a href="#数组型（Array）" class="headerlink" title="数组型（Array）"></a>数组型（Array）</h3><p>当复选框绑定到数组型变量时，选中的复选框的value值会被添加到数组中，未选中的则会从数组中移除。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selectedItems&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Item1&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selectedItems&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Item2&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selectedItems&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Item3&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>选中的项目：&#123;&#123; selectedItems &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">selectedItems</span>: []</span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selectedItems&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Item1&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selectedItems&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Item2&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selectedItems&quot;</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Item3&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>选中的项目：&#123;&#123; selectedItems &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">selectedItems</span>: <span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>如果变量是字符串类型则所有的复选框都会被选中</p><p>在上面的例子中，<code>selectedItems</code>是一个数组型变量，当用户选中任意一个复选框时，对应的value值（例如”Item1”）会被添加到<code>selectedItems</code>数组中。如果用户取消选中，该值则会从数组中移除。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>当复选框绑定到布尔型变量时，其用于表示单个复选框的选中状态。</li><li>当复选框绑定到数组型变量时，用于表示多个复选框中被选中的项，并以数组的形式存储所有选中项的value值。</li></ul><p>使用哪种类型主要取决于具体的应用场景和需求。如果只需要控制单个复选框的选中状态，通常使用布尔型变量。而如果需要处理多选的情况，比如表单中的多项选择题，使用数组型变量会更加方便。</p><h3 id="单选框"><a href="#单选框" class="headerlink" title="单选框"></a>单选框</h3><p>对于单选框，v-model会将选中的值作为数据进行绑定。例如，我们可以将单选框的选中值绑定到一个字符串类型的数据：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selected&quot;</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">value</span>=<span class="string">&quot;A&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;selected&quot;</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">value</span>=<span class="string">&quot;B&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>&#123;&#123; selected &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">selected</span>: <span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="下拉框"><a href="#下拉框" class="headerlink" title="下拉框"></a>下拉框</h3><p>对于下拉框，v-model会将选中的值作为数据进行绑定。例如，我们可以将下拉框的选中值绑定到一个字符串类型的数据：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">v-model</span>=<span class="string">&quot;selected&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;A&quot;</span>&gt;</span>Option A<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;B&quot;</span>&gt;</span>Option B<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>&#123;&#123; selected &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="title function_">data</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">selected</span>: <span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="language-javascript">    &#125;;</span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>通过v-model指令，我们可以轻松地实现表单元素与Vue实例数据的双向绑定。无论是输入框、复选框、单选框还是下拉框，都可以通过v-model指令来实现数据的同步更新。这大大简化了表单操作的代码量，并提高了开发效率。</p><p>以上是v-model的基础使用和绑定不同类型的表单标签的方式，希望对你有所帮助！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Vue基础" scheme="http://blog.ioimp.top/tags/Vue%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>JS中什么是事件冒泡</title>
    <link href="http://blog.ioimp.top/2023/12/23/JS%E4%B8%AD%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%8B%E4%BB%B6%E5%86%92%E6%B3%A1/"/>
    <id>http://blog.ioimp.top/2023/12/23/JS%E4%B8%AD%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%8B%E4%BB%B6%E5%86%92%E6%B3%A1/</id>
    <published>2023-12-22T16:33:50.000Z</published>
    <updated>2023-12-23T07:14:37.397Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="事件冒泡"><a href="#事件冒泡" class="headerlink" title="事件冒泡"></a>事件冒泡</h1><p>在JavaScript中，事件冒泡是指当一个元素上的事件被触发时，事件会从该元素开始向上冒泡至其父元素，直到最顶层的父元素。这种冒泡的行为可以让我们在处理事件时更加方便和灵活。</p><h2 id="事件冒泡的原理"><a href="#事件冒泡的原理" class="headerlink" title="事件冒泡的原理"></a>事件冒泡的原理</h2><p>事件冒泡的原理是基于DOM树的结构。在一个典型的HTML页面中，元素之间存在嵌套关系，父元素包含子元素，子元素包含孙元素，以此类推。当一个元素上发生了某个事件（比如点击事件），浏览器会首先触发该元素上的事件处理程序，然后再触发其父元素上的事件处理程序，直到最顶层的父元素。</p><h2 id="事件冒泡的应用"><a href="#事件冒泡的应用" class="headerlink" title="事件冒泡的应用"></a>事件冒泡的应用</h2><p>事件冒泡在JavaScript中有着广泛的应用。通过使用事件冒泡，我们可以方便地为多个元素添加相同的事件处理程序，而不需要分别为每个元素添加。这样可以大大简化代码并提高代码的可维护性。</p><p>另外，事件冒泡还可以实现事件委托。事件委托是指将事件处理程序绑定在父元素上，然后通过事件冒泡的机制来触发处理程序。这种方式可以减少事件处理程序的数量，从而提高性能。例如，我们可以将点击事件处理程序绑定在一个父元素上，然后通过事件冒泡来判断具体是哪个子元素被点击了，从而执行相应的操作。</p><h2 id="如何阻止事件冒泡"><a href="#如何阻止事件冒泡" class="headerlink" title="如何阻止事件冒泡"></a>如何阻止事件冒泡</h2><p>有时候我们希望阻止事件冒泡，即在某个元素上触发事件后，不再向上冒泡至其父元素。在JavaScript中，可以通过调用事件对象的<code>stopPropagation()</code>方法来实现。这样可以在事件处理程序中使用<code>event.stopPropagation()</code>来阻止事件冒泡。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>事件冒泡是JavaScript中的一种重要的事件机制，可以使我们更加方便地处理事件。通过了解事件冒泡的原理和应用，我们可以更好地运用它来编写高效的JavaScript代码。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;!<span class="variable constant_">DOCTYPE</span> html&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">title</span>&gt;</span>事件冒泡示例<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;parent&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;child&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">button</span> <span class="attr">id</span>=<span class="string">&quot;button&quot;</span>&gt;</span>点击我<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="comment">// 获取父元素、子元素和按钮元素</span></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="keyword">var</span> parent = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;parent&#x27;</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="keyword">var</span> child = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;child&#x27;</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="keyword">var</span> button = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;button&#x27;</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="comment">// 为父元素、子元素和按钮元素添加点击事件处理程序</span></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    parent.<span class="title function_">addEventListener</span>(<span class="string">&#x27;click&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;父元素被点击&#x27;</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    &#125;);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    child.<span class="title function_">addEventListener</span>(<span class="string">&#x27;click&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;子元素被点击&#x27;</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    &#125;);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    button.<span class="title function_">addEventListener</span>(<span class="string">&#x27;click&#x27;</span>, <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      event.<span class="title function_">stopPropagation</span>(); <span class="comment">// 阻止事件冒泡</span></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;按钮被点击&#x27;</span>);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    &#125;);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span></span><br></pre></td></tr></table></figure><p>在上述示例代码中，我们创建了一个父元素<code>parent</code>、一个子元素<code>child</code>和一个按钮元素<code>button</code>。我们为这三个元素分别添加了点击事件处理程序。</p><p>当点击按钮时，点击事件会首先触发按钮元素上的事件处理程序，然后再冒泡至子元素和父元素。但是由于我们在按钮元素的事件处理程序中调用了<code>event.stopPropagation()</code>方法，所以事件冒泡会在按钮元素处被阻止，不再向上冒泡至子元素和父元素。因此，只会在控制台输出”按钮被点击”，而不会输出”子元素被点击”和”父元素被点击”。</p><p>这个示例展示了如何使用事件冒泡和阻止事件冒泡来处理事件。<br>希望本篇博客对你理解事件冒泡有所帮助！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Vue基础" scheme="http://blog.ioimp.top/tags/Vue%E5%9F%BA%E7%A1%80/"/>
    
    <category term="JavaScript" scheme="http://blog.ioimp.top/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>MVVM设计模式</title>
    <link href="http://blog.ioimp.top/2023/12/23/MVVM%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>http://blog.ioimp.top/2023/12/23/MVVM%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2023-12-22T16:19:02.000Z</published>
    <updated>2023-12-22T16:47:28.419Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="什么是MVVM设计模式"><a href="#什么是MVVM设计模式" class="headerlink" title="什么是MVVM设计模式"></a>什么是MVVM设计模式</h2><p>MVVM是一种软件架构设计模式，它将应用程序的用户界面(UI)、业务逻辑和数据模型分离开来。MVVM的全称是Model-View-ViewModel，它的核心思想是将视图(View)和模型(Model)之间的依赖关系解耦，通过ViewModel来进行数据的交互和控制。</p><ul><li>Model：模型层，负责数据的访问和处理。它通常包含了数据模型、数据访问层和业务逻辑等。</li><li>View：视图层，负责展示数据并与用户进行交互。它通常包含了用户界面和用户交互逻辑等。</li><li>ViewModel：视图模型层，负责将模型层的数据转化为视图层可用的数据，并处理视图层的用户交互逻辑。它通常包含了数据绑定、命令绑定和业务逻辑等。</li></ul><h2 id="MVVM的优势"><a href="#MVVM的优势" class="headerlink" title="MVVM的优势"></a>MVVM的优势</h2><p>MVVM设计模式的优势在于它能够提高代码的可维护性、可测试性和可扩展性。</p><ul><li>可维护性：由于视图和模型之间的解耦，开发人员可以更容易地对视图和模型进行独立的修改和维护，而不会对其他部分产生影响。</li><li>可测试性：由于ViewModel负责处理业务逻辑，开发人员可以更容易地编写针对ViewModel的单元测试，而不需要依赖于具体的视图。</li><li>可扩展性：由于视图和模型之间的解耦，开发人员可以更容易地对视图和模型进行扩展，而不会对其他部分产生影响。</li></ul><h2 id="MVVM的实现方式"><a href="#MVVM的实现方式" class="headerlink" title="MVVM的实现方式"></a>MVVM的实现方式</h2><p>MVVM的实现方式有多种，下面以一个简单的示例来介绍其中一种实现方式。</p><h3 id="1-创建模型-Model"><a href="#1-创建模型-Model" class="headerlink" title="1. 创建模型(Model)"></a>1. 创建模型(Model)</h3><p>首先，我们需要创建一个模型类来表示我们的数据。比如，我们创建一个User模型类，用于表示用户的信息。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">  <span class="title function_">constructor</span>(<span class="params">name, age</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">name</span> = name;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">age</span> = age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-创建视图-View"><a href="#2-创建视图-View" class="headerlink" title="2. 创建视图(View)"></a>2. 创建视图(View)</h3><p>接下来，我们需要创建一个视图组件来展示用户的信息，并与用户进行交互。比如，我们创建一个UserView组件，用于展示用户的姓名和年龄，并提供一个按钮用于修改用户的信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">  &lt;div&gt;</span><br><span class="line">    &lt;p&gt;&#123;&#123; name &#125;&#125;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;&#123;&#123; age &#125;&#125;&lt;/p&gt;</span><br><span class="line">    &lt;button @click=&quot;update&quot;&gt;修改&lt;/button&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">export default &#123;</span><br><span class="line">  props: &#123;</span><br><span class="line">    user: &#123;</span><br><span class="line">      type: Object,</span><br><span class="line">      required: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  data() &#123;</span><br><span class="line">    return &#123;</span><br><span class="line">      name: this.user.name,</span><br><span class="line">      age: this.user.age</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;,</span><br><span class="line">  methods: &#123;</span><br><span class="line">    update() &#123;</span><br><span class="line">      // 处理修改按钮的点击事件</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><h3 id="3-创建视图模型-ViewModel"><a href="#3-创建视图模型-ViewModel" class="headerlink" title="3. 创建视图模型(ViewModel)"></a>3. 创建视图模型(ViewModel)</h3><p>然后，我们需要创建一个视图模型类来将模型的数据转化为视图可用的数据，并处理视图的用户交互逻辑。比如，我们创建一个UserViewModel视图模型类，用于将User模型的数据转化为UserView组件可用的数据，并处理修改按钮的点击事件。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UserViewModel</span> &#123;</span><br><span class="line">  <span class="title function_">constructor</span>(<span class="params">user</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">user</span> = user;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">get</span> <span class="title function_">name</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">this</span>.<span class="property">user</span>.<span class="property">name</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">set</span> <span class="title function_">name</span>(<span class="params">value</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">user</span>.<span class="property">name</span> = value;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">get</span> <span class="title function_">age</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">this</span>.<span class="property">user</span>.<span class="property">age</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">set</span> <span class="title function_">age</span>(<span class="params">value</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">user</span>.<span class="property">age</span> = value;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="title function_">update</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="comment">// 处理修改按钮的点击事件</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-绑定视图-View-和视图模型-ViewModel"><a href="#4-绑定视图-View-和视图模型-ViewModel" class="headerlink" title="4. 绑定视图(View)和视图模型(ViewModel)"></a>4. 绑定视图(View)和视图模型(ViewModel)</h3><p>最后，我们需要在视图中绑定视图模型，以实现数据的双向绑定和用户交互的命令绑定。比如，我们可以在父组件中引入UserView组件，并将UserViewModel实例作为props传递给UserView组件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">  &lt;div&gt;</span><br><span class="line">    &lt;user-view :user=&quot;userViewModel&quot;&gt;&lt;/user-view&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">import UserView from &#x27;./UserView.vue&#x27;;</span><br><span class="line">import User from &#x27;./User.js&#x27;;</span><br><span class="line"></span><br><span class="line">export default &#123;</span><br><span class="line">  components: &#123;</span><br><span class="line">    UserView</span><br><span class="line">  &#125;,</span><br><span class="line">  data() &#123;</span><br><span class="line">    return &#123;</span><br><span class="line">      userViewModel: new UserViewModel(new User(&#x27;John Doe&#x27;, 25))</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p><img src="/images/image17.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MVVM设计模式通过将视图(View)和模型(Model)之间的依赖关系解耦，提高了代码的可维护性、可测试性和可扩展性。通过创建视图模型(ViewModel)来处理数据的转化和用户交互逻辑，实现了视图(View)和模型(Model)之间的解耦。同时，通过数据绑定和命令绑定，实现了视图(View)和视图模型(ViewModel)之间的双向通信。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Vue基础" scheme="http://blog.ioimp.top/tags/Vue%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Vue中 main.js, APP.vue和 index.html 的作用和关系</title>
    <link href="http://blog.ioimp.top/2023/12/22/Vue%E4%B8%AD-main-js-APP-vue%E5%92%8C-index-html-%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E5%85%B3%E7%B3%BB/"/>
    <id>http://blog.ioimp.top/2023/12/22/Vue%E4%B8%AD-main-js-APP-vue%E5%92%8C-index-html-%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E5%85%B3%E7%B3%BB/</id>
    <published>2023-12-22T15:47:51.000Z</published>
    <updated>2023-12-22T15:50:05.839Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在Vue中，main.js、APP.vue和index.html是三个核心文件，它们在Vue项目中扮演着不同的角色和功能。</p><h2 id="index-html"><a href="#index-html" class="headerlink" title="index.html"></a>index.html</h2><p>index.html是Vue项目的入口文件。它是一个HTML文件，包含了整个应用的骨架。在index.html中，我们可以定义应用的标题、引入CSS和JavaScript文件，以及提供一个容器元素（通常是一个div元素），用于挂载Vue实例。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>My Vue App<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;styles.css&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;main.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;app&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="main-js"><a href="#main-js" class="headerlink" title="main.js"></a>main.js</h2><p>main.js是Vue应用的入口文件。它是一个JavaScript文件，用于创建和配置Vue实例。在main.js中，我们可以引入Vue库，创建Vue实例，并将其挂载到index.html中的容器元素上。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">Vue</span> <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">App</span> <span class="keyword">from</span> <span class="string">&#x27;./App.vue&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> <span class="title class_">Vue</span>(&#123;</span><br><span class="line">  <span class="attr">render</span>: <span class="function"><span class="params">h</span> =&gt;</span> <span class="title function_">h</span>(<span class="title class_">App</span>),</span><br><span class="line">&#125;).$mount(<span class="string">&#x27;#app&#x27;</span>)</span><br></pre></td></tr></table></figure><p>在上面的代码中，我们首先引入了Vue库和App.vue组件。然后，创建了一个Vue实例，并使用render函数渲染App组件。最后，使用$mount方法将Vue实例挂载到id为”app”的元素上。</p><h2 id="App-vue"><a href="#App-vue" class="headerlink" title="App.vue"></a>App.vue</h2><p>App.vue是Vue应用的根组件。它是一个单文件组件，包含了应用的整体布局和逻辑。在App.vue中，我们可以定义应用的顶级路由、导航栏、侧边栏等组件。同时，App.vue也可以包含其他子组件，用于构建整个应用的页面结构。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">header</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>My Vue App<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">nav</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">router-link</span> <span class="attr">to</span>=<span class="string">&quot;/&quot;</span>&gt;</span>Home<span class="tag">&lt;/<span class="name">router-link</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">router-link</span> <span class="attr">to</span>=<span class="string">&quot;/about&quot;</span>&gt;</span>About<span class="tag">&lt;/<span class="name">router-link</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">header</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">router-view</span>&gt;</span><span class="tag">&lt;/<span class="name">router-view</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="attr">name</span>: <span class="string">&#x27;App&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">&#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css"><span class="comment">/* 样式定义 */</span></span></span><br><span class="line"><span class="language-css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在上面的代码中，我们定义了一个顶级的div元素，包含了一个header元素和一个router-view元素。header元素用于显示应用的标题和导航栏，router-view元素用于渲染当前路由对应的组件。</p><h2 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h2><p>这三个文件之间的关系如下：</p><ol><li>index.html是整个应用的入口文件，它引入了main.js和App.vue。</li><li>main.js是Vue应用的入口文件，它创建了Vue实例并将其挂载到index.html中的容器元素上。</li><li>App.vue是Vue应用的根组件，它包含了应用的整体布局和逻辑。在main.js中，我们使用import语句引入了App.vue，并在Vue实例的配置中使用了App组件。</li></ol><p>综上所述，index.html提供了应用的骨架，main.js创建了Vue实例并将其挂载到index.html中的容器元素上，而App.vue定义了整个应用的布局和逻辑。通过这三个文件的协作，我们可以构建出一个完整的Vue应用。<br><img src="/images/image16.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Vue基础" scheme="http://blog.ioimp.top/tags/Vue%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>为什么 yarn build 命令非常耗时</title>
    <link href="http://blog.ioimp.top/2023/12/22/%E4%B8%BA%E4%BB%80%E4%B9%88-yarn-build%E5%91%BD%E4%BB%A4%E9%9D%9E%E5%B8%B8%E8%80%97%E6%97%B6/"/>
    <id>http://blog.ioimp.top/2023/12/22/%E4%B8%BA%E4%BB%80%E4%B9%88-yarn-build%E5%91%BD%E4%BB%A4%E9%9D%9E%E5%B8%B8%E8%80%97%E6%97%B6/</id>
    <published>2023-12-22T08:31:23.000Z</published>
    <updated>2023-12-22T09:27:44.484Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在开发过程中，我们经常使用构建工具来编译、打包和优化我们的代码。而在前端开发中，<code>yarn build</code> 命令是常用的构建命令之一。然而，你可能会注意到，<code>yarn build</code> 命令有时候会非常耗时，特别是在项目变得庞大复杂时。那么，为什么 <code>yarn build</code> 命令会如此耗时呢？本篇博客将对此进行探讨。</p><h2 id="1-代码量的增加"><a href="#1-代码量的增加" class="headerlink" title="1. 代码量的增加"></a>1. 代码量的增加</h2><p>随着项目的发展，代码量也会逐渐增加。更多的代码需要被编译、转换、打包和优化，这必然会增加构建的时间。尤其是在处理大量文件时，构建工具需要遍历每一个文件并进行处理，这将会消耗大量的时间。</p><h2 id="2-依赖项的增多"><a href="#2-依赖项的增多" class="headerlink" title="2. 依赖项的增多"></a>2. 依赖项的增多</h2><p>在现代的前端开发中，我们通常依赖于许多第三方库和工具。这些依赖项可能有自己的构建过程，当我们执行 <code>yarn build</code> 命令时，构建工具需要先编译和打包这些依赖项，然后再处理我们自己的代码。因此，依赖项的增多也会导致构建时间的增加。</p><h2 id="3-文件读取和加载"><a href="#3-文件读取和加载" class="headerlink" title="3. 文件读取和加载"></a>3. 文件读取和加载</h2><p>在构建过程中，构建工具需要从磁盘读取对应的文件到内存中进行处理。这个过程涉及到磁盘的读取速度和文件的大小。如果项目中有大量的文件或者文件很大，那么读取和加载的时间将会增加。</p><h2 id="4-代码处理和转换"><a href="#4-代码处理和转换" class="headerlink" title="4. 代码处理和转换"></a>4. 代码处理和转换</h2><p>一旦文件被加载到内存中，构建工具开始根据配置使用对应的 loader 对代码进行处理和转换。例如，对于 JavaScript 文件，可能会使用 Babel 进行转换；对于 CSS 文件，可能会使用 PostCSS 进行处理。这个处理和转换的过程可能会涉及到复杂的算法和逻辑，因此会耗费一定的时间。</p><h2 id="5-输出到磁盘"><a href="#5-输出到磁盘" class="headerlink" title="5. 输出到磁盘"></a>5. 输出到磁盘</h2><p>在代码处理和转换完成后，构建工具会将处理完的内容输出到磁盘的指定目录。这个过程也需要写入磁盘的速度和文件的大小。如果输出的文件很多或者文件很大，那么写入磁盘的时间将会增加。</p><h2 id="6-优化和压缩过程"><a href="#6-优化和压缩过程" class="headerlink" title="6. 优化和压缩过程"></a>6. 优化和压缩过程</h2><p>在构建过程中，我们通常会对代码进行优化和压缩，以提高性能和减少文件大小。这些优化和压缩过程可能需要较长的时间，特别是在处理大型项目时。例如，压缩和混淆 JavaScript 代码、优化 CSS 样式、压缩图片等都需要一定的时间。</p><h2 id="7-硬件性能限制"><a href="#7-硬件性能限制" class="headerlink" title="7. 硬件性能限制"></a>7. 硬件性能限制</h2><p>在一些较老或配置较低的计算机上，构建过程可能会更加耗时。较慢的处理器、较少的内存和较慢的硬盘都会对构建时间产生影响。因此，如果你的计算机性能较低，那么构建时间可能会更长。</p><h2 id="8-构建过程的优化"><a href="#8-构建过程的优化" class="headerlink" title="8. 构建过程的优化"></a>8. 构建过程的优化</h2><p>尽管 <code>yarn build</code> 命令可能会耗时，但我们仍然可以采取一些措施来优化构建过程，以减少构建时间。以下是一些常见的优化方法：</p><ul><li>使用增量构建：只重新构建修改过的文件，而不是整个项目。</li><li>使用缓存：将构建过程中生成的中间文件缓存起来，以便下次构建时能够复用。</li><li>并行处理：将构建过程中的任务并行执行，以提高整体的构建速度。</li><li>优化配置文件：检查构建工具的配置文件，确保其使用了最佳的配置选项。</li></ul><p>总结起来，<code>yarn build</code> 命令耗时的原因有很多，包括代码量的增加、依赖项的增多、文件读取和加载、代码处理和转换、输出到磁盘、优化和压缩过程、硬件性能限制等。然而，我们可以通过优化构建过程和硬件环境，来减少构建时间，提高开发效率。希望本篇博客能够对你理解 <code>yarn build</code> 命令的耗时问题有所帮助。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
    <category term="WebPack" scheme="http://blog.ioimp.top/tags/WebPack/"/>
    
  </entry>
  
  <entry>
    <title>WebPack对Js降级实现兼容低版本浏览器</title>
    <link href="http://blog.ioimp.top/2023/12/22/WebPack%E5%AF%B9js%E9%99%8D%E7%BA%A7%E5%AE%9E%E7%8E%B0%E5%85%BC%E5%AE%B9%E4%BD%8E%E7%89%88%E6%9C%AC%E6%B5%8F%E8%A7%88%E5%99%A8/"/>
    <id>http://blog.ioimp.top/2023/12/22/WebPack%E5%AF%B9js%E9%99%8D%E7%BA%A7%E5%AE%9E%E7%8E%B0%E5%85%BC%E5%AE%B9%E4%BD%8E%E7%89%88%E6%9C%AC%E6%B5%8F%E8%A7%88%E5%99%A8/</id>
    <published>2023-12-22T07:34:51.000Z</published>
    <updated>2023-12-22T08:16:09.125Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在前端开发中，我们经常会遇到兼容性的问题，特别是在低版本浏览器中。为了解决这个问题，Webpack提供了一种降级的方式，可以实现在低版本浏览器中兼容新的JavaScript语法和功能。</p><h2 id="什么是Webpack"><a href="#什么是Webpack" class="headerlink" title="什么是Webpack"></a>什么是Webpack</h2><p>Webpack是一个现代化的前端构建工具，它能够将多个JavaScript文件打包成一个或多个bundle文件，从而提高网站性能和加载速度。除此之外，Webpack还提供了许多其他功能，如代码分割、模块化、热模块替换等。</p><h2 id="为什么需要兼容低版本浏览器"><a href="#为什么需要兼容低版本浏览器" class="headerlink" title="为什么需要兼容低版本浏览器"></a>为什么需要兼容低版本浏览器</h2><p>虽然现代浏览器已经支持了许多新的JavaScript语法和功能，但是在实际开发中我们仍然需要兼容低版本浏览器。因为在某些情况下，用户可能仍然使用低版本的浏览器，我们不能因为他们的浏览器版本低就让他们无法正常使用我们的网站或应用。</p><h2 id="Webpack如何实现兼容低版本浏览器"><a href="#Webpack如何实现兼容低版本浏览器" class="headerlink" title="Webpack如何实现兼容低版本浏览器"></a>Webpack如何实现兼容低版本浏览器</h2><p>Webpack提供了一些插件和配置选项，可以帮助我们实现兼容低版本浏览器。下面是一些常用的方法：</p><h3 id="Babel插件"><a href="#Babel插件" class="headerlink" title="Babel插件"></a>Babel插件</h3><p>Babel是一个广泛使用的JavaScript编译器，它可以将新的JavaScript语法转换成低版本浏览器可以理解的语法。在Webpack中，我们可以使用Babel插件来处理JavaScript文件。</p><p>首先，我们需要安装一些必要的Babel插件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install babel-loader @babel/core @babel/preset-env --save-dev</span><br></pre></td></tr></table></figure><p>然后，在Webpack配置文件中，我们需要添加一个规则来处理JavaScript文件：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">module</span>: &#123;</span><br><span class="line">  <span class="attr">rules</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">test</span>: <span class="regexp">/\.js$/</span>,</span><br><span class="line">      <span class="attr">exclude</span>: <span class="regexp">/node_modules/</span>,</span><br><span class="line">      <span class="attr">use</span>: &#123;</span><br><span class="line">        <span class="attr">loader</span>: <span class="string">&#x27;babel-loader&#x27;</span>,</span><br><span class="line">        <span class="attr">options</span>: &#123;</span><br><span class="line">          <span class="attr">presets</span>: [<span class="string">&#x27;@babel/preset-env&#x27;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，Webpack就会使用Babel插件来转换JavaScript文件，并将其输出到bundle文件中。</p><h3 id="Polyfill"><a href="#Polyfill" class="headerlink" title="Polyfill"></a>Polyfill</h3><p>除了转换新的JavaScript语法外，我们还需要处理一些新的JavaScript功能，比如Promise、Map、Set等。为了在低版本浏览器中使用这些功能，我们可以使用Polyfill。</p><p>Polyfill是一种JavaScript代码片段，它可以在低版本浏览器中实现新的JavaScript功能。在Webpack中，我们可以使用<code>@babel/polyfill</code>插件来引入Polyfill。</p><p>首先，我们需要安装<code>@babel/polyfill</code>插件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install @babel/polyfill --save</span><br></pre></td></tr></table></figure><p>然后，在入口文件中，我们需要引入Polyfill：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;@babel/polyfill&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这样，Webpack会将Polyfill打包到bundle文件中，并在低版本浏览器中自动加载。</p><h3 id="其他配置选项"><a href="#其他配置选项" class="headerlink" title="其他配置选项"></a>其他配置选项</h3><p>除了Babel插件和Polyfill外，Webpack还提供了其他一些配置选项，可以帮助我们实现兼容低版本浏览器。比如，我们可以使用<code>target</code>选项来指定要兼容的浏览器版本：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">target</span>: [<span class="string">&#x27;web&#x27;</span>, <span class="string">&#x27;browserslist:ie &gt;= 8&#x27;</span>]</span><br></pre></td></tr></table></figure><p>这样，Webpack会根据我们的配置自动处理兼容性问题。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在本文中，我们介绍了Webpack如何实现兼容低版本浏览器的方法。通过使用Babel插件、Polyfill和其他配置选项，我们可以让我们的网站或应用在低版本浏览器中正常运行。希望本文对你有所帮助！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
    <category term="WebPack" scheme="http://blog.ioimp.top/tags/WebPack/"/>
    
  </entry>
  
  <entry>
    <title>Webpack中加载器模式设为asset，为什么以8KB大小区分图片</title>
    <link href="http://blog.ioimp.top/2023/12/22/Webpack%E4%B8%AD%E5%8A%A0%E8%BD%BD%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AE%BE%E4%B8%BAasset%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BB%A58KB%E5%A4%A7%E5%B0%8F%E5%8C%BA%E5%88%86%E5%9B%BE%E7%89%87/"/>
    <id>http://blog.ioimp.top/2023/12/22/Webpack%E4%B8%AD%E5%8A%A0%E8%BD%BD%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AE%BE%E4%B8%BAasset%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BB%A58KB%E5%A4%A7%E5%B0%8F%E5%8C%BA%E5%88%86%E5%9B%BE%E7%89%87/</id>
    <published>2023-12-22T07:11:39.000Z</published>
    <updated>2023-12-22T07:34:50.722Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Webpack中加载器模式设为asset，为什么以8KB大小区分图片"><a href="#Webpack中加载器模式设为asset，为什么以8KB大小区分图片" class="headerlink" title="Webpack中加载器模式设为asset，为什么以8KB大小区分图片"></a>Webpack中加载器模式设为asset，为什么以8KB大小区分图片</h2><p>在Webpack中，加载器模式可以设置为<code>asset</code>，用于处理资源文件（例如图片、字体等）。</p><p>默认情况下，Webpack会根据资源文件的大小来决定如何处理。当资源文件的大小小于8KB时，Webpack会将其转换为Data URL（base64编码）并直接嵌入到生成的JS文件中，以减少HTTP请求。而当资源文件的大小大于等于8KB时，Webpack会将其处理为独立的文件，并通过URL引用的方式加载。</p><p>这种区分是为了平衡代码体积和加载性能之间的关系。将小文件转换为Data URL可以减少HTTP请求的数量，但会增加JS文件的体积，可能导致加载时间变长。而将大文件作为独立文件加载可以减小JS文件的体积，但会增加HTTP请求的数量，可能导致加载时间变长。</p><p>因此，8KB是一个经验值，可以根据具体项目的需求进行调整。如果项目中有大量的小文件，可以考虑将此值调低，以减少HTTP请求的数量；如果项目中有大量的大文件，可以考虑将此值调高，以减小JS文件的体积。</p><h2 id="将图片转换为base64编码的好处和坏处如下："><a href="#将图片转换为base64编码的好处和坏处如下：" class="headerlink" title="将图片转换为base64编码的好处和坏处如下："></a>将图片转换为base64编码的好处和坏处如下：</h2><p><strong>好处：</strong></p><ol><li>减少HTTP请求：将图片转换为base64编码后，可以直接嵌入到HTML、CSS或JavaScript文件中，避免了额外的HTTP请求，从而加快页面加载速度。</li><li>简化项目结构：将图片嵌入到代码中，可以减少项目中的文件数量，简化项目结构，方便管理和部署。</li><li>提高图片加载速度：由于base64编码的图片嵌入到文件中，不需要再进行额外的网络请求，因此可以减少图片的加载时间。</li></ol><p><strong>坏处：</strong></p><ol><li>增加文件体积：base64编码会使图片的体积增加约1&#x2F;3，因为编码后的文本比原始二进制数据要大。这可能导致文件体积增大，特别是当有多个图片被转换为base64编码时，会增加整个文件的大小。</li><li>缓存问题：base64编码的图片无法被浏览器缓存，因为它们被嵌入到了文件中。每次文件更新都会导致图片重新下载，这可能会影响网页的性能。</li><li>不适用于大型图片：由于base64编码会增加文件体积，因此对于大型图片（通常超过几十KB或更大）来说，将其转换为base64编码可能导致文件过大，影响页面加载速度。</li></ol><p>因此，将图片转换为base64编码适用于小型图标或小图片，并且在需要减少HTTP请求和简化项目结构的情况下使用。对于大型图片，最好将其作为独立文件加载，以避免文件过大和缓存问题。</p><h2 id="WebPack如何处理字体图标"><a href="#WebPack如何处理字体图标" class="headerlink" title="WebPack如何处理字体图标"></a>WebPack如何处理字体图标</h2><p><img src="/images/image15.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
    <category term="WebPack" scheme="http://blog.ioimp.top/tags/WebPack/"/>
    
  </entry>
  
  <entry>
    <title>宏任务和微任务的区别</title>
    <link href="http://blog.ioimp.top/2023/12/22/%E5%AE%8F%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%BE%AE%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://blog.ioimp.top/2023/12/22/%E5%AE%8F%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%BE%AE%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2023-12-21T16:52:10.000Z</published>
    <updated>2023-12-21T16:53:53.609Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>宏任务是由浏览器引擎进行调度和执行的，它们会被放入宏任务队列中，并且按照队列的顺序执行。宏任务的执行时间较长，因此会造成较大的延迟。常见的宏任务包括DOM事件处理、setTimeout和setInterval等。</p><p>微任务是在宏任务执行完毕之后立即执行的任务，它们会被放入微任务队列中，并且在宏任务队列为空时执行。微任务的执行时间较短，因此不会造成较大的延迟。常见的微任务包括Promise的resolve和reject回调、MutationObserver和process.nextTick等。</p><p>由于微任务会在宏任务执行完毕之后立即执行，因此微任务的优先级较高。也就是说，当一个宏任务执行完毕后，会立即执行所有的微任务，而不会等待下一个宏任务。这样可以保证微任务的执行顺序不会被打乱。</p><p>总结起来，宏任务的执行顺序是先进先出，而微任务的执行顺序是后进先出。宏任务的执行时间较长，会造成较大的延迟，而微任务的执行时间较短，不会造成较大的延迟。微任务的优先级较高，会在宏任务执行完毕之后立即执行。<br><img src="/images/image13.png"><br><img src="/images/image14.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>为什么说同步任务是非耗时任务，异步任务是耗时任务</title>
    <link href="http://blog.ioimp.top/2023/12/22/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4%E5%90%8C%E6%AD%A5%E4%BB%BB%E5%8A%A1%E6%98%AF%E9%9D%9E%E8%80%97%E6%97%B6%E4%BB%BB%E5%8A%A1%EF%BC%8C%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E6%98%AF%E8%80%97%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.ioimp.top/2023/12/22/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4%E5%90%8C%E6%AD%A5%E4%BB%BB%E5%8A%A1%E6%98%AF%E9%9D%9E%E8%80%97%E6%97%B6%E4%BB%BB%E5%8A%A1%EF%BC%8C%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E6%98%AF%E8%80%97%E6%97%B6%E4%BB%BB%E5%8A%A1/</id>
    <published>2023-12-21T16:35:58.000Z</published>
    <updated>2023-12-21T16:43:04.362Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>同步任务</strong>是指在程序执行过程中，必须等待该任务完成后才能继续执行下面的代码。因为同步任务会阻塞程序的执行，所以它通常被认为是非耗时任务。</p><p><strong>异步任务</strong>是指在程序执行过程中，不需要等待该任务完成就可以继续执行下面的代码。异步任务通常会通过多线程、回调函数或者事件驱动等方式实现。由于异步任务不会阻塞程序的执行，所以它通常被认为是耗时任务。</p><p><strong>需要注意的是</strong>，同步任务和异步任务的耗时性质与任务本身的执行时间没有直接关系。一个同步任务可能执行时间很长，但它会阻塞程序的执行，所以被认为是非耗时任务。而一个异步任务可能执行时间很短，但它不会阻塞程序的执行，所以被认为是耗时任务。</p><p>耗时和非耗时的区分是<strong>相对于程序整体执行流程而言的</strong>。耗时任务通常指的是那些需要较长时间才能完成的任务，比如访问网络、读写大文件、进行复杂计算等。这些任务如果以同步方式执行，会导致程序在等待任务完成期间无法进行任何其他操作，即阻塞了程序的执行流程，用户体验较差。</p><p>非耗时任务则是那些可以迅速完成的任务，如简单的数学计算、修改变量值等。这些任务即使以同步方式执行，也不会对程序的流畅性造成太大影响。</p><p>因此，在编程中，通常会将耗时任务设计为异步执行，以避免阻塞主线程，提高程序的响应性和效率。通过回调函数、Promise、async&#x2F;await等机制，可以在耗时任务完成后再执行相关的操作，而不必让整个程序等待耗时任务的完成。这就是为什么通常将同步任务视为非耗时任务，而将异步任务视为耗时任务的原因。</p><h2 id="同步任务和异步任务的执行过程"><a href="#同步任务和异步任务的执行过程" class="headerlink" title="同步任务和异步任务的执行过程"></a>同步任务和异步任务的执行过程</h2><p><img src="/images/image12.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
    <category term="异步操作" scheme="http://blog.ioimp.top/tags/%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>Node中async/await的详解</title>
    <link href="http://blog.ioimp.top/2023/12/22/Node%E4%B8%ADasync-await%E7%9A%84%E8%AF%A6%E8%A7%A3/"/>
    <id>http://blog.ioimp.top/2023/12/22/Node%E4%B8%ADasync-await%E7%9A%84%E8%AF%A6%E8%A7%A3/</id>
    <published>2023-12-21T16:23:35.000Z</published>
    <updated>2023-12-21T16:30:07.422Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="async-await的基本使用"><a href="#async-await的基本使用" class="headerlink" title="async&#x2F;await的基本使用"></a>async&#x2F;await的基本使用</h1><p>async&#x2F;await是ES8中引入的新语法，用于简化promise的异步操作。</p><p>使用async关键字修饰函数，表示该函数是一个异步函数。异步函数内部可以使用await关键字来等待一个promise对象的执行结果。</p><p>await关键字可以放在任何返回promise的表达式前面，它会暂停函数的执行，直到promise被解析或拒绝。如果promise被解析，await表达式会返回解析的值；如果promise被拒绝，await表达式会抛出一个错误。</p><p>异步函数可以像普通函数一样返回一个值，返回的值会被包装成一个被解析的promise对象。</p><p>以下是示例代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 异步函数示例</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">fetchData</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="comment">// 使用await等待promise的执行结果</span></span><br><span class="line">  <span class="keyword">const</span> result = <span class="keyword">await</span> <span class="title function_">fetch</span>(<span class="string">&#x27;https://api.example.com/data&#x27;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 返回一个被解析的promise对象</span></span><br><span class="line">  <span class="keyword">return</span> result.<span class="title function_">json</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用异步函数示例</span></span><br><span class="line"><span class="title function_">fetchData</span>()</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(data);</span><br><span class="line">  &#125;)</span><br><span class="line">  .<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure><p>在上面的示例中，<code>fetchData</code>是一个异步函数，使用<code>await</code>关键字等待<code>fetch</code>函数返回的promise对象的执行结果。在<code>fetchData</code>函数内部，可以像同步代码一样使用<code>result</code>变量来访问<code>fetch</code>函数返回的结果。</p><p>调用异步函数时，可以像调用普通函数一样使用<code>.then</code>和<code>.catch</code>方法来处理异步操作的结果。在上面的示例中，使用<code>.then</code>方法来处理异步操作的成功结果，使用<code>.catch</code>方法来处理异步操作的错误结果。</p><p>通过使用async&#x2F;await，我们可以将异步操作的代码写得更加简洁、易读，并且可以避免使用链式调用then的方式。</p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><h2 id="1-使用环境"><a href="#1-使用环境" class="headerlink" title="1. 使用环境"></a>1. 使用环境</h2><ul><li><code>async</code>和<code>await</code>是ES7的新特性，需要确保Node版本至少为7.6.0或更高。</li><li><code>async</code>函数返回一个Promise对象，可以使用<code>.then()</code>和<code>.catch()</code>进行链式调用。</li></ul><h2 id="2-错误处理"><a href="#2-错误处理" class="headerlink" title="2. 错误处理"></a>2. 错误处理</h2><ul><li>使用<code>await</code>时，如果Promise被拒绝（reject），会抛出异常。因此需要使用<code>try...catch</code>语句进行错误处理。</li><li>如果没有正确处理错误，可能会导致程序崩溃。</li></ul><h2 id="3-循环中使用"><a href="#3-循环中使用" class="headerlink" title="3. 循环中使用"></a>3. 循环中使用</h2><ul><li>在循环中使用<code>await</code>时，需要注意可能会导致代码变成串行执行，影响性能。</li><li>如果需要并行执行，可以使用<code>Promise.all()</code>。</li></ul><h2 id="4-await的使用"><a href="#4-await的使用" class="headerlink" title="4. await的使用"></a>4. <code>await</code>的使用</h2><ul><li><code>await</code>只能在<code>async</code>函数内部使用。</li><li><code>await</code>后面跟着的应该是一个Promise对象或者任何要等待的值。</li><li>在async修饰的方法中，第一个await之前的代码都是同步执行的，而第一个await之后的代码都会异步执行。</li></ul><h2 id="5-返回值"><a href="#5-返回值" class="headerlink" title="5. 返回值"></a>5. 返回值</h2><ul><li><code>async</code>函数总是返回一个Promise，即使函数内部没有使用<code>await</code>。</li><li>如果<code>async</code>函数内部抛出错误，返回的Promise会被拒绝（reject）。</li></ul><h2 id="6-await的等待"><a href="#6-await的等待" class="headerlink" title="6. await的等待"></a>6. <code>await</code>的等待</h2><ul><li><code>await</code>会暂停其后的代码执行，直到Promise解决（resolve）或拒绝（reject）。</li></ul><h2 id="7-调试"><a href="#7-调试" class="headerlink" title="7. 调试"></a>7. 调试</h2><ul><li>在使用<code>async</code>和<code>await</code>时，可能会使得调试变得更加困难，因为它们会改变错误堆栈的追踪方式。</li><li></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
    <category term="异步操作" scheme="http://blog.ioimp.top/tags/%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>Node中Promise 对象的意思</title>
    <link href="http://blog.ioimp.top/2023/12/21/Node%E4%B8%ADPromise-%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%84%8F%E6%80%9D/"/>
    <id>http://blog.ioimp.top/2023/12/21/Node%E4%B8%ADPromise-%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%84%8F%E6%80%9D/</id>
    <published>2023-12-21T02:56:30.000Z</published>
    <updated>2023-12-21T16:02:47.417Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Node中Promise-对象的意思"><a href="#Node中Promise-对象的意思" class="headerlink" title="Node中Promise 对象的意思"></a>Node中Promise 对象的意思</h1><p>Promise 对象是 JavaScript 中处理异步操作的一种方式，它代表了一个异步操作的最终完成或失败，并可以返回一个结果或错误。</p><h2 id="Promise-的基本概念"><a href="#Promise-的基本概念" class="headerlink" title="Promise 的基本概念"></a>Promise 的基本概念</h2><ul><li>Promise 是一个构造函数<ul><li>我们可以创建Promise的实例 const p&#x3D; new Promise()</li><li>new 出来的一个实例对象，代表一个异步操作</li></ul></li><li>Promise.prototype上包含then() </li><li>.then（）方法用来预先指定成功和失败的回调函数<ul><li>p.then(成功回调函数，失败的回调函数)</li><li>p.then(result&#x3D;&gt;{},error&#x3D;&gt;{})</li></ul></li></ul><h2 id="Promise-对象有三种状态："><a href="#Promise-对象有三种状态：" class="headerlink" title="Promise 对象有三种状态："></a>Promise 对象有三种状态：</h2><ol><li>Pending（进行中）：初始状态，表示异步操作还在进行中，既不是成功也不是失败状态。</li><li>Fulfilled（已完成）：表示异步操作成功完成，并返回了一个结果。</li><li>Rejected（已失败）：表示异步操作失败，并返回了一个错误。</li></ol><p>Promise 对象的构造函数接受一个执行器函数作为参数，这个执行器函数有两个参数，分别是 resolve 和 reject 函数。在执行器函数中，我们可以执行异步操作，并在适当的时候调用 resolve 或 reject 函数来改变 Promise 对象的状态。</p><h2 id="Promise-对象具有以下特点："><a href="#Promise-对象具有以下特点：" class="headerlink" title="Promise 对象具有以下特点："></a>Promise 对象具有以下特点：</h2><ol><li>Promise 对象是不可变的，一旦状态改变就无法再次改变。</li><li>Promise 对象可以通过 <code>.then()</code> 方法添加成功状态的回调函数，通过 <code>.catch()</code> 方法添加失败状态的回调函数，也可以使用 <code>.finally()</code> 方法添加无论成功或失败都会执行的回调函数。</li><li>Promise 对象可以通过 Promise 链实现对多个异步操作的串行或并行处理。</li><li>Promise 对象可以通过 <code>async/await</code> 语法进行更简洁的异步操作处理。</li></ol><h2 id="可以用console-dir-Promise-来查课Promise对象的属性"><a href="#可以用console-dir-Promise-来查课Promise对象的属性" class="headerlink" title="可以用console.dir(Promise) 来查课Promise对象的属性"></a>可以用console.dir(Promise) 来查课Promise对象的属性</h2><p>使用 Promise 对象可以更好地处理异步操作，避免了回调地狱和层层嵌套的问题，使代码更加清晰和可维护。<br><code>console.dir</code> 是 JavaScript 中的一个方法，用于将一个对象的所有可枚举属性打印到控制台中，以便查看对象的结构和属性。</p><p>该方法接受一个对象作为参数，并将对象的属性以键值对的形式打印到控制台中。与 <code>console.log()</code> 方法不同，<code>console.dir()</code> 方法会显示对象的属性的详细信息，包括属性名称、属性值和属性的数据类型。</p><p><code>console.dir()</code> 方法在调试和开发过程中非常有用，可以帮助开发人员了解对象的结构和属性，以便更好地理解和调试代码。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 利用node  fs模块进行的读取文件操作 三次嵌套容易引起回调地狱</span></span><br><span class="line"><span class="comment">// const &#123; error &#125; = require(&#x27;console&#x27;);</span></span><br><span class="line"><span class="comment">// let fs = require(&#x27;fs&#x27;);</span></span><br><span class="line"><span class="comment">// fs.readFile(&#x27;./file/test1.txt&#x27;,&#x27;utf-8&#x27;,(error,res)=&gt;&#123;</span></span><br><span class="line"><span class="comment">//     if(error) console.log(error.message)</span></span><br><span class="line"><span class="comment">//     console.log(res)</span></span><br><span class="line"><span class="comment">//     fs.readFile(&#x27;./file/test2.txt&#x27;,&#x27;utf-8&#x27;,(error,res)=&gt;&#123;</span></span><br><span class="line"><span class="comment">//         if(error) console.log(error.message)</span></span><br><span class="line"><span class="comment">//         console.log(res)</span></span><br><span class="line"><span class="comment">//         fs.readFile(&#x27;./file/test3.txt&#x27;,&#x27;utf-8&#x27;,(error,res)=&gt;&#123;</span></span><br><span class="line"><span class="comment">//             if(error) console.log(error.message)</span></span><br><span class="line"><span class="comment">//             console.log(res)</span></span><br><span class="line"><span class="comment">//         &#125;)</span></span><br><span class="line"><span class="comment">//     &#125;)</span></span><br><span class="line"><span class="comment">// &#125;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 利用then-fs来进行文件读取操作（未进行顺序处理）</span></span><br><span class="line"><span class="comment">// import thenFs from &#x27;then-fs&#x27;</span></span><br><span class="line"><span class="comment">// thenFs.readFile(&#x27;./file/test.txt&#x27;,&#x27;utf8&#x27;).then((r1)=&gt;&#123;console.log(r1)&#125;)</span></span><br><span class="line"><span class="comment">// thenFs.readFile(&#x27;./file/test2.txt&#x27;,&#x27;utf8&#x27;).then((r2)=&gt;&#123;console.log(r2)&#125;)</span></span><br><span class="line"><span class="comment">// thenFs.readFile(&#x27;./file/test3.txt&#x27;,&#x27;utf8&#x27;).then((r3)=&gt;&#123;console.log(r3)&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// then-fs顺序处理</span></span><br><span class="line"><span class="keyword">import</span> thenFs <span class="keyword">from</span> <span class="string">&#x27;then-fs&#x27;</span></span><br><span class="line">thenFs.<span class="title function_">readFile</span>(<span class="string">&#x27;./file/test.txt&#x27;</span>,<span class="string">&#x27;utf8&#x27;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">r1</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(r1)</span><br><span class="line">    <span class="keyword">return</span> thenFs.<span class="title function_">readFile</span>(<span class="string">&#x27;./file/test2.txt&#x27;</span>,<span class="string">&#x27;utf8&#x27;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">r2</span>)=&gt;</span>&#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(r2)</span><br><span class="line">        thenFs.<span class="title function_">readFile</span>(<span class="string">&#x27;./file/test3.txt&#x27;</span>,<span class="string">&#x27;utf8&#x27;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">r3</span>)=&gt;</span>&#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(r3)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
  </entry>
  
  <entry>
    <title>npm和pnpm的区别</title>
    <link href="http://blog.ioimp.top/2023/12/21/npm%E5%92%8Cpnpm%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://blog.ioimp.top/2023/12/21/npm%E5%92%8Cpnpm%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2023-12-21T01:43:41.000Z</published>
    <updated>2023-12-21T01:44:43.544Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>pnpm 和 npm 都是 JavaScript 包管理工具，用于安装和管理项目的依赖。</p><ol><li><p>安装速度：pnpm 在安装依赖时使用了硬链接的方式，可以复用已安装的依赖，因此安装速度更快。而 npm 则会将依赖完全复制到项目的 <code>node_modules</code> 目录中，因此安装速度相对较慢。</p></li><li><p>磁盘空间占用：由于 pnpm 使用了硬链接的方式，相同的依赖只会在磁盘上占用一份空间，因此 pnpm 的磁盘空间占用相对较小。而 npm 则会将每个项目的依赖都完整地复制到项目的 <code>node_modules</code> 目录中，因此磁盘空间占用较大。</p></li><li><p>内存占用：pnpm 在安装和运行时只需要占用较少的内存，因为它使用了硬链接和符号链接来共享依赖。而 npm 则需要占用较多的内存，因为它会将所有的依赖都解压到内存中。</p></li><li><p>兼容性：由于 pnpm 使用了硬链接和符号链接的方式，可能在某些操作系统或文件系统上不兼容。而 npm 则是使用了标准的文件复制方式，因此更加兼容。</p></li></ol><p>综上所述，pnpm 相对于 npm 来说，在安装速度、磁盘空间占用和内存占用方面有一定的优势，但在兼容性方面可能存在一些问题。因此，在选择使用哪个工具时，可以根据具体的项目需求和环境来决定。</p><p>pnpm 在安装依赖时会将依赖信息添加到项目的 package.json 文件中。这与 npm 的行为是一致的。当你使用 pnpm 安装依赖时，会自动更新 package.json 文件的 dependencies 或 devDependencies 字段，将安装的依赖添加到其中，以便项目在其他环境中能够正确地安装和运行所需的依赖。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="前端" scheme="http://blog.ioimp.top/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="ES6" scheme="http://blog.ioimp.top/tags/ES6/"/>
    
    <category term="前端学习" scheme="http://blog.ioimp.top/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Node.js" scheme="http://blog.ioimp.top/tags/Node-js/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy_Splash的使用</title>
    <link href="http://blog.ioimp.top/2023/12/03/13-Scrapy-Splash%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://blog.ioimp.top/2023/12/03/13-Scrapy-Splash%E7%9A%84%E4%BD%BF%E7%94%A8/</id>
    <published>2023-12-03T04:00:18.000Z</published>
    <updated>2023-12-03T04:02:14.277Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Scrapy-splash模块使用"><a href="#Scrapy-splash模块使用" class="headerlink" title="Scrapy_splash模块使用"></a>Scrapy_splash模块使用</h1><h2 id="一-Splash"><a href="#一-Splash" class="headerlink" title="一. Splash"></a>一. Splash</h2><p>后续的爬虫的课程. 随便随时来听.  – 樵夫说的. </p><p>splash是一个可以动态渲染js的工具. 有助于我们完成复杂的js内容加载工作.  你可以理解为另一个没有界面的selenium.</p><h3 id="1-1-splash安装"><a href="#1-1-splash安装" class="headerlink" title="1.1 splash安装"></a>1.1 splash安装</h3><p>splash的安装过程十分复杂. 复杂到官方都不推荐你去手动安装它. </p><p>官方建议. 用docker去安装splash. 所以. 你需要先去安装docker. 但是docker这玩意在windows上支持非常不好. 各种各样的问题. 外加上后期我们要把爬虫部署到linux. 那干脆. 我们就安装一个linux. 在linux上搞docker是非常easy的. </p><p>有能力, 不怕苦的同学可以在windows上搞一个docker试试. 我这里就不带你们找坑踩了. 直接上Linux. </p><h4 id="1-1-1安装VM"><a href="#1-1-1安装VM" class="headerlink" title="1.1.1安装VM"></a>1.1.1安装VM</h4><p><img src="/images/scrapy02/17561629196138_.pic_hd.jpg" alt="17561629196138_.pic_hd"></p><p><img src="/images/scrapy02/17561629196138_.pic.jpg" alt="17561629196138_.pic"></p><p><img src="/images/scrapy02/17581629196184_.pic.jpg" alt="17581629196184_.pic"></p><p><img src="/images/scrapy02/17571629196155_.pic-9199960.jpg" alt="17571629196155_.pic"></p><p><img src="/images/scrapy02/17581629196184_.pic-9199973.jpg" alt="17581629196184_.pic"></p><p><img src="/images/scrapy02/17591629196208_.pic.jpg" alt="17591629196208_.pic"></p><p><img src="/images/scrapy02/17601629196228_.pic.jpg" alt="17601629196228_.pic"></p><p><img src="/images/scrapy02/17611629196237_.pic.jpg" alt="17611629196237_.pic"></p><p><img src="/images/scrapy02/17621629196250_.pic_hd.jpg" alt="17621629196250_.pic_hd"></p><p><img src="/images/scrapy02/17631629196343_.pic_hd.jpg" alt="17631629196343_.pic_hd"></p><p><img src="/images/scrapy02/17641629196362_.pic_hd.jpg" alt="17641629196362_.pic_hd"></p><p><img src="/images/scrapy02/17651629196369_.pic_hd.jpg" alt="17651629196369_.pic_hd"></p><p><img src="/images/scrapy02/17661629196398_.pic_hd.jpg" alt="17661629196398_.pic_hd"></p><p><img src="/images/scrapy02/17671629196461_.pic_hd.jpg" alt="17671629196461_.pic_hd"></p><p><img src="/images/scrapy02/17681629196491_.pic_hd.jpg" alt="17681629196491_.pic_hd"></p><p><img src="/images/scrapy02/17691629196532_.pic_hd.jpg" alt="17691629196532_.pic_hd"></p><p><img src="/images/scrapy02/17701629196571_.pic_hd.jpg" alt="17701629196571_.pic_hd"></p><p><img src="/images/scrapy02/17711629196622_.pic_hd.jpg" alt="17711629196622_.pic_hd"></p><p><img src="/images/scrapy02/17721629196663_.pic_hd.jpg" alt="17721629196663_.pic_hd"></p><p><img src="/images/scrapy02/17731629196679_.pic_hd.jpg" alt="17731629196679_.pic_hd"></p><h4 id="1-1-2-安装Linux"><a href="#1-1-2-安装Linux" class="headerlink" title="1.1.2 安装Linux"></a>1.1.2 安装Linux</h4><img src="image-20210817140222006.png" alt="image-20210817140222006" style="zoom:50%;" /><img src="image-20210817140422074.png" alt="image-20210817140422074" style="zoom:40%;" /><img src="image-20210817140631614.png" alt="image-20210817140631614" style="zoom:40%;" /><img src="image-20210817140748141.png" alt="image-20210817140748141" style="zoom:40%;" /><img src="image-20210817140818074.png" alt="image-20210817140818074" style="zoom:40%;" /><img src="image-20210817140849908.png" alt="image-20210817140849908" style="zoom:40%;" /><img src="image-20210817140925752.png" alt="image-20210817140925752" style="zoom:40%;" /><img src="image-20210817141200195.png" alt="image-20210817141200195" style="zoom:50%;" /><img src="image-20210817141307223.png" alt="image-20210817141307223" style="zoom:50%;" /><img src="image-20210817141415716.png" alt="image-20210817141415716" style="zoom:40%;" /><img src="image-20210817141552531.png" alt="image-20210817141552531" style="zoom:40%;" /><img src="image-20210817141643259.png" alt="image-20210817141643259" style="zoom:40%;" /><img src="image-20210817141729496.png" alt="image-20210817141729496" style="zoom:40%;" /><img src="image-20210817141824889.png" alt="image-20210817141824889" style="zoom:40%;" /><img src="image-20210817141850749.png" alt="image-20210817141850749" style="zoom:40%;" /><img src="image-20210817142347367.png" alt="image-20210817142347367" style="zoom:40%;" /><img src="image-20210817142421655.png" alt="image-20210817142421655" style="zoom:50%;" /><img src="image-20210817142519453.png" alt="image-20210817142519453" style="zoom:40%;" /><img src="image-20210817142634663.png" alt="image-20210817142634663" style="zoom:40%;" /><p>安装好的linux后,我们需要学会使用linux的一个工具. 叫yum, 我们需要用它来帮我们完成各种软件的安装. 十分的方便. 我们先用<code>ifconfig</code>来做一个测试. </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum search ifconfig   // 搜索出ifconfig的包</span><br><span class="line"></span><br><span class="line">yum install net-tools.x86_64  // 安装该软件, 安装过程中会出现很多个询问. 直接y即可</span><br></pre></td></tr></table></figure><p>发现了吧, 在linux这个破黑窗口里. 属实难受+憋屈. 所以, 我们这里选择用ssh远程连接linux. </p><p>mac版本:  打开终端. 输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh root@服务器ip地址</span><br><span class="line">输入密码</span><br></pre></td></tr></table></figure><p>就可以顺利的链接到你的linux服务器. 接下来. 我们可以使用各种命令来操纵linux了. </p><p>Windows: </p><p><img src="/images/scrapy02/17751629199547_.pic_hd.jpg" alt="17751629199547_.pic_hd"></p><p><img src="/images/scrapy02/17791629200276_.pic_hd.jpg" alt="17791629200276_.pic_hd"></p><p><img src="/images/scrapy02/17761629199585_.pic_hd.jpg" alt="17761629199585_.pic_hd"></p><p><img src="/images/scrapy02/17771629199596_.pic_hd.jpg" alt="17771629199596_.pic_hd"></p><p><img src="/images/scrapy02/17781629199688_.pic_hd.jpg" alt="17781629199688_.pic_hd"></p><h4 id="1-1-3-安装docker"><a href="#1-1-3-安装docker" class="headerlink" title="1.1.3 安装docker"></a>1.1.3 安装docker</h4><p>​安装docker就一条例命令就好了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@sylar-centos-2 ~]# yum install docker</span><br></pre></td></tr></table></figure><p>​配置docker的源. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@sylar-centos-2 ~]# vi /etc/docker/daemon.json</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入一下内容, 注意.先按<span class="string">&#x27;i&#x27;</span>, 更换为输入模式. 然后再填写内容</span></span><br><span class="line">&#123;</span><br><span class="line">&quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com/&quot;]</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存: 先按esc. 退出输入模式, 然后输入<span class="string">&quot;:wq&quot;</span> 表示写入, 退出. 就完事儿了</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@sylar-centos-2 ~]# systemctl start docker    # 启动docker</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@sylar-centos-2 ~]# docker ps      # 查看docker运行状态</span><br></pre></td></tr></table></figure><p>如需关闭或者重新启动docker:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker   # 停止docker服务</span><br><span class="line">systemctl restart docker  # 重启docker服务</span><br></pre></td></tr></table></figure><p>Vm -&gt; cenos -&gt; ssh -&gt; docker -&gt; splash </p><h4 id="1-1-4-安装splash"><a href="#1-1-4-安装splash" class="headerlink" title="1.1.4 安装splash"></a>1.1.4 安装splash</h4><ol><li><p>拉取splash镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull scrapinghub/splash</span><br></pre></td></tr></table></figure><p>splash比较大. 大概2个G左右. 有点儿耐心等会儿就好了</p></li><li><p>运行splash</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8050:8050 scrapinghub/splash</span><br></pre></td></tr></table></figure></li><li><p>打开浏览器访问splash</p><p><a href="http://192.168.31.82:8050/">http://192.168.31.82:8050/</a></p><p><img src="/images/scrapy02/image-20210817153337076.png" alt="image-20210817153337076"></p></li></ol><h3 id="1-2-splash简单使用"><a href="#1-2-splash简单使用" class="headerlink" title="1.2 splash简单使用"></a>1.2 splash简单使用</h3><p>​我们可以在文本框内输入百度的网址. 然后点击render. 可以看到splash会对我们的网页进行动态的加载. 并返回截图. 运行状况. 以及页面代码(经过js渲染后的)</p><p><img src="/images/scrapy02/image-20210817153704882.png" alt="image-20210817153704882"></p><p><img src="/images/scrapy02/image-20210817153711026.png" alt="image-20210817153711026"></p><p>快速解释一下, script中的脚本. 这里面用的是lua的脚本语法. 所以看起来会有些难受. </p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span>  <span class="comment">-- 主函数</span></span><br><span class="line">  <span class="built_in">assert</span>(splash:go(args.url))  <span class="comment">-- 进入xxx页面</span></span><br><span class="line">  <span class="built_in">assert</span>(splash:wait(<span class="number">0.5</span>))   <span class="comment">-- 等待0.5秒</span></span><br><span class="line">  <span class="keyword">return</span> &#123;  <span class="comment">-- 返回</span></span><br><span class="line">    html = splash:html(),  <span class="comment">-- splash:html() 页面源代码</span></span><br><span class="line">    png = splash:png(),   <span class="comment">-- splash:png() 页面截图</span></span><br><span class="line">    har = splash:har(),   <span class="comment">-- splash:har() 页面加载过程</span></span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">end</span>   <span class="comment">-- 函数结束</span></span><br></pre></td></tr></table></figure><p>有必要说明一下. 在lua中, <code>.</code>表示的是属性(变量), <code>:</code>表示的是方法(函数)的调用. </p><p>常见操作符都一样. 剩下的. 我们到案例里看. </p><h3 id="1-3-splash的http-api接口"><a href="#1-3-splash的http-api接口" class="headerlink" title="1.3 splash的http-api接口"></a>1.3 splash的http-api接口</h3><p>splash提供了对外的http-api接口. 我们可以像访问一个普通url一样访问splash. 并由splash帮助我们渲染好页面内容. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://<span class="number">192.168</span><span class="number">.31</span><span class="number">.82</span>:<span class="number">8050</span>/render.html?url=http://www.baidu.com</span><br></pre></td></tr></table></figure><p>虽然看不出任何差别. 但是你心里要清楚一个事情. 此时拿到的直接是经过js渲染后的html</p><p>我们换个url你就知道了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://<span class="number">192.168</span><span class="number">.31</span><span class="number">.82</span>:<span class="number">8050</span>/render.html?url=https://www.endata.com.cn/BoxOffice/BO/Year/index.html&amp;wait=<span class="number">5</span></span><br></pre></td></tr></table></figure><p>endata这个网站. 它的数据是后期经过ajax请求二次加载进来的. 我们通过splash可以等待它后期加载完再拿html. </p><p>综上, splash的工作机制:</p><p><img src="/images/scrapy02/image-20210817155156714.png" alt="image-20210817155156714"></p><p>整个一个代理服务器的逻辑. ~~~~</p><h2 id="二-python中使用splash"><a href="#二-python中使用splash" class="headerlink" title="二. python中使用splash"></a>二. python中使用splash</h2><h3 id="2-1-splash在python中如何使用"><a href="#2-1-splash在python中如何使用" class="headerlink" title="2.1 splash在python中如何使用"></a>2.1 splash在python中如何使用</h3><p>既然splash提供了http-api接口. 那我们就可以像请求普通网站一样去请求到splash.<br>在python中, 我们最熟悉的能发送http请求的东西就是requests了. </p><p>接下来.我们就用requests来完成splash的对接. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># splash提供的api接口</span></span><br><span class="line"><span class="string">渲染html的接口</span></span><br><span class="line"><span class="string">http://192.168.31.184:8050/render.html?url=你的url&amp;wait=等待时间&amp;time_out=超时时间</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">截图的接口</span></span><br><span class="line"><span class="string">http://192.168.31.184:8050/render.png  参数和render.html基本一致, 可选width, height</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">加载过程接口</span></span><br><span class="line"><span class="string">http://192.168.31.184:8050/render.har  参数和render.html基本一致</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">json接口</span></span><br><span class="line"><span class="string">http://192.168.31.184:8050/render.json  参数和render.html基本一致</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">执行lua脚本的接口</span></span><br><span class="line"><span class="string">http://192.168.31.184:8050/execute?lua_source=你要执行的lua脚本</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最简单的调用splash的render.html</span></span><br><span class="line">url = <span class="string">&quot;http://192.168.31.184:8050/render.html?url=https://www.baidu.com&amp;wait=5&quot;</span></span><br><span class="line">resp = requests.get(url)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure><h3 id="2-2-我们以网易新闻首页要闻为例"><a href="#2-2-我们以网易新闻首页要闻为例" class="headerlink" title="2.2 我们以网易新闻首页要闻为例."></a>2.2 我们以网易新闻首页<code>要闻</code>为例.</h3><p>先搞定脚本部分.</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">    <span class="built_in">assert</span>(splash:go(args.url))</span><br><span class="line">    <span class="built_in">assert</span>(splash:wait(<span class="number">1</span>))</span><br><span class="line">    <span class="comment">-- 加载一段js, 后面作为lua函数进行调用. </span></span><br><span class="line">    <span class="comment">-- 在这个脚本中, 主要返回了&quot;加载更多&quot;按钮的状态</span></span><br><span class="line">    get_display_style = splash:jsfunc(<span class="string">[[</span></span><br><span class="line"><span class="string">      function()&#123;</span></span><br><span class="line"><span class="string">        return document.getElementsByClassName(&#x27;load_more_btn&#x27;)[0].style.display;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    ]]</span>)</span><br><span class="line">    <span class="comment">-- lua中的循环语句. 和python的while功能一样. </span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">do</span>  <span class="comment">-- 语法规定. 相当于开始</span></span><br><span class="line">        <span class="comment">-- 直接运行js代码, 滚动到&#x27;加载更多&#x27;按钮</span></span><br><span class="line">        splash:runjs(<span class="string">&quot;document.getElementsByClassName(&#x27;load_more_btn&#x27;)[0].scrollIntoView(true)&quot;</span>)</span><br><span class="line">        <span class="comment">-- 等待</span></span><br><span class="line">        splash:wait(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">-- 找到该按钮. 点击它</span></span><br><span class="line">        splash:<span class="built_in">select</span>(<span class="string">&quot;.load_more_btn&quot;</span>).click()</span><br><span class="line">        <span class="comment">-- 调用上方预制的js脚本, 获取&#x27;正在加载按钮&#x27;的状态</span></span><br><span class="line">        display_style = get_display_style()</span><br><span class="line">        <span class="comment">-- 如果不显示了. 也就结束了</span></span><br><span class="line">        <span class="keyword">if</span>(display_style== <span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">            <span class="keyword">break</span>  <span class="comment">-- 同python中的break. 打断循环</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="built_in">assert</span>(splash:wait(<span class="number">2</span>)) <span class="comment">-- 不在乎多等2秒</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        html = splash:html(),</span><br><span class="line">        png = splash:png(),</span><br><span class="line">        har = splash:har(),</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>到了python里面就可以使用这个脚本了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行lua脚本</span></span><br><span class="line">lua = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">function main(splash, args)</span></span><br><span class="line"><span class="string">    assert(splash:go(args.url))</span></span><br><span class="line"><span class="string">    assert(splash:wait(0.5))</span></span><br><span class="line"><span class="string">    -- 加载一段js, 后面作为lua函数进行调用. </span></span><br><span class="line"><span class="string">    -- 在这个脚本中, 主要返回了&quot;加载更多&quot;按钮的状态</span></span><br><span class="line"><span class="string">    get_display_style = splash:jsfunc([[</span></span><br><span class="line"><span class="string">      function()&#123;</span></span><br><span class="line"><span class="string">        return document.getElementsByClassName(&#x27;load_more_btn&#x27;)[0].style.display;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    ]])</span></span><br><span class="line"><span class="string">    -- lua中的循环语句. 和python的while功能一样. </span></span><br><span class="line"><span class="string">    while (true)</span></span><br><span class="line"><span class="string">    do  -- 语法规定. 相当于开始</span></span><br><span class="line"><span class="string">        -- 直接运行js代码, 滚动到&#x27;加载更多&#x27;按钮</span></span><br><span class="line"><span class="string">        splash:runjs(&quot;document.getElementsByClassName(&#x27;load_more_btn&#x27;)[0].scrollIntoView(true)&quot;)</span></span><br><span class="line"><span class="string">        -- 等待</span></span><br><span class="line"><span class="string">        splash:wait(1)</span></span><br><span class="line"><span class="string">        -- 找到该按钮. 点击它</span></span><br><span class="line"><span class="string">        splash:select(&quot;.load_more_btn&quot;).click()</span></span><br><span class="line"><span class="string">        -- 调用上方预制的js脚本, 获取&#x27;正在加载按钮&#x27;的状态</span></span><br><span class="line"><span class="string">        display_style = get_display_style()</span></span><br><span class="line"><span class="string">        -- 如果不显示了. 也就结束了</span></span><br><span class="line"><span class="string">        if(display_style== &#x27;none&#x27;)</span></span><br><span class="line"><span class="string">        then</span></span><br><span class="line"><span class="string">            break  -- 同python中的break. 打断循环</span></span><br><span class="line"><span class="string">        end</span></span><br><span class="line"><span class="string">    end</span></span><br><span class="line"><span class="string">    assert(splash:wait(2)) -- 不在乎多等2秒</span></span><br><span class="line"><span class="string">    return &#123;</span></span><br><span class="line"><span class="string">        html = splash:html(),    -- 拿到页面源代码</span></span><br><span class="line"><span class="string">        cookies = splash:get_cookies()  -- 拿到cookies</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备能够执行lua脚本的url  -&gt; splash服务地址</span></span><br><span class="line">url = <span class="string">&quot;http://192.168.31.82:8050/execute&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 远程访问splash, 执行脚本</span></span><br><span class="line">resp = requests.get(url, params=&#123;</span><br><span class="line">    <span class="string">&quot;url&quot;</span>:<span class="string">&quot;https://news.163.com&quot;</span>,</span><br><span class="line">    <span class="string">&quot;lua_source&quot;</span>: lua</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">result = resp.json()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取结果</span></span><br><span class="line">tree = etree.HTML(result.get(<span class="string">&#x27;html&#x27;</span>))</span><br><span class="line"><span class="comment"># print(resp.text)</span></span><br><span class="line">divs = tree.xpath(<span class="string">&quot;//ul[@class=&#x27;newsdata_list fixed_bar_padding noloading&#x27;]/li[1]/div[2]/div&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> div <span class="keyword">in</span> divs:</span><br><span class="line">    a = div.xpath(<span class="string">&quot;./div/div/h3/a&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> a:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    a = a[<span class="number">0</span>]</span><br><span class="line">    href = a.xpath(<span class="string">&#x27;./@href&#x27;</span>)</span><br><span class="line">    title = a.xpath(<span class="string">&#x27;./text()&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(title, href)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result.get(<span class="string">&quot;cookies&quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>##三. scrapy_splash</p><p>安装scrapy_splash模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy_splash</span><br></pre></td></tr></table></figure><p>创建一个普通的scrapy项目, 然后把scrapy_splash配置到settings文件中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line">USER_AGENT = <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># scrapy_splash</span></span><br><span class="line"><span class="comment"># 渲染服务的url, 这里换成你自己的</span></span><br><span class="line">SPLASH_URL = <span class="string">&#x27;http://192.168.31.82:8050&#x27;</span></span><br><span class="line"><span class="comment"># 下载器中间件, 这个必须要配置</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashCookiesMiddleware&#x27;</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashMiddleware&#x27;</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#x27;</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个可由可无</span></span><br><span class="line"><span class="comment"># SPIDER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#     &#x27;scrapy_splash.SplashDeduplicateArgsMiddleware&#x27;: 100,</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"><span class="comment"># 去重过滤器, 这个必须要配置</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&#x27;scrapy_splash.SplashAwareDupeFilter&#x27;</span></span><br><span class="line"><span class="comment"># 使用Splash的Http缓存, 这个必须要配置</span></span><br><span class="line">HTTPCACHE_STORAGE = <span class="string">&#x27;scrapy_splash.SplashAwareFSCacheStorage&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最后. 整理修改一下spider</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy_splash.request <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># splash的lua脚本</span></span><br><span class="line">lua_source = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">function main(splash, args)  -- 主函数</span></span><br><span class="line"><span class="string">    assert(splash:go(&quot;https://news.163.com/&quot;))  -- 访问url</span></span><br><span class="line"><span class="string">    assert(splash:wait(2))  -- 等待</span></span><br><span class="line"><span class="string">    -- 预存一个js函数</span></span><br><span class="line"><span class="string">    get_btn_display = splash:jsfunc([[</span></span><br><span class="line"><span class="string">        function()&#123;</span></span><br><span class="line"><span class="string">            return document.getElementsByClassName(&#x27;load_more_btn&#x27;)[0].style.display;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]])</span></span><br><span class="line"><span class="string">    -- lua的while循环</span></span><br><span class="line"><span class="string">    while(true)</span></span><br><span class="line"><span class="string">    do</span></span><br><span class="line"><span class="string">        -- 直接执行一个js脚本</span></span><br><span class="line"><span class="string">        -- 向下拉动滚动条. </span></span><br><span class="line"><span class="string">        splash:runjs(&quot;document.getElementsByClassName(&#x27;load_more_btn&#x27;)[0].scrollIntoView(true)&quot;)</span></span><br><span class="line"><span class="string">        assert(splash:wait(1))</span></span><br><span class="line"><span class="string">        -- 选择 &quot;加载更多&quot;</span></span><br><span class="line"><span class="string">        btn = splash:select(&quot;.load_more_btn&quot;)</span></span><br><span class="line"><span class="string">        -- 点它</span></span><br><span class="line"><span class="string">        btn:click()</span></span><br><span class="line"><span class="string">        -- 判断是否可见 调用上方预制的js函数</span></span><br><span class="line"><span class="string">        ss = get_btn_display()</span></span><br><span class="line"><span class="string">        -- 如果是none. 就没有数据了(网易自己设计的)</span></span><br><span class="line"><span class="string">        if (ss == &#x27;none&#x27;)</span></span><br><span class="line"><span class="string">        then</span></span><br><span class="line"><span class="string">            break</span></span><br><span class="line"><span class="string">        end</span></span><br><span class="line"><span class="string">    end</span></span><br><span class="line"><span class="string">    return &#123;</span></span><br><span class="line"><span class="string">        html = splash:html(),</span></span><br><span class="line"><span class="string">        cookies = splash:get_cookies()</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    end</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WangyiSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;wangyi&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;163.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://news.163.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 发送splash请求</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(</span><br><span class="line">            url=self.start_urls[<span class="number">0</span>],</span><br><span class="line">            callback=self.parse,</span><br><span class="line">            endpoint=<span class="string">&quot;execute&quot;</span>,</span><br><span class="line">            args=&#123;<span class="string">&quot;lua_source&quot;</span>: lua_source, &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        divs = resp.xpath(<span class="string">&quot;//ul[@class=&#x27;newsdata_list fixed_bar_padding noloading&#x27;]/li[1]/div[2]/div&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> divs:</span><br><span class="line">            a = div.xpath(<span class="string">&quot;./div/div/h3/a&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> a:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            href = a.xpath(<span class="string">&#x27;./@href&#x27;</span>).extract_first()</span><br><span class="line">            title = a.xpath(<span class="string">&#x27;./text()&#x27;</span>).extract_first()</span><br><span class="line">            <span class="built_in">print</span>(href)</span><br><span class="line">            <span class="comment"># 可以采用正常的抓取方案</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                url=href,</span><br><span class="line">                callback=self.details</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">details</span>(<span class="params">self, resp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data.txt&quot;</span>, mode=<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&quot;____&quot;</span>.join(resp.xpath(<span class="string">&quot;//div[@class=&#x27;post_body&#x27;]//p/text()&quot;</span>).extract()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="爬虫开发" scheme="http://blog.ioimp.top/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Scrapy爬虫" scheme="http://blog.ioimp.top/tags/Scrapy%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Scarpy_分布式爬虫</title>
    <link href="http://blog.ioimp.top/2023/12/03/Scarpy-%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB/"/>
    <id>http://blog.ioimp.top/2023/12/03/Scarpy-%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB/</id>
    <published>2023-12-03T03:59:26.000Z</published>
    <updated>2023-12-03T04:04:23.779Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="分布式爬虫"><a href="#分布式爬虫" class="headerlink" title="分布式爬虫"></a>分布式爬虫</h1><h2 id="一-增量式爬虫"><a href="#一-增量式爬虫" class="headerlink" title="一. 增量式爬虫"></a>一. 增量式爬虫</h2><p>​增量式爬虫, 顾名思义. 可以对网站进行反复抓取. 然后发现新东西了就保存起来. 遇到了以前抓取过的内容就自动过滤掉即可. 其核心思想就两个字. 去重. 并且可以反复去重. 今天运行一下. 明天再运行一下. 将不同的数据过滤出来. 相同的数据去除掉(不保存)即可. </p><p>​此时, 我们以天涯为目标来尝试一下完成增量式爬虫. </p><p>spider: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> Redis</span><br><span class="line"><span class="keyword">from</span> tianya.items <span class="keyword">import</span> TianyaItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TySpider</span>(scrapy.Spider):</span><br><span class="line"></span><br><span class="line">    name = <span class="string">&#x27;ty&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;tianya.cn&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://bbs.tianya.cn/list-worldlook-1.shtml&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        self.red = Redis(password=<span class="string">&quot;123456&quot;</span>, db=<span class="number">6</span>, decode_responses=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">super</span>().__init__(name, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        tbodys = resp.css(<span class="string">&quot;.tab-bbs-list tbody&quot;</span>)[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">for</span> tbody <span class="keyword">in</span> tbodys:</span><br><span class="line">            hrefs = tbody.xpath(<span class="string">&quot;./tr/td[1]/a/@href&quot;</span>).extract()</span><br><span class="line">            <span class="keyword">for</span> h <span class="keyword">in</span> hrefs:</span><br><span class="line">                <span class="comment"># 两个方案.</span></span><br><span class="line">                url = resp.urljoin(h)</span><br><span class="line">                <span class="comment"># 判断是否在该set集合中有数据</span></span><br><span class="line">                r = self.red.sismember(<span class="string">&quot;tianya:details&quot;</span>, url)  </span><br><span class="line">                <span class="comment">#   1. url去重. 优点: 简单, 缺点: 如果有人回复了帖子.就无法提取到最新的数据了</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> r:</span><br><span class="line">                    <span class="keyword">yield</span> scrapy.Request(url=resp.urljoin(h), callback=self.parse_details)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;该url已经被抓取过<span class="subst">&#123;url&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        next_href = resp.xpath(<span class="string">&quot;//div[@class=&#x27;short-pages-2 clearfix&#x27;]/div[@class=&#x27;links&#x27;]/a[last()]/@href&quot;</span>).extract_first()</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=resp.urljoin(next_href), callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_details</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        title = resp.xpath(<span class="string">&#x27;//*[@id=&quot;post_head&quot;]/h1/span[1]/span/text()&#x27;</span>).extract_first()</span><br><span class="line">        content = resp.xpath(<span class="string">&#x27;//*[@id=&quot;bd&quot;]/div[4]/div[1]/div/div[2]/div[1]/text()&#x27;</span>).extract_first()</span><br><span class="line">        item = TianyaItem()</span><br><span class="line">        item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">        item[<span class="string">&#x27;content&#x27;</span>] = content</span><br><span class="line">        <span class="comment"># 提取完数据. 该url进入redis</span></span><br><span class="line">        self.red.sadd(<span class="string">&quot;tianya:details&quot;</span>, resp.url)  </span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​pipelines</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> Redis</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TianyaPipeline</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="comment">#   2. 数据内容去重. 优点: 保证数据的一致性. 缺点: 需要每次都把数据从网页中提取出来</span></span><br><span class="line">        <span class="built_in">print</span>(json.dumps(<span class="built_in">dict</span>(item)))</span><br><span class="line">        r = self.red.sadd(<span class="string">&quot;tianya:pipelines:items&quot;</span>, json.dumps(<span class="built_in">dict</span>(item)))</span><br><span class="line">        <span class="keyword">if</span> r:</span><br><span class="line">            <span class="comment"># 进入数据库</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;存入数据库&quot;</span>, item[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;已经在数据里了&quot;</span>, item[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.red = Redis(password=<span class="string">&quot;123456&quot;</span>, db=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.red.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上述方案是直接用redis进行的去重. 我们还可以选择使用数据库, mongodb进行过滤. 原理都一样, 不在赘述. </p><h2 id="二-分布式爬虫"><a href="#二-分布式爬虫" class="headerlink" title="二. 分布式爬虫"></a>二. 分布式爬虫</h2><p>​分布式爬虫, 就是搭建一个分布式的集群, 让其对一组资源进行分布联合爬取. </p><p>​既然要集群来抓取. 意味着会有好几个爬虫同时运行. 那此时就非常容易产生这样一个问题. 如果有重复的url怎么办?  在原来的程序中. scrapy中会由调度器来自动完成这个任务. 但是, 此时是多个爬虫一起跑. 而我们又知道不同的机器之间是不能直接共享调度器的. 怎么办? 我们可以采用redis来作为各个爬虫的调度器. 此时我们引出一个新的模块叫scrapy-redis. 在该模块中提供了这样一组操作. 它们重写了scrapy中的调度器. 并将调度队列和去除重复的逻辑全部引入到了redis中. 这样就形成了这样一组结构</p><p><img src="/images/scrapy02/image-20210812152215427.png" alt="image-20210812152215427"></p><p>​整体工作流程:</p><pre><code>1. 某个爬虫从redis_key获取到起始url. 传递给引擎, 到调度器. 然后把起始url直接丢到redis的请求队列里. 开始了scrapy的爬虫抓取工作.  2. 如果抓取过程中产生了新的请求. 不论是哪个节点产生的, 最终都会到redis的去重集合中进行判定是否抓取过. 3. 如果抓取过. 直接就放弃该请求. 如果没有抓取过. 自动丢到redis请求队列中. 4. 调度器继续从redis请求队列里获取要进行抓取的请求. 完成爬虫后续的工作. </code></pre><p>接下来. 我们用scrapy-redis完成上述流程</p><ol><li><p>首先, 创建项目, 和以前一样, 该怎么创建还怎么创建. </p></li><li><p>修改Spider. 将start_urls注释掉. 更换成redis_key</p></li><li><p>然后再settings中对redis以及scrapy_redis配置一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">REDIS_HOST = <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">REDIS_PORT = <span class="number">6379</span></span><br><span class="line">REDIS_DB = <span class="number">8</span></span><br><span class="line">REDIS_PARAMS = &#123;</span><br><span class="line">    <span class="string">&quot;password&quot;</span>:<span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># scrapy-redis配置信息  # 固定的</span></span><br><span class="line">SCHEDULER = <span class="string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span></span><br><span class="line">SCHEDULER_PERSIST = <span class="literal">True</span>  <span class="comment"># 如果为真. 在关闭时自动保存请求信息, 如果为假, 则不保存请求信息</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span> <span class="comment"># 去重的逻辑. 要用redis的</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;tianya2.pipelines.Tianya2Pipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy_redis.pipelines.RedisPipeline&#x27;</span>: <span class="number">301</span>  <span class="comment"># 配置redis的pipeline</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><p>布隆过滤器:</p><p>​平时, 我们如果需要对数据进行去重操作可以有以下方案: </p><pre><code>1. 直接用set集合来存储url. (最low的方案)2. 用set集合存储hash过的url. scrapy默认3. 用redis来存储hash过的请求, scrapy-redis默认就是这样做的. 如果请求非常非常多. redis压力是很大的.4. 用布隆过滤器. </code></pre><p>布隆过滤器的原理: 其实它里面就是一个改良版的bitmap. 何为bitmap, 假设我提前准备好一个数组, 然后把源数据经过hash计算. 会计算出一个数字. 我们按照下标来找到该下标对应的位置. 然后设置成1. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = 李嘉诚</span><br><span class="line">b = 张翠山</span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]  <span class="number">10</span>个长度数组</span><br><span class="line"></span><br><span class="line"><span class="built_in">hash</span>(a) = <span class="number">3</span></span><br><span class="line"><span class="built_in">hash</span>(b) = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>] </span><br><span class="line"><span class="built_in">hash</span>(张三) = <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找的时候依然执行该hash算法. 然后直接去找对应下标的位置看看是不是1. 是1就有, 不是1就没有</span></span><br></pre></td></tr></table></figure><p>这样有个不好的现象. 容易误判. 如果hash算法选的不够好. 很容易搞错. 那怎么办. 多选几个hash算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">a = 李嘉诚</span><br><span class="line">b = 张翠山</span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">hash1(a) = <span class="number">3</span></span><br><span class="line">hash2(a) = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">hash1(b) = <span class="number">2</span></span><br><span class="line">hash2(b) = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找的时候, 重新按照这个hash的顺序, 在重新执行一遍. 依然会得到2个值. 分别去这两个位置看是否是1. 如果全是1, 就有,  如果有一个是0, 就没有. </span></span><br></pre></td></tr></table></figure><p>在scrapy-redis中想要使用布隆过滤器是非常简单的. 你可以自己去写这个布隆过滤器的逻辑. 不过我建议直接用第三方的就可以了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装布隆过滤器</span></span><br><span class="line">pip install scrapy_redis_bloomfilter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去重类，要使用 BloomFilter 请替换 DUPEFILTER_CLASS</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&quot;scrapy_redis_bloomfilter.dupefilter.RFPDupeFilter&quot;</span></span><br><span class="line"><span class="comment"># 哈希函数的个数，默认为 6，可以自行修改</span></span><br><span class="line">BLOOMFILTER_HASH_NUMBER = <span class="number">6</span></span><br><span class="line"><span class="comment"># BloomFilter 的 bit 参数，默认 30，占用 128MB 空间，去重量级 1 亿</span></span><br><span class="line">BLOOMFILTER_BIT = <span class="number">30</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="爬虫开发" scheme="http://blog.ioimp.top/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Scrapy爬虫" scheme="http://blog.ioimp.top/tags/Scrapy%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>crawlSpider</title>
    <link href="http://blog.ioimp.top/2023/12/03/crawlSpider/"/>
    <id>http://blog.ioimp.top/2023/12/03/crawlSpider/</id>
    <published>2023-12-03T03:58:31.000Z</published>
    <updated>2023-12-03T03:59:08.333Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Scrapy抓取全网站数据"><a href="#Scrapy抓取全网站数据" class="headerlink" title="Scrapy抓取全网站数据"></a>Scrapy抓取全网站数据</h1><h2 id="一-使用常规Spider"><a href="#一-使用常规Spider" class="headerlink" title="一. 使用常规Spider"></a>一. 使用常规Spider</h2><p>我们把目光对准汽车之家. 抓取二手车信息.</p><p>注意, 汽车之家的访问频率要控制一下. 要不然会跳验证的. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOAD_DELAY = <span class="number">3</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ErshouSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;ershou&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;che168.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.che168.com/beijing/a0_0msdgscncgpi1ltocsp100exx0/?pvareaid=102179#currengpostion&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        <span class="comment"># print(resp.text)</span></span><br><span class="line">        <span class="comment"># 链接提取器</span></span><br><span class="line">        le = LinkExtractor(restrict_xpaths=(<span class="string">&quot;//ul[@class=&#x27;viewlist_ul&#x27;]/li/a&quot;</span>,), deny_domains=(<span class="string">&quot;topicm.che168.com&quot;</span>,) )</span><br><span class="line">        links = le.extract_links(resp)</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                url=link.url,</span><br><span class="line">                callback=self.parse_detail</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 翻页功能</span></span><br><span class="line">        le2 = LinkExtractor(restrict_xpaths=(<span class="string">&quot;//div[@id=&#x27;listpagination&#x27;]/a&quot;</span>,))</span><br><span class="line">        pages = le2.extract_links(resp)</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pages:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=page.url, callback=self.parse_detail)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        title = resp.xpath(<span class="string">&#x27;/html/body/div[5]/div[2]/h3/text()&#x27;</span>).extract_first()</span><br><span class="line">        <span class="built_in">print</span>(title)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>LinkExtractor: 链接提取器. 可以非常方便的帮助我们从一个响应页面中提取到url链接. 我们只需要提前定义好规则即可. </p><p>参数: </p><p>​allow, 接收一堆正则表达式, 可以提取出符合该正则的链接<br>​deny, 接收一堆正则表达式, 可以剔除符合该正则的链接<br>​allow_domains: 接收一堆域名, 符合里面的域名的链接被提取<br>​deny_domains: 接收一堆域名, 剔除不符合该域名的链接<br>​restrict_xpaths: 接收一堆xpath, 可以提取符合要求xpath的链接<br>​restrict_css: 接收一堆css选择器, 可以提取符合要求的css选择器的链接<br>​tags: 接收一堆标签名, 从某个标签中提取链接, 默认a, area<br>​attrs: 接收一堆属性名, 从某个属性中提取链接, 默认href</p><p>值得注意的, &#x3D;&#x3D;在提取到的url中, 是有重复的内容的. 但是我们不用管. scrapy会自动帮我们过滤掉重复的url请求.&#x3D;&#x3D; </p><h2 id="二-使用CrawlSpider"><a href="#二-使用CrawlSpider" class="headerlink" title="二. 使用CrawlSpider"></a>二. 使用CrawlSpider</h2><p>在scrapy中提供了CrawlSpider来完成全站数据抓取. </p><ol><li><p>创建项目</p><p><code>scrapy startproject qichezhijia</code></p></li><li><p>进入项目</p><p><code>cd qichezhijia</code></p></li><li><p>创建爬虫(CrawlSpider)</p><p><code>scrapy genspider </code>&#x3D;&#x3D;-t crawl&#x3D;&#x3D;<code> ershouche che168.com</code></p><p>和以往的爬虫不同. 该爬虫需要用到crawl的模板来创建爬虫. </p></li><li><p>修改spider中的rules和回调函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ErshoucheSpider</span>(<span class="title class_ inherited__">CrawlSpider</span>):</span><br><span class="line">    name = <span class="string">&#x27;ershouche&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;che168.com&#x27;</span>, <span class="string">&#x27;autohome.com.cn&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.che168.com/beijing/a0_0msdgscncgpi1ltocsp1exx0/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    le = LinkExtractor(restrict_xpaths=(<span class="string">&quot;//ul[@class=&#x27;viewlist_ul&#x27;]/li/a&quot;</span>,), deny_domains=(<span class="string">&quot;topicm.che168.com&quot;</span>,) )</span><br><span class="line">    le1 = LinkExtractor(restrict_xpaths=(<span class="string">&quot;//div[@id=&#x27;listpagination&#x27;]/a&quot;</span>,))</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(le1, follow=<span class="literal">True</span>),  <span class="comment"># 单纯为了做分页</span></span><br><span class="line">        Rule(le, callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">False</span>), <span class="comment"># 单纯提取数据</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_item</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="built_in">print</span>(response.url)</span><br></pre></td></tr></table></figure><p>CrawlSpider的工作流程. </p><p>前期和普通的spider是一致的. 在第一次请求回来之后. 会自动的将返回的response按照rules中订制的规则来提取链接. 并进一步执行callback中的回调. 如果follow是True, 则继续在响应的内容中继续使用该规则提取链接.  相当于在parse中的scrapy.request(xxx, callback&#x3D;self.parse)</p></li></ol><h2 id="三-Redis简单使用"><a href="#三-Redis简单使用" class="headerlink" title="三. Redis简单使用"></a>三. Redis简单使用</h2><p>​redis作为一款目前这个星球上性能最高的非关系型数据库之一. 拥有每秒近十万次的读写能力. 其实力只能用恐怖来形容. </p><ol><li><p>安装redis</p><p>redis是我见过这个星球上最好安装的软件了. 比起前面的那一坨. 它简直了…</p><p>直接把压缩包解压. 然后配置一下环境变量就可以了. </p><p><img src="/images/scrapy01/image-20210810184227132.png" alt="images/scrapy01/image-20210810184227132"></p><p><img src="/images/scrapy01/image-20210810184318301.png" alt="images/scrapy01/image-20210810184318301"></p><p>接下来, 在环境变量中将该文件夹配置到path中. </p><p><img src="/images/scrapy01/image-20210810184649037.png" alt="images/scrapy01/image-20210810184649037"></p><p>win7的同学自求多福吧…</p><p>我们给redis多配置几个东西(修改redis的配置文件, mac是: redis.conf, windows是: )</p><ol><li><p>关闭bind</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bind 127.0.0.1 ::1  # 注释掉它</span></span><br></pre></td></tr></table></figure></li><li><p>关闭保护模式  windows不用设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protected-mode no    <span class="comment"># 设置为no</span></span><br></pre></td></tr></table></figure></li><li><p>设置密码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requirepass <span class="number">123456</span>   <span class="comment"># 设置密码</span></span><br></pre></td></tr></table></figure></li></ol><p>将redis怼到windows服务&#x3D;&#x3D;必须进入到redis目录后才可以&#x3D;&#x3D;</p><p><img src="/images/scrapy01/image-20210810185306517.png" alt="images/scrapy01/image-20210810185306517"></p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 将redis安装到windows服务</span><br><span class="line">redis-server.exe --service-install redis.windows.conf --loglevel verbose</span><br><span class="line"># 卸载服务：</span><br><span class="line">redis-server --service-uninstall</span><br><span class="line"># 开启服务：</span><br><span class="line">redis-server --service-<span class="built_in">start</span></span><br><span class="line"># 停止服务：</span><br><span class="line">redis-server --service-stop</span><br></pre></td></tr></table></figure><p>使用redis-cli链接redis</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h ip地址 -p 端口 --raw   <span class="comment"># raw可以让redis显示出中文</span></span><br><span class="line">auth 密码   <span class="comment"># 如果有密码可以这样来登录, 如果没有.不用这一步</span></span><br></pre></td></tr></table></figure><p><img src="/images/scrapy01/image-20210810185605290.png" alt="images/scrapy01/image-20210810185605290"></p><p>附赠RDM, redis desktop manager. 可以帮我们完成redis数据库的可视化操作(需要就装, 不需要就算)</p><p><img src="/images/scrapy01/image-20210810185659813.png" alt="images/scrapy01/image-20210810185659813"></p></li><li><p>redis常见数据类型</p><p>redis中常见的数据类型有5个. </p><p>命令规则:  <code>命令 key 参数</code></p><ol><li><p>string</p><p>字符串(它自己认为是字符串, 我认为是任何东西. ), redis最基础的数据类型. </p><p>常用命令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> key value  <span class="comment"># 添加一条数据</span></span><br><span class="line">get key   <span class="comment"># 查看一条数据</span></span><br><span class="line">incr key       <span class="comment"># 让该key对应的数据自增1(原子性, 安全)</span></span><br><span class="line">incrby key count     <span class="comment"># 让该key对应的value自增 count </span></span><br><span class="line"><span class="built_in">type</span> key<span class="comment"># 查看数据类型(set进去的东西一律全是字符串)</span></span><br></pre></td></tr></table></figure><p>例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> name zhangsan  <span class="comment"># 添加数据  name = zhangsan</span></span><br><span class="line">get name<span class="comment"># 查看数据 zhangsan</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> age <span class="number">10</span></span><br><span class="line">get age <span class="comment"># 10</span></span><br><span class="line">incr age<span class="comment"># 11</span></span><br><span class="line">get age <span class="comment"># 11</span></span><br><span class="line">incrby age <span class="number">5</span><span class="comment"># 16</span></span><br></pre></td></tr></table></figure></li><li><p>hash</p><p>哈希, 相当于字典. </p><p>常见操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hset key k1 v1   <span class="comment"># 将k1, v1存储在key上</span></span><br><span class="line">hget key k1      <span class="comment"># 将key上的k1提取出来</span></span><br><span class="line">hmset key k1 v1 k2 v2 k3 v3....  <span class="comment"># 一次性将多个k,v存储在key</span></span><br><span class="line">hmget key k1 k2....<span class="comment"># 一次性将key中的k1, k2...提取出来</span></span><br><span class="line">hgetall key <span class="comment"># 一次性将key中所有内容全部提取</span></span><br><span class="line">hkeys key<span class="comment"># 将key中所有的k全部提取</span></span><br><span class="line">hvals key <span class="comment"># 将key中所有的v全部提取</span></span><br></pre></td></tr></table></figure><p>示例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HMSET stu <span class="built_in">id</span> <span class="number">1</span> name sylar age <span class="number">18</span></span><br><span class="line">HMGET stu name age   <span class="comment"># syalr 18</span></span><br><span class="line">HGETALL stu    <span class="comment"># id 1 name sylar age 18</span></span><br><span class="line">HKEYS stu <span class="comment"># id name age</span></span><br><span class="line">HVALS stu   <span class="comment"># 1 syalr 18</span></span><br></pre></td></tr></table></figure></li><li><p>list</p><p>列表, 底层是一个双向链表. 可以从左边和右边进行插入. 记住每次插入都要记得这货是个&#x3D;&#x3D;双向链表&#x3D;&#x3D;</p><p>常见操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">LPUSH key 数据<span class="number">1</span> 数据<span class="number">2</span> 数据<span class="number">3.</span>... <span class="comment"># 从左边插入数据</span></span><br><span class="line">RPUSH key 数据<span class="number">1</span> 数据<span class="number">2</span> 数据<span class="number">3.</span>... <span class="comment"># 从右边插入数据</span></span><br><span class="line">LRANGE key start stop     <span class="comment"># 从start到stop提取数据. </span></span><br><span class="line"></span><br><span class="line">LLEN key<span class="comment"># 返回key对应列表的长度</span></span><br><span class="line">LPOP key        <span class="comment"># 从左边删除一个.并返回被删除元素</span></span><br><span class="line">RPOP key<span class="comment"># 从右边删除一个.并返回被删除元素</span></span><br></pre></td></tr></table></figure><p>示例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">LPUSH banji yiban erban sanban siban</span><br><span class="line">LRANGE banji <span class="number">0</span> -<span class="number">1</span>   <span class="comment"># yiban erban sanban siban</span></span><br><span class="line">RPUSH ban ban1 ban2 ban3</span><br><span class="line">LRANGE ban <span class="number">0</span> -<span class="number">1</span>     <span class="comment"># ban1 ban2 ban3</span></span><br><span class="line">LPOP ban  <span class="comment"># ban1</span></span><br><span class="line">LLEN key  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure></li><li><p>set</p><p>set是无序的超大集合. 无序, 不重复. </p><p>常见操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SADD key 值   <span class="comment"># 向集合内存入数据</span></span><br><span class="line">SMEMBERS key  <span class="comment"># 查看集合内所有元素</span></span><br><span class="line">SCARD key <span class="comment"># 查看key中元素的个数</span></span><br><span class="line">SISMEMBER key val  <span class="comment"># 查看key中是否包含val</span></span><br><span class="line">SUNION key1 key2  <span class="comment"># 并集</span></span><br><span class="line">SDIFF key1 key2  <span class="comment"># 差集合, 在key1中, 但不在key2中的数据</span></span><br><span class="line">SINTER key1 key2 <span class="comment"># 计算交集, 在key1和key2中都出现了的</span></span><br><span class="line">SPOP key  <span class="comment"># 随机从key中删除一个数据</span></span><br><span class="line">SRANDMEMBER key count <span class="comment"># 随机从key中查询count个数据</span></span><br></pre></td></tr></table></figure><p>实例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SADD stars 柯震东 吴亦凡 张默 房祖名   <span class="comment"># 4</span></span><br><span class="line">SADD stars 吴亦凡    <span class="comment"># 0. 重复的数据是存储不进去的.</span></span><br><span class="line">SMEMBERS stars   <span class="comment"># 柯震东 吴亦凡 张默 房祖名</span></span><br><span class="line">SISMEMBER stars 吴亦凡  <span class="comment"># 吴亦凡在 stars里么?  1 在  0 不在</span></span><br><span class="line"></span><br><span class="line">SADD my 周杰伦 吴亦凡 房祖名  </span><br><span class="line">SINTER stars my  <span class="comment"># 计算交集  吴亦凡 房祖名</span></span><br><span class="line"></span><br><span class="line">SPOP my  <span class="comment"># 随机删除一个</span></span><br><span class="line">SRANDMEMEBER my <span class="number">2</span>   <span class="comment"># 从集合总随机查看2个</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>zset</p><p>有序集合, 有序集合中的内容也是不可以重复的. 并且存储的数据也是redis最基础的string数据. 但是在存储数据的同时还增加了一个score. 表示分值. redis就是通过这个score作为排序的规则的. </p><p>常用操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ZADD key s1 m1 s2 m2 ... <span class="comment"># 向key中存入 m1 m2 分数分别为s1 s2</span></span><br><span class="line">ZRANGE key start stop [withscores]   <span class="comment"># 查看从start 到stop中的所有数据 [是否要分数]</span></span><br><span class="line">ZREVRANGE key start stop <span class="comment"># 倒叙查看start到stop的数据</span></span><br><span class="line">ZCARD key   <span class="comment"># 查看zset的数据个数</span></span><br><span class="line">ZCOUNT key <span class="built_in">min</span> <span class="built_in">max</span>  <span class="comment"># 查看分数在min和max之间的数据量</span></span><br><span class="line">ZINCRBY key score member  <span class="comment"># 将key中member的分值score</span></span><br><span class="line">ZSCORE key m  <span class="comment"># 查看key中m的分值</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>示例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ZADD fam <span class="number">1</span> sylar <span class="number">2</span> alex <span class="number">3</span> tory  <span class="comment"># 添加三个数据</span></span><br><span class="line">ZRANGE fam <span class="number">0</span> -<span class="number">1</span> WITHSCORES <span class="comment"># 正序查看</span></span><br><span class="line">ZREVRANGE fam <span class="number">0</span> -<span class="number">1</span> WITHSCORES   <span class="comment"># 倒叙查看</span></span><br><span class="line">ZINCRBY fam <span class="number">10</span> alex  <span class="comment"># 给alex加10分</span></span><br><span class="line">ZADD fam <span class="number">100</span> alex   <span class="comment"># 给alex修改分数为100分</span></span><br><span class="line">ZSCORE fam alex   <span class="comment"># 查看alex的分数</span></span><br><span class="line">ZCARD fam    <span class="comment"># 查看fam的数据个数</span></span><br></pre></td></tr></table></figure></li></ol><p>redis还有非常非常多的操作. 我们就不一一列举了. 各位可以在网络上找到非常多的资料. </p><p>&#x3D;&#x3D;各位大佬们注意. 数据保存完一定要save一下, 避免数据没有写入硬盘而产生的数据丢失&#x3D;&#x3D;</p></li></ol><h2 id="四-python搞定redis"><a href="#四-python搞定redis" class="headerlink" title="四. python搞定redis"></a>四. python搞定redis</h2><p>​python处理redis使用专用的redis模块. 同样的, 它也是一个第三方库.</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install redis</span><br></pre></td></tr></table></figure><p>​获取连接(1)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> Redis</span><br><span class="line"></span><br><span class="line">red = Redis(host=<span class="string">&quot;127.0.0.1&quot;</span>,  <span class="comment"># 地址</span></span><br><span class="line">            port=<span class="number">6379</span>,   <span class="comment"># 端口</span></span><br><span class="line">            db=<span class="number">0</span>,   <span class="comment"># 数据库</span></span><br><span class="line">            password=<span class="number">123456</span>,  <span class="comment"># 密码</span></span><br><span class="line">            decode_responses=<span class="literal">True</span>)  <span class="comment"># 是否自动解码</span></span><br></pre></td></tr></table></figure><p>​获取连接(2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pool = redis.ConnectionPool(</span><br><span class="line">        host=<span class="string">&quot;127.0.0.1&quot;</span>,  <span class="comment"># 地址</span></span><br><span class="line">        port=<span class="number">6379</span>,   <span class="comment"># 端口</span></span><br><span class="line">        db=<span class="number">0</span>,   <span class="comment"># 数据库</span></span><br><span class="line">        password=<span class="number">123456</span>,  <span class="comment"># 密码</span></span><br><span class="line">        decode_responses=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">r = redis.Redis(connection_pool=pool)</span><br><span class="line"><span class="built_in">print</span>(r.keys())</span><br></pre></td></tr></table></figure><p>​我们以一个免费代理IP池能用到的操作来尝试一下redis</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 存入数据</span></span><br><span class="line">red.<span class="built_in">set</span>(<span class="string">&quot;sylar&quot;</span>, <span class="string">&quot;邱彦涛&quot;</span>)</span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line"><span class="built_in">print</span>(red.get(<span class="string">&quot;sylar&quot;</span>))</span><br><span class="line"></span><br><span class="line">lst = [<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张娜拉&quot;</span>]</span><br><span class="line">red.lpush(<span class="string">&quot;names&quot;</span>, *lst)  <span class="comment"># 将所有的名字都存入names</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 查询所有数据</span></span><br><span class="line">result = red.lrange(<span class="string">&quot;names&quot;</span>, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从上面的操作上可以看出. python中的redis和redis-cli中的操作是几乎一样的</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来, 咱们站在一个代理IP池的角度来分析各个功能</span></span><br><span class="line"><span class="comment"># 抓取到了IP. 保存入库</span></span><br><span class="line">red.zadd(<span class="string">&quot;proxy&quot;</span>, &#123;<span class="string">&quot;192.168.1.1&quot;</span>: <span class="number">10</span>, <span class="string">&quot;192.168.1.2&quot;</span>: <span class="number">10</span>&#125;)</span><br><span class="line">red.zadd(<span class="string">&quot;proxy&quot;</span>, &#123;<span class="string">&quot;192.168.1.3&quot;</span>: <span class="number">10</span>, <span class="string">&quot;192.168.1.6&quot;</span>: <span class="number">10</span>&#125;)</span><br><span class="line">red.zadd(<span class="string">&quot;proxy&quot;</span>, &#123;<span class="string">&quot;192.168.1.4&quot;</span>: <span class="number">10</span>, <span class="string">&quot;192.168.1.7&quot;</span>: <span class="number">10</span>&#125;)</span><br><span class="line">red.zadd(<span class="string">&quot;proxy&quot;</span>, &#123;<span class="string">&quot;192.168.1.5&quot;</span>: <span class="number">10</span>, <span class="string">&quot;192.168.1.8&quot;</span>: <span class="number">10</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给某一个ip增加到100分</span></span><br><span class="line">red.zadd(<span class="string">&quot;proxy&quot;</span>, &#123;<span class="string">&quot;192.168.1.4&quot;</span>: <span class="number">100</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给&quot;192.168.1.4&quot; 扣10分</span></span><br><span class="line">red.zincrby(<span class="string">&quot;proxy&quot;</span>, -<span class="number">10</span>, <span class="string">&quot;192.168.1.4&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分扣没了. 删除掉它</span></span><br><span class="line">red.zrem(<span class="string">&quot;proxy&quot;</span>, <span class="string">&quot;192.168.1.4&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可用的代理数量</span></span><br><span class="line">c = red.zcard(<span class="string">&quot;proxy&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="comment"># 根据分值进行查询(0~100)之间</span></span><br><span class="line">r = red.zrangebyscore(<span class="string">&quot;proxy&quot;</span>, <span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询前100个数据(分页查询)</span></span><br><span class="line">r = red.zrevrange(<span class="string">&#x27;proxy&#x27;</span>, <span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断proxy是否存在, 如果是None就是不存在</span></span><br><span class="line">r = red.zscore(<span class="string">&quot;proxy&quot;</span>, <span class="string">&quot;192.168.1.4&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="爬虫开发" scheme="http://blog.ioimp.top/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Scrapy爬虫" scheme="http://blog.ioimp.top/tags/Scrapy%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy_模拟登录与中间件</title>
    <link href="http://blog.ioimp.top/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    <id>http://blog.ioimp.top/2023/12/03/Scrapy-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/</id>
    <published>2023-12-03T03:57:12.000Z</published>
    <updated>2023-12-03T03:58:19.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="模拟登录与中间件"><a href="#模拟登录与中间件" class="headerlink" title="模拟登录与中间件"></a>模拟登录与中间件</h1><h2 id="一-Scrapy处理cookie"><a href="#一-Scrapy处理cookie" class="headerlink" title="一. Scrapy处理cookie"></a>一. Scrapy处理cookie</h2><p>​在requests中我们讲解处理cookie主要有两个方案. 第一个方案. 从浏览器里直接把cookie搞出来. 贴到heades里. 这种方案, 简单粗暴. 第二个方案是走正常的登录流程. 通过session来记录请求过程中的cookie. 那么到了scrapy中如何处理cookie?  其实也是这两个方案. </p><p>​首先, 我们依然是把目标定好,  还是我们的老朋友, <a href="https://user.17k.com/ck/author/shelf?page=1&appKey=2406394919">https://user.17k.com/ck/author/shelf?page=1&amp;appKey=2406394919</a></p><p>​这个url必须要登录后才能访问(用户书架). &#x3D;&#x3D;对于该网页而言&#x3D;&#x3D;, 就必须要用到cookie了. 首先, 创建项目, 建立爬虫. 把该填的地方填上. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request, FormRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LoginSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;login&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;17k.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://user.17k.com/ck/author/shelf?page=1&amp;appKey=2406394919&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​此时运行时, 显示的是该用户还未登录. 不论是哪个方案. 在请求到start_urls里面的url之前必须得获取到cookie. 但是默认情况下, scrapy会自动的帮我们完成其实request的创建. 此时, 我们需要自己去组装第一个请求. 这时就需要我们自己的爬虫中重写start_requests()方法. 该方法负责起始request的组装工作. 我们不妨先看看原来的start_requests()是如何工作的. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下是scrapy源码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">    cls = self.__class__</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.start_urls <span class="keyword">and</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;start_url&#x27;</span>):</span><br><span class="line">        <span class="keyword">raise</span> AttributeError(</span><br><span class="line">            <span class="string">&quot;Crawling could not start: &#x27;start_urls&#x27; not found &quot;</span></span><br><span class="line">            <span class="string">&quot;or empty (but found &#x27;start_url&#x27; attribute instead, &quot;</span></span><br><span class="line">            <span class="string">&quot;did you miss an &#x27;s&#x27;?)&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> method_is_overridden(cls, Spider, <span class="string">&#x27;make_requests_from_url&#x27;</span>):</span><br><span class="line">        warnings.warn(</span><br><span class="line">            <span class="string">&quot;Spider.make_requests_from_url method is deprecated; it &quot;</span></span><br><span class="line">            <span class="string">&quot;won&#x27;t be called in future Scrapy releases. Please &quot;</span></span><br><span class="line">            <span class="string">&quot;override Spider.start_requests method instead (see %s.%s).&quot;</span> % (</span><br><span class="line">                cls.__module__, cls.__name__</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">            <span class="keyword">yield</span> self.make_requests_from_url(url)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">            <span class="comment"># 核心就这么一句话. 组建一个Request对象.我们也可以这么干. </span></span><br><span class="line">            <span class="keyword">yield</span> Request(url, dont_filter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>自己写个start_requests()看看. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;我是万恶之源&quot;</span>)</span><br><span class="line">    <span class="keyword">yield</span> Request(</span><br><span class="line">        url=LoginSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">        callback=self.parse</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>接下来, 我们去处理cookie</p><h3 id="1-方案一-直接从浏览器复制cookie过来"><a href="#1-方案一-直接从浏览器复制cookie过来" class="headerlink" title="1. 方案一, 直接从浏览器复制cookie过来"></a>1. 方案一, 直接从浏览器复制cookie过来</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 直接从浏览器复制</span></span><br><span class="line">        cookies = <span class="string">&quot;GUID=bbb5f65a-2fa2-40a0-ac87-49840eae4ad1; c_channel=0; c_csc=web; Hm_lvt_9793f42b498361373512340937deb2a0=1627572532,1627711457,1627898858,1628144975; accessToken=avatarUrl%3Dhttps%253A%252F%252Fcdn.static.17k.com%252Fuser%252Favatar%252F16%252F16%252F64%252F75836416.jpg-88x88%253Fv%253D1610625030000%26id%3D75836416%26nickname%3D%25E5%25AD%25A4%25E9%25AD%2582%25E9%2587%258E%25E9%25AC%25BCsb%26e%3D1643697376%26s%3D73f8877e452e744c; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2275836416%22%2C%22%24device_id%22%3A%2217700ba9c71257-035a42ce449776-326d7006-2073600-17700ba9c728de%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_referrer%22%3A%22%22%2C%22%24latest_referrer_host%22%3A%22%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%7D%2C%22first_id%22%3A%22bbb5f65a-2fa2-40a0-ac87-49840eae4ad1%22%7D; Hm_lpvt_9793f42b498361373512340937deb2a0=1628145672&quot;</span></span><br><span class="line">        cookie_dic = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> cookies.split(<span class="string">&quot;; &quot;</span>):</span><br><span class="line">            k, v = c.split(<span class="string">&quot;=&quot;</span>)</span><br><span class="line">            cookie_dic[k] = v</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> Request(</span><br><span class="line">            url=LoginSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">            cookies=cookie_dic,</span><br><span class="line">            callback=self.parse</span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>这种方案和原来的requests几乎一模一样.  需要注意的是: cookie需要通过cookies参数进行传递!</p><h3 id="2-方案二-完成登录过程"><a href="#2-方案二-完成登录过程" class="headerlink" title="2. 方案二, 完成登录过程."></a>2. 方案二, 完成登录过程.</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 登录流程</span></span><br><span class="line">    username = <span class="string">&quot;18614075987&quot;</span></span><br><span class="line">    password = <span class="string">&quot;q6035945&quot;</span></span><br><span class="line">    url = <span class="string">&quot;https://passport.17k.com/ck/user/login&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 发送post请求</span></span><br><span class="line">    <span class="comment"># yield Request(</span></span><br><span class="line">    <span class="comment">#     url=url,</span></span><br><span class="line">    <span class="comment">#     method=&quot;post&quot;,</span></span><br><span class="line">    <span class="comment">#     body=&quot;loginName=18614075987&amp;password=q6035945&quot;,</span></span><br><span class="line">    <span class="comment">#     callback=self.parse</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 发送post请求</span></span><br><span class="line">    <span class="keyword">yield</span> FormRequest(</span><br><span class="line">        url=url,</span><br><span class="line">        formdata=&#123;</span><br><span class="line">            <span class="string">&quot;loginName&quot;</span>: username,</span><br><span class="line">            <span class="string">&quot;password&quot;</span>: password</span><br><span class="line">        &#125;,</span><br><span class="line">        callback=self.parse</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">    <span class="comment"># 得到响应结果. 直接请求到默认的start_urls</span></span><br><span class="line">    <span class="keyword">yield</span> Request(</span><br><span class="line">        url=LoginSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">        callback=self.parse_detail</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self, resp</span>):</span><br><span class="line">    <span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure><p>​注意, 发送post请求有两个方案, </p><ol><li><p>Scrapy.Request(url&#x3D;url, method&#x3D;’post’, body&#x3D;数据)</p></li><li><p>Scarpy.FormRequest(url&#x3D;url, formdata&#x3D;数据)  -&gt; 推荐</p><p>区别: 方式1的数据只能是字符串. 这个就很难受. 所以推荐用第二种.</p></li></ol><h2 id="二-Scrapy的中间件"><a href="#二-Scrapy的中间件" class="headerlink" title="二. Scrapy的中间件"></a>二. Scrapy的中间件</h2><p>​中间件的作用: 负责处理引擎和爬虫以及引擎和下载器之间的请求和响应. 主要是可以对request和response做预处理. 为后面的操作做好充足的准备工作. 在python中准备了两种中间件, 分别是下载器中间件和爬虫中间件. </p><h3 id="1-DownloaderMiddleware"><a href="#1-DownloaderMiddleware" class="headerlink" title="1. DownloaderMiddleware"></a>1. DownloaderMiddleware</h3><p>​下载中间件, 它是介于引擎和下载器之间,  引擎在获取到request对象后, 会交给下载器去下载, 在这之间我们可以设置下载中间件. 它的执行流程:</p><p>​引擎拿到request -&gt; 中间件1(process_request) -&gt; 中间件2(process_request) …..-&gt;      下载器-|<br>​    引擎拿到request &lt;- 中间件1(process_response) &lt;- 中间件2(process_response) ….. &lt;-下载器-|</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MidDownloaderMiddleware1</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_request&quot;</span>, <span class="string">&quot;ware1&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_response&quot;</span>, <span class="string">&quot;ware1&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_exception&quot;</span>, <span class="string">&quot;ware1&quot;</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MidDownloaderMiddleware2</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_request&quot;</span>, <span class="string">&quot;ware2&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_response&quot;</span>, <span class="string">&quot;ware2&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_exception&quot;</span>, <span class="string">&quot;ware2&quot;</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>设置中间件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="comment"># &#x27;mid.middlewares.MidDownloaderMiddleware&#x27;: 542,</span></span><br><span class="line">   <span class="string">&#x27;mid.middlewares.MidDownloaderMiddleware1&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">   <span class="string">&#x27;mid.middlewares.MidDownloaderMiddleware2&#x27;</span>: <span class="number">544</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>优先级参考管道. </p><p>运行效果;</p><p><img src="/images/scrapy01/image-20210805180841148.png" alt="images/scrapy01/image-20210805180841148"></p><p>接下来, 我们来说说这几个方法的返回值问题(难点)</p><ol><li><p>process_request(request, spider):  在每个请求到达下载器之前调用</p><p>一, return None  不拦截, 把请求继续向后传递给权重低的中间件或者下载器</p><p>二, return request 请求被拦截, 并将一个新的请求返回. 后续中间件以及下载器收不到本次请求</p><p>三, return response 请求被拦截, 下载器将获取不到请求, 但是引擎是可以接收到本次响应的内容, 也就是说在当前方法内就已经把响应内容获取到了. </p></li><li><p>proccess_response(request, response, spider): 每个请求从下载器出来调用</p><p>一, return response 通过引擎将响应内容继续传递给其他组件或传递给其他process_response()处理</p><p>二, return request  响应被拦截. 将返回内容直接回馈给调度器(通过引擎), 后续process_response()接收不到响应内容.</p></li></ol><p>OK, 至此, 中间件的含义算是完事儿了. 那这东西有啥用?  我们上案例!</p><h4 id="1-1-动态随机设置UA"><a href="#1-1-动态随机设置UA" class="headerlink" title="1.1. 动态随机设置UA"></a>1.1. 动态随机设置UA</h4><p>设置统一的UA很简单. 直接在settings里设置即可. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT = <span class="string">&#x27;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure><p>但是这个不够好, 我希望得到一个随机的UA.  此时就可以这样设计, 首先, 在settings里定义好一堆UserAgent.  <a href="http://useragentstring.com/pages/useragentstring.php?name=Chrome">http://useragentstring.com/pages/useragentstring.php?name=Chrome</a> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT_LIST = [</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2919.83 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2866.71 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (X11; Ubuntu; Linux i686 on x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2820.59 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2762.73 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2656.18 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/44.0.2403.155 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2226.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.4; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.124 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 4.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​中间件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyRandomUserAgentMiddleware</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        UA = choice(USER_AGENT_LIST)</span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = UA</span><br><span class="line">        <span class="comment"># 不要返回任何东西</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="1-2-处理代理问题"><a href="#1-2-处理代理问题" class="headerlink" title="1.2 处理代理问题"></a>1.2 处理代理问题</h4><p>代理问题一直是我们作为一名爬虫工程师很蛋疼的问题. 不加容易被检测, 加了效率低, 免费的可用IP更是凤毛麟角. 没办法, 无论如何还是得面对它. 这里, 我们采用两个方案来给各位展示scrapy中添加代理的逻辑.</p><ol><li><p>免费代理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ProxyMiddleware</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;又来&quot;</span>)</span><br><span class="line">        proxy = choice(PROXY_LIST)</span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&quot;https://&quot;</span>+proxy  <span class="comment"># 设置代理</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;有么有结果???&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> response.status != <span class="number">200</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;尝试失败&quot;</span>)</span><br><span class="line">            request.dont_filter = <span class="literal">True</span>  <span class="comment"># 丢回调度器重新请求</span></span><br><span class="line">            <span class="keyword">return</span> request</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;出错了!&quot;</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li><li><p>收费代理</p><p>免费代理实在太难用了. 我们这里直接选择一个收费代理. 依然选择<code>快代理</code>, 这个根据你自己的喜好进行调整. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MoneyProxyMiddleware</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_proxy</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        912831993520336t12831993520578每次请求换IP</span></span><br><span class="line"><span class="string">        tps138.kdlapi.com 15818</span></span><br><span class="line"><span class="string">        需实名认证5次/s5Mb/s有效续费|订单详情|实名认证</span></span><br><span class="line"><span class="string">        隧道用户名密码修改密码</span></span><br><span class="line"><span class="string">        用户名：t12831993520578密码：t72a13xu</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        url = <span class="string">&quot;http://tps138.kdlapi.com:15818&quot;</span></span><br><span class="line">        auth = basic_auth_header(username=<span class="string">&quot;t12831993520578&quot;</span>, password=<span class="string">&quot;t72a13xu&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> url, auth</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;......&quot;</span>)</span><br><span class="line">        url, auth = self._get_proxy()</span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = url</span><br><span class="line">        request.headers[<span class="string">&#x27;Proxy-Authorization&#x27;</span>] = auth</span><br><span class="line">        request.headers[<span class="string">&#x27;Connection&#x27;</span>] = <span class="string">&#x27;close&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(response.status, <span class="built_in">type</span>(response.status))</span><br><span class="line">        <span class="keyword">if</span> response.status != <span class="number">200</span>:</span><br><span class="line">            request.dont_filter = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">return</span> request</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="1-3-使用selenium完成数据抓取"><a href="#1-3-使用selenium完成数据抓取" class="headerlink" title="1.3 使用selenium完成数据抓取"></a>1.3 使用selenium完成数据抓取</h4><p>首先, 我们需要使用selenium作为下载器进行下载. 那么我们的请求应该也是特殊订制的. 所以, 在我的设计里, 我可以重新设计一个请求. 就叫SeleniumRequest</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.http.request <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SeleniumRequest</span>(<span class="title class_ inherited__">Request</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>这里面不需要做任何操作. 整体还是用它父类的东西来进行操作. </p><p>接下来. 完善一下spider</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> boss.request <span class="keyword">import</span> SeleniumRequest</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BeijingSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;beijing&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;zhipin.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.zhipin.com/job_detail/?query=python&amp;city=101010100&amp;industry=&amp;position=&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">yield</span> SeleniumRequest(</span><br><span class="line">            url=BeijingSpider.start_urls[<span class="number">0</span>],</span><br><span class="line">            callback=self.parse,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        li_list = resp.xpath(<span class="string">&#x27;//*[@id=&quot;main&quot;]/div/div[3]/ul/li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            href = li.xpath(<span class="string">&quot;./div[1]/div[1]/div[1]/div[1]/div[1]/span[1]/a[1]/@href&quot;</span>).extract_first()</span><br><span class="line">            name = li.xpath(<span class="string">&quot;./div[1]/div[1]/div[1]/div[1]/div[1]/span[1]/a[1]/text()&quot;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(name, href)</span><br><span class="line">            <span class="built_in">print</span>(resp.urljoin(href))</span><br><span class="line">            <span class="keyword">yield</span> SeleniumRequest(</span><br><span class="line">                url=resp.urljoin(href),</span><br><span class="line">                callback=self.parse_detail,</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 下一页.....</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;招聘人&quot;</span>, resp.xpath(<span class="string">&#x27;//*[@id=&quot;main&quot;]/div[3]/div/div[2]/div[1]/h2&#x27;</span>).extract())</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>中间件~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BossDownloaderMiddleware</span>:</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        <span class="comment"># 这里很关键哦. </span></span><br><span class="line">        <span class="comment"># 在爬虫开始的时候. 执行spider_opened</span></span><br><span class="line">        <span class="comment"># 在爬虫结束的时候. 执行spider_closed</span></span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        crawler.signals.connect(s.spider_closed, signal=signals.spider_closed)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(request, SeleniumRequest):</span><br><span class="line">            self.web.get(request.url)</span><br><span class="line">            time.sleep(<span class="number">3</span>)</span><br><span class="line">            page_source = self.web.page_source</span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=request.url, encoding=<span class="string">&#x27;utf-8&#x27;</span>, request=request, body=page_source)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.web = Chrome()</span><br><span class="line">        self.web.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># 完成登录. 拿到cookie. 很容易...</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;创建浏览器&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_closed</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.web.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;关闭浏览器&quot;</span>)</span><br></pre></td></tr></table></figure><p>settings</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="comment"># 怼在所有默认中间件前面. 只要是selenium后面所有的中间件都给我停</span></span><br><span class="line">   <span class="string">&#x27;boss.middlewares.BossDownloaderMiddleware&#x27;</span>: <span class="number">99</span>,  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-4-用selenium设置cookie"><a href="#1-4-用selenium设置cookie" class="headerlink" title="1.4 用selenium设置cookie"></a>1.4 用selenium设置cookie</h4><p>有了这个案例. 想要用selenium处理cookie也很容易了. 直接在spider_opened位置完成登录, 然后在process_request()中简单设置一下即可. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChaojiyingDownloaderMiddleware</span>:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request.cookies:</span><br><span class="line">            request.cookies = self.cookie</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        web = Chrome()</span><br><span class="line">        web.get(<span class="string">&quot;https://www.chaojiying.com/user/login/&quot;</span>)</span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[1]/input&#x27;</span>).send_keys(<span class="string">&quot;18614075987&quot;</span>)</span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[2]/input&#x27;</span>).send_keys(<span class="string">&#x27;q6035945&#x27;</span>)</span><br><span class="line">        img = web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/div/img&#x27;</span>)</span><br><span class="line">        verify_code = self.base64_api(<span class="string">&quot;q6035945&quot;</span>, <span class="string">&quot;q6035945&quot;</span>, img.screenshot_as_base64, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[3]/input&#x27;</span>).send_keys(verify_code)</span><br><span class="line"></span><br><span class="line">        web.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div[3]/div[1]/form/p[4]/input&#x27;</span>).click()</span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line">        cookies = web.get_cookies()</span><br><span class="line">        self.cookie = &#123;dic[<span class="string">&#x27;name&#x27;</span>]:dic[<span class="string">&#x27;value&#x27;</span>] <span class="keyword">for</span> dic <span class="keyword">in</span> cookies&#125;</span><br><span class="line">        web.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">base64_api</span>(<span class="params">self, uname, pwd, b64_img, typeid</span>):</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;username&quot;</span>: uname,</span><br><span class="line">            <span class="string">&quot;password&quot;</span>: pwd,</span><br><span class="line">            <span class="string">&quot;typeid&quot;</span>: typeid,</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: b64_img</span><br><span class="line">        &#125;</span><br><span class="line">        result = json.loads(requests.post(<span class="string">&quot;http://api.ttshitu.com/predict&quot;</span>, json=data).text)</span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">&#x27;success&#x27;</span>]:</span><br><span class="line">            <span class="keyword">return</span> result[<span class="string">&quot;data&quot;</span>][<span class="string">&quot;result&quot;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> result[<span class="string">&quot;message&quot;</span>]</span><br></pre></td></tr></table></figure><h3 id="2-SpiderMiddleware-了解"><a href="#2-SpiderMiddleware-了解" class="headerlink" title="2. SpiderMiddleware(了解)"></a>2. SpiderMiddleware(了解)</h3><p>​爬虫中间件. 是处于引擎和spider之间的中间件. 里面常用的方法有:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CuowuSpiderMiddleware</span>:</span><br><span class="line">    <span class="comment"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class="line">    <span class="comment"># scrapy acts as if the spider middleware does not modify the</span></span><br><span class="line">    <span class="comment"># passed objects.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_input</span>(<span class="params">self, response, spider</span>):</span><br><span class="line">        <span class="comment"># 请求被返回, 即将进入到spider时调用</span></span><br><span class="line">        <span class="comment"># 要么返回None, 要么报错</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我是process_spider_input&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_output</span>(<span class="params">self, response, result, spider</span>):</span><br><span class="line">        <span class="comment"># 处理完spider中的数据. 返回数据后. 执行</span></span><br><span class="line">        <span class="comment"># 返回值要么是item, 要么是request.</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我是process_spider_output&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            <span class="keyword">yield</span> i</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我是process_spider_output&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_exception</span>(<span class="params">self, response, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_spider_exception&quot;</span>)</span><br><span class="line">        <span class="comment"># spider中报错 或者, process_spider_input() 方法报错</span></span><br><span class="line">        <span class="comment"># 返回None或者Request或者item.</span></span><br><span class="line">        it = ErrorItem()</span><br><span class="line">        it[<span class="string">&#x27;name&#x27;</span>] = <span class="string">&quot;exception&quot;</span></span><br><span class="line">        it[<span class="string">&#x27;url&#x27;</span>] = response.url</span><br><span class="line">        <span class="keyword">yield</span> it</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_start_requests</span>(<span class="params">self, start_requests, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process_start_requests&quot;</span>)</span><br><span class="line">        <span class="comment"># 第一次启动爬虫时被调用.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must return only requests (not items).</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> start_requests:</span><br><span class="line">            <span class="keyword">yield</span> r</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>items</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ErrorItem</span>(scrapy.Item):</span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br></pre></td></tr></table></figure><p>spider:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaocuoSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;baocuo&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;baidu.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.baidu.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        name = resp.xpath(<span class="string">&#x27;//title/text()&#x27;</span>).extract_first()</span><br><span class="line">        <span class="comment"># print(1/0)  # 调整调整这个. 简单琢磨一下即可~~</span></span><br><span class="line">        it = CuowuItem()</span><br><span class="line">        it[<span class="string">&#x27;name&#x27;</span>] = name</span><br><span class="line">        <span class="built_in">print</span>(name)</span><br><span class="line">        <span class="keyword">yield</span> it</span><br></pre></td></tr></table></figure><p>pipeline:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cuowu.items <span class="keyword">import</span> ErrorItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CuowuPipeline</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(item, ErrorItem):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;错误&quot;</span>, item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;没错&quot;</span>, item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>目录结构:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cuowu</span><br><span class="line">├── cuowu</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── baocuo.py</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="爬虫开发" scheme="http://blog.ioimp.top/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Scrapy爬虫" scheme="http://blog.ioimp.top/tags/Scrapy%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy_管道</title>
    <link href="http://blog.ioimp.top/2023/12/03/09-Scrapy-%E7%AE%A1%E9%81%93/"/>
    <id>http://blog.ioimp.top/2023/12/03/09-Scrapy-%E7%AE%A1%E9%81%93/</id>
    <published>2023-12-03T03:56:22.000Z</published>
    <updated>2023-12-03T03:56:56.718Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Scrapy管道"><a href="#Scrapy管道" class="headerlink" title="Scrapy管道"></a>Scrapy管道</h1><p>在上一小节中, 我们初步掌握了Scrapy的基本运行流程以及基本开发流程. 本节继续讨论关于Scrapy更多的内容. </p><h2 id="一-关于管道"><a href="#一-关于管道" class="headerlink" title="一. 关于管道"></a>一. 关于管道</h2><p>上一节内容, 我们已经可以从spider中提取到数据. 然后通过引擎将数据传递给pipeline, 那么在pipeline中如何对数据进行保存呢? 我们主要针对四种数据存储展开讲解. </p><p>前三个案例以<a href="http://datachart.500.com/ssq/%E4%B8%BA%E6%A1%88%E4%BE%8B%E5%9F%BA%E7%A1%80">http://datachart.500.com/ssq/为案例基础</a>. 最后一个以<a href="https://www.tupianzj.com/bizhi/DNmeinv/%E4%B8%BA%E6%A1%88%E4%BE%8B%E5%9F%BA%E7%A1%80">https://www.tupianzj.com/bizhi/DNmeinv/为案例基础</a>. </p><h3 id="1-csv文件写入"><a href="#1-csv文件写入" class="headerlink" title="1. csv文件写入"></a>1. csv文件写入</h3><p>​写入文件是一个非常简单的事情. 直接在pipeline中开启文件即可. 但这里要说明的是. 如果我们只在process_item中进行处理文件是不够优雅的.  总不能有一条数据就open一次吧</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CaipiaoFilePipeline</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;caipiao.txt&quot;</span>, mode=<span class="string">&quot;a&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment"># 写入文件</span></span><br><span class="line">            f.write(<span class="string">f&quot;<span class="subst">&#123;item[<span class="string">&#x27;qihao&#x27;</span>]&#125;</span>, <span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join(item[<span class="string">&#x27;red_ball&#x27;</span>])&#125;</span>, <span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join(item[<span class="string">&#x27;blue_ball&#x27;</span>])&#125;</span>\n&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><p>​我们希望的是, 能不能打开一个文件, 然后就用这一个文件句柄来完成数据的保存. 答案是可以的. 我们可以在pipeline中创建两个方法, 一个是open_spider(), 另一个是close_spider(). 看名字也能明白其含义: </p><p>​open_spider(), 在爬虫开始的时候执行一次<br>​close_spider(), 在爬虫结束的时候执行一次</p><p>​有了这俩货, 我们就可以很简单的去处理这个问题</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CaipiaoFilePipeline</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.f = <span class="built_in">open</span>(<span class="string">&quot;caipiao.txt&quot;</span>, mode=<span class="string">&quot;a&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> self.f:</span><br><span class="line">            self.f.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="comment"># 写入文件</span></span><br><span class="line">        self.f.write(<span class="string">f&quot;<span class="subst">&#123;item[<span class="string">&#x27;qihao&#x27;</span>]&#125;</span>, <span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join(item[<span class="string">&#x27;red_ball&#x27;</span>])&#125;</span>, <span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join(item[<span class="string">&#x27;blue_ball&#x27;</span>])&#125;</span>\n&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><p>​在爬虫开始的时候打开一个文件, 在爬虫结束的时候关闭这个文件. 满分~</p><p>​对了, 别忘了设置settings</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;caipiao.pipelines.CaipiaoFilePipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-mysql数据库写入"><a href="#2-mysql数据库写入" class="headerlink" title="2. mysql数据库写入"></a>2. mysql数据库写入</h3><p>​有了上面的示例, 写入数据库其实也就很顺其自然了, 首先, 在open_spider中创建好数据库连接. 在close_spider中关闭链接. 在proccess_item中对数据进行保存工作. </p><p>先把mysql相关设置丢到settings里</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MYSQL配置信息</span></span><br><span class="line">MYSQL_CONFIG = &#123;</span><br><span class="line">   <span class="string">&quot;host&quot;</span>: <span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">   <span class="string">&quot;port&quot;</span>: <span class="number">3306</span>,</span><br><span class="line">   <span class="string">&quot;user&quot;</span>: <span class="string">&quot;root&quot;</span>,</span><br><span class="line">   <span class="string">&quot;password&quot;</span>: <span class="string">&quot;test123456&quot;</span>,</span><br><span class="line">   <span class="string">&quot;database&quot;</span>: <span class="string">&quot;spider&quot;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caipiao.settings <span class="keyword">import</span> MYSQL_CONFIG <span class="keyword">as</span> mysql</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CaipiaoMySQLPipeline</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.conn = pymysql.connect(host=mysql[<span class="string">&quot;host&quot;</span>], port=mysql[<span class="string">&quot;port&quot;</span>], user=mysql[<span class="string">&quot;user&quot;</span>], password=mysql[<span class="string">&quot;password&quot;</span>], database=mysql[<span class="string">&quot;database&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.conn.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="comment"># 写入文件</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cursor = self.conn.cursor()</span><br><span class="line">            sql = <span class="string">&quot;insert into caipiao(qihao, red, blue) values(%s, %s, %s)&quot;</span></span><br><span class="line">            red = <span class="string">&quot;,&quot;</span>.join(item[<span class="string">&#x27;red_ball&#x27;</span>])</span><br><span class="line">            blue = <span class="string">&quot;,&quot;</span>.join(item[<span class="string">&#x27;blue_ball&#x27;</span>])</span><br><span class="line">            cursor.execute(sql, (item[<span class="string">&#x27;qihao&#x27;</span>], red, blue))</span><br><span class="line">            self.conn.commit()</span><br><span class="line">            spider.logger.info(<span class="string">f&quot;保存数据<span class="subst">&#123;item&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            self.conn.rollback()</span><br><span class="line">            spider.logger.error(<span class="string">f&quot;保存数据库失败!&quot;</span>, e, <span class="string">f&quot;数据是: <span class="subst">&#123;item&#125;</span>&quot;</span>)  <span class="comment"># 记录错误日志</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>别忘了把pipeline设置一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;caipiao.pipelines.CaipiaoMySQLPipeline&#x27;</span>: <span class="number">301</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-mongodb数据库写入"><a href="#3-mongodb数据库写入" class="headerlink" title="3. mongodb数据库写入"></a>3. mongodb数据库写入</h3><p>​mongodb数据库写入和mysql写入如出一辙…不废话直接上代码吧</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MONGO_CONFIG = &#123;</span><br><span class="line">   <span class="string">&quot;host&quot;</span>: <span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">   <span class="string">&quot;port&quot;</span>: <span class="number">27017</span>,</span><br><span class="line">   <span class="string">&#x27;has_user&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">   <span class="string">&#x27;user&#x27;</span>: <span class="string">&quot;python_admin&quot;</span>,</span><br><span class="line">   <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span>,</span><br><span class="line">   <span class="string">&quot;db&quot;</span>: <span class="string">&quot;python&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caipiao.settings <span class="keyword">import</span> MONGO_CONFIG <span class="keyword">as</span> mongo</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CaipiaoMongoDBPipeline</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        client = pymongo.MongoClient(host=mongo[<span class="string">&#x27;host&#x27;</span>],</span><br><span class="line">                                     port=mongo[<span class="string">&#x27;port&#x27;</span>])</span><br><span class="line">        db = client[mongo[<span class="string">&#x27;db&#x27;</span>]]</span><br><span class="line">        <span class="keyword">if</span> mongo[<span class="string">&#x27;has_user&#x27;</span>]:</span><br><span class="line">            db.authenticate(mongo[<span class="string">&#x27;user&#x27;</span>], mongo[<span class="string">&#x27;password&#x27;</span>])</span><br><span class="line">        self.client = client</span><br><span class="line">        self.collection = db[<span class="string">&#x27;caipiao&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        self.collection.insert(&#123;<span class="string">&quot;qihao&quot;</span>: item[<span class="string">&#x27;qihao&#x27;</span>], <span class="string">&#x27;red&#x27;</span>: item[<span class="string">&quot;red_ball&quot;</span>], <span class="string">&#x27;blue&#x27;</span>: item[<span class="string">&#x27;blue_ball&#x27;</span>]&#125;)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 三个管道可以共存~</span></span><br><span class="line">   <span class="string">&#x27;caipiao.pipelines.CaipiaoFilePipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">   <span class="string">&#x27;caipiao.pipelines.CaipiaoMySQLPipeline&#x27;</span>: <span class="number">301</span>,</span><br><span class="line">   <span class="string">&#x27;caipiao.pipelines.CaipiaoMongoDBPipeline&#x27;</span>: <span class="number">302</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-文件保存"><a href="#4-文件保存" class="headerlink" title="4. 文件保存"></a>4. 文件保存</h3><p>接下来我们来尝试使用scrapy来下载一些图片, 看看效果如何. </p><p>首先, 随便找个图片网站(安排好的). <a href="https://www.tupianzj.com/bizhi/DNmeinv/">https://www.tupianzj.com/bizhi/DNmeinv/</a>. 可以去看看, 妹子们还是很漂亮的. </p><p>接下来. 创建好项目,  定义好数据结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MeinvItem</span>(scrapy.Item):</span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    img_url = scrapy.Field()</span><br><span class="line">    img_path = scrapy.Field()</span><br></pre></td></tr></table></figure><p>完善spider, 注意看yield scrapy.Request()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> meinv.items <span class="keyword">import</span> MeinvItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TupianzhijiaSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;tupianzhijia&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;tupianzj.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.tupianzj.com/bizhi/DNmeinv/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, resp, **kwargs</span>):</span><br><span class="line">        li_list = resp.xpath(<span class="string">&quot;//ul[@class=&#x27;list_con_box_ul&#x27;]/li&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            href = li.xpath(<span class="string">&quot;./a/@href&quot;</span>).extract_first()</span><br><span class="line">            <span class="comment"># 拿到href为了什么? 进入详情页啊</span></span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            url: 请求地址</span></span><br><span class="line"><span class="string">            method: 请求方式</span></span><br><span class="line"><span class="string">            callback: 回调函数</span></span><br><span class="line"><span class="string">            errback: 报错回调</span></span><br><span class="line"><span class="string">            dont_filter: 默认False, 表示&quot;不过滤&quot;, 该请求会重新进行发送</span></span><br><span class="line"><span class="string">            headers: 请求头. </span></span><br><span class="line"><span class="string">            cookies: cookie信息</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                url=resp.urljoin(href),  <span class="comment"># scrapy的url拼接</span></span><br><span class="line">                method=<span class="string">&#x27;get&#x27;</span>,</span><br><span class="line">                callback=self.parse_detail,</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 下一页</span></span><br><span class="line">        next_page = resp.xpath(<span class="string">&#x27;//div[@class=&quot;pages&quot;]/ul/li/a[contains(text(), &quot;下一页&quot;)]/@href&#x27;</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                url=resp.urljoin(next_page),</span><br><span class="line">                method=<span class="string">&#x27;get&#x27;</span>,</span><br><span class="line">                callback=self.parse</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self, resp</span>):</span><br><span class="line">        img_src = resp.xpath(<span class="string">&#x27;//*[@id=&quot;bigpic&quot;]/a[1]/img/@src&#x27;</span>).extract_first()</span><br><span class="line">        name = resp.xpath(<span class="string">&#x27;//*[@id=&quot;container&quot;]/div/div/div[2]/h1/text()&#x27;</span>).extract_first()</span><br><span class="line">        meinv = MeinvItem()</span><br><span class="line">        meinv[<span class="string">&#x27;name&#x27;</span>] = name</span><br><span class="line">        meinv[<span class="string">&#x27;img_url&#x27;</span>] = img_src</span><br><span class="line">        <span class="keyword">yield</span> meinv</span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>​关于Request()的参数:<br>​url: 请求地址<br>​            method: 请求方式<br>​            callback: 回调函数<br>​            errback: 报错回调<br>​            dont_filter: 默认False, 表示”不过滤”, 该请求会重新进行发送<br>​            headers: 请求头.<br>​            cookies: cookie信息</p><p>​接下来就是下载问题了. 如何在pipeline中下载一张图片呢? Scrapy早就帮你准备好了. 在Scrapy中有一个ImagesPipeline可以实现自动图片下载功能. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline, FilesPipeline</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> meinv.settings <span class="keyword">import</span> MYSQL</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MeinvPipeline</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.conn = pymysql.connect(</span><br><span class="line">            host=MYSQL[<span class="string">&#x27;host&#x27;</span>],</span><br><span class="line">            port=MYSQL[<span class="string">&#x27;port&#x27;</span>],</span><br><span class="line">            user=MYSQL[<span class="string">&#x27;user&#x27;</span>],</span><br><span class="line">            password=MYSQL[<span class="string">&#x27;password&#x27;</span>],</span><br><span class="line">            database=MYSQL[<span class="string">&#x27;database&#x27;</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="keyword">if</span> self.conn:</span><br><span class="line">            self.conn.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cursor = self.conn.cursor()</span><br><span class="line">            sql = <span class="string">&quot;insert into tu (name, img_src, img_path) values (%s, %s, %s)&quot;</span></span><br><span class="line">            cursor.execute(sql, (item[<span class="string">&#x27;name&#x27;</span>], item[<span class="string">&#x27;img_src&#x27;</span>], item[<span class="string">&#x27;img_path&#x27;</span>]))</span><br><span class="line">            self.conn.commit()</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            self.conn.rollback()</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="keyword">if</span> cursor:</span><br><span class="line">                cursor.close()</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MeinvSavePipeline</span>(<span class="title class_ inherited__">ImagesPipeline</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_media_requests</span>(<span class="params">self, item, info</span>):</span><br><span class="line">        <span class="comment"># 发送请求去下载图片</span></span><br><span class="line">        <span class="comment"># 如果是一堆图片. 可以使用循环去得到每一个url, 然后在yield每一个图片对应的Request对象</span></span><br><span class="line">        <span class="keyword">return</span> scrapy.Request(item[<span class="string">&#x27;img_url&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 准备好图片的名称</span></span><br><span class="line">        filename = request.url.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;img/<span class="subst">&#123;filename&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">item_completed</span>(<span class="params">self, results, item, info</span>):</span><br><span class="line">        <span class="comment"># 文件存储的路径</span></span><br><span class="line">        ok, res = results[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># print(res[&#x27;path&#x27;])</span></span><br><span class="line">        item[<span class="string">&#x27;img_path&#x27;</span>] = res[<span class="string">&quot;path&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><p>最后, 需要在settings中设置以下内容:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MYSQL = &#123;</span><br><span class="line">   <span class="string">&quot;host&quot;</span>: <span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">   <span class="string">&quot;port&quot;</span>: <span class="number">3306</span>,</span><br><span class="line">   <span class="string">&quot;user&quot;</span>: <span class="string">&quot;root&quot;</span>,</span><br><span class="line">   <span class="string">&quot;password&quot;</span>: <span class="string">&quot;test123456&quot;</span>,</span><br><span class="line">   <span class="string">&quot;database&quot;</span>: <span class="string">&#x27;spider&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">&#x27;meinv.pipelines.MeinvPipeline&#x27;</span>: <span class="number">303</span>,</span><br><span class="line">    <span class="string">&#x27;meinv.pipelines.MeinvSavePipeline&#x27;</span>: <span class="number">301</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 图片保存路径  -&gt; ImagesPipeline</span></span><br><span class="line">IMAGES_STORE= <span class="string">&#x27;./my_tu&#x27;</span></span><br><span class="line"><span class="comment"># 文件保存路径 -&gt; FilesPipeline</span></span><br><span class="line">FILES_STORE = <span class="string">&#x27;./my_tu&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="爬虫开发" scheme="http://blog.ioimp.top/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Scrapy爬虫" scheme="http://blog.ioimp.top/tags/Scrapy%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>scrapy入门课件</title>
    <link href="http://blog.ioimp.top/2023/12/03/scrapy%E5%85%A5%E9%97%A8%E8%AF%BE%E4%BB%B6/"/>
    <id>http://blog.ioimp.top/2023/12/03/scrapy%E5%85%A5%E9%97%A8%E8%AF%BE%E4%BB%B6/</id>
    <published>2023-12-03T03:53:32.000Z</published>
    <updated>2023-12-03T03:55:45.577Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Scrapy-基本介绍与使用"><a href="#Scrapy-基本介绍与使用" class="headerlink" title="Scrapy 基本介绍与使用"></a>Scrapy 基本介绍与使用</h1><h2 id="一-爬虫工程化"><a href="#一-爬虫工程化" class="headerlink" title="一, 爬虫工程化"></a>一, 爬虫工程化</h2><p>​在之前的学习中我们已经掌握了爬虫这门技术需要的大多数的技术点, 但是我们现在写的代码还很流程化, 很难进行商用的. 想要我们的爬虫达到商用级别, 必须要对我们现在编写的爬虫代码进行大刀阔斧式的重组, 已达到工程化的爬虫. 何为工程化, 就是让你的程序更加的有体系, 有逻辑, 更加的模块化. </p><p>​就好比, 我们家里以前做过鞋子, 我妈妈给我做鞋, 她需要从画图纸到裁剪到最后的缝合, 一步一步的完成一双鞋子的制作. 这种手工鞋子如果每年做个几双, 没问题. 我妈妈辛苦一点, 也能搞定. 但是, 如果现在我想去售卖这个鞋子. 再依靠妈妈一双一双的缝制. 你不赔死, 也得让你妈打死. 为什么? 第一, 产能跟不上. 一个人的力量是有限的, 第二, 一个人要完整的把制作鞋子的工艺从头搞到尾. 就算你想招人分担一下. 貌似也不好找这样厉害的手艺人. 怎么办? 聪明的你可能已经想到了. 从头到尾完成一双鞋的人不好找. 那我就把这个工艺过程分开. 分成4份, 画图, 裁剪, 缝合, 验收.  招4个人. 每个人就负责一小部分. 并且这一小部分是很容易完成的. 最终只要有一个人(我)来做一个总指挥. 我的制鞋小工厂就建起来了. </p><p>​上述逻辑同样适用于我们的爬虫, 想想, 到目前为止, 我们所编写的爬虫我们都是从头到尾的每一步都要亲力亲为. 这样做固然有其优点(可控性更好), 但是各位请认真思考. 这样的代码逻辑是不能形成批量生产的效果的(写100个爬虫). 很多具有共通性的代码逻辑都没有进行重复利用. 那我们就可以考虑看看, 能不能把一些共性的问题(获取页面源代码, 数据存储), 单独搞成一个功能. 如果我们把这些功能单独进行编写. 并且产生类似单独的功能模块, 将大大的提高我们爬虫的效率.  已达到我们爬虫工程化开发的效果. </p><p>​爬虫工程化: 对爬虫的功能进行模块化的开发. 并达到可以批量生产的效果(不论是开发还是数据产出)</p><h2 id="二-scrapy简介"><a href="#二-scrapy简介" class="headerlink" title="二, scrapy简介"></a>二, scrapy简介</h2><p>​Scrapy到目前为止依然是这个星球上最流行的爬虫框架. 摘一下官方给出对scrapy的介绍</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">An open source and collaborative framework for extracting the data you need from websites.</span><br><span class="line"></span><br><span class="line">In a fast, simple, yet extensible way.</span><br></pre></td></tr></table></figure><p>​scrapy的特点: 速度快, 简单, 可扩展性强. </p><p>​scrapy的官方文档: <a href="https://docs.scrapy.org/en/latest/">https://docs.scrapy.org/en/latest/</a></p><h2 id="三-scrapy工作流程-重点"><a href="#三-scrapy工作流程-重点" class="headerlink" title="三, scrapy工作流程(重点)"></a>三, scrapy工作流程(重点)</h2><p>​之前我们所编写的爬虫的逻辑: </p><p><img src="/images/scrapy01/image-20210803105808636.png" alt="images/scrapy01/image-20210803105808636"></p><p>​scrapy的工作流程: </p><p><img src="/images/scrapy01/image-20210803113438252.png" alt="images/scrapy01/image-20210803113438252"></p><p>整个工作流程, </p><ol><li><p>爬虫中起始的url构造成request对象, 并传递给调度器. </p></li><li><p><code>引擎</code>从<code>调度器</code>中获取到request对象. 然后交给<code>下载器</code></p></li><li><p>由<code>下载器</code>来获取到页面源代码, 并封装成response对象. 并回馈给<code>引擎</code></p></li><li><p><code>引擎</code>将获取到的response对象传递给<code>spider</code>, 由<code>spider</code>对数据进行解析(parse). 并回馈给<code>引擎</code></p></li><li><p><code>引擎</code>将数据传递给pipeline进行数据持久化保存或进一步的数据处理. </p></li><li><p>在此期间如果spider中提取到的并不是数据. 而是子页面url. 可以进一步提交给调度器, 进而重复<code>步骤2</code>的过程</p></li></ol><p>上述过程中一直在重复着几个东西, </p><ol><li><p>引擎(engine)</p><p>scrapy的核心, 所有模块的衔接, 数据流程梳理.</p></li><li><p>调度器(scheduler)</p><p>本质上这东西可以看成是一个队列. 里面存放着一堆我们即将要发送的请求. 可以看成是一个url的容器. 它决定了下一步要去爬取哪一个url. 通常我们在这里可以对url进行去重操作.  </p></li><li><p>下载器(downloader)</p><p>它的本质就是用来发动请求的一个模块. 小白们完全可以把它理解成是一个get_page_source()的功能. 只不过这货返回的是一个response对象. </p></li><li><p>爬虫(spider)</p><p>这是我们要写的第一个部分的内容, 负责解析下载器返回的response对象.从中提取到我们需要的数据. </p></li><li><p>管道(pipeline)</p><p>这是我们要写的第二个部分的内容, 主要负责数据的存储和各种持久化操作.</p></li></ol><p>经过上述的介绍来看, scrapy其实就是把我们平时写的爬虫进行了四分五裂式的改造. 对每个功能进行了单独的封装, 并且, 各个模块之间互相的不做依赖. 一切都由引擎进行调配. 这种思想希望你能知道–解耦. 让模块与模块之间的关联性更加的松散. 这样我们如果希望替换某一模块的时候会非常的容易. 对其他模块也不会产生任何的影响. </p><p>到目前为止, 我们对scrapy暂时了解这么多就够了. 后面会继续在这个图上进一步展开. </p><h2 id="四-scrapy安装"><a href="#四-scrapy安装" class="headerlink" title="四, scrapy安装"></a>四, scrapy安装</h2><p>​在windows上安装scrapy是一个很痛苦的事情. 可能会出现各种各样的异常BUG. </p><p>​先使用pip直接安装看看报错不</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scrapy </span><br></pre></td></tr></table></figure><p>​如果安装成功, 直接去创建项目即可. 如果报错可能需要安装VC++14.0库才可以. 安装的时候一定不要死记安装步骤, 要观察报错信息. 根据报错信息进行一点点的调整, 多试几次pip. 直至success. </p><p>如果上述过程还是无法正常安装scrapy, 可以考虑用下面的方案来安装:</p><ol><li><p>安装wheel</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install wheel</span><br></pre></td></tr></table></figure></li><li><p>下载twisted安装包, <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted">https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted</a></p><p><img src="/images/scrapy01/image-20210803144429440.png" alt="images/scrapy01/image-20210803144429440"></p><ol start="3"><li>用wheel安装twisted.</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Twisted‑<span class="number">21.7</span><span class="number">.0</span>‑py3‑none‑<span class="built_in">any</span>.whl</span><br></pre></td></tr></table></figure></li><li><p>安装pywin32</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure></li><li><p>安装scrapy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure></li></ol><p>总之, 最终你的控制台输入<code>scrapy version</code>能显示版本号. 就算成功了</p><h2 id="五-scrapy实例"><a href="#五-scrapy实例" class="headerlink" title="五, scrapy实例"></a>五, scrapy实例</h2><p>​接下来, 我们用scrapy来完成一个超级简单的爬虫, 目标: 深入理解Scrapy工作的流程, 以及各个模块之间是如何搭配工作的. </p><ol><li><p>创建项目</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject 项目名称</span><br></pre></td></tr></table></figure><p>示例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject mySpider_2</span><br></pre></td></tr></table></figure><p>创建好项目后, 我们可以在pycharm里观察到scrapy帮我们创建了一个文件夹, 里面的目录结构如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mySpider_2   <span class="comment"># 项目所在文件夹, 建议用pycharm打开该文件夹</span></span><br><span class="line">    ├── mySpider_2  <span class="comment"># 项目跟目录</span></span><br><span class="line">    │   ├── __init__.py</span><br><span class="line">    │   ├── items.py  <span class="comment"># 封装数据的格式</span></span><br><span class="line">    │   ├── middlewares.py  <span class="comment"># 所有中间件</span></span><br><span class="line">    │   ├── pipelines.py<span class="comment"># 所有的管道</span></span><br><span class="line">    │   ├── settings.py<span class="comment"># 爬虫配置信息</span></span><br><span class="line">    │   └── spiders<span class="comment"># 爬虫文件夹, 稍后里面会写入爬虫代码</span></span><br><span class="line">    │       └── __init__.py</span><br><span class="line">    └── scrapy.cfg<span class="comment"># scrapy项目配置信息,不要删它,别动它,善待它. </span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>创建爬虫</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd 文件夹  <span class="comment"># 进入项目所在文件夹</span></span><br><span class="line">scrapy genspider 爬虫名称 允许抓取的域名范围</span><br></pre></td></tr></table></figure><p>示例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd mySpider_2</span><br><span class="line">scrapy genspider youxi 4399.com</span><br></pre></td></tr></table></figure><p>效果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(base) sylardeMBP:第七章 sylar$ cd mySpider_2</span><br><span class="line">(base) sylardeMBP:mySpider_2 sylar$ ls</span><br><span class="line">mySpider_2      scrapy.cfg</span><br><span class="line">(base) sylardeMBP:mySpider_2 sylar$ scrapy genspider youxi http://www<span class="number">.4399</span>.com/</span><br><span class="line">Created spider <span class="string">&#x27;youxi&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  mySpider_2.spiders.youxi</span><br><span class="line">(base) sylardeMBP:mySpider_2 sylar$ </span><br></pre></td></tr></table></figure><p>至此, 爬虫创建完毕, 我们打开文件夹看一下. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">├── mySpider_2</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── youxi.py   <span class="comment"># 多了一个这个. </span></span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>编写数据解析过程</p><p>完善youxi.py中的内容. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YouxiSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;youxi&#x27;</span>  <span class="comment"># 该名字非常关键, 我们在启动该爬虫的时候需要这个名字</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;4399.com&#x27;</span>]  <span class="comment"># 爬虫抓取的域.</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.4399.com/flash/&#x27;</span>]  <span class="comment"># 起始页</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response, **kwargs</span>):</span><br><span class="line">        <span class="comment"># response.text  # 页面源代码</span></span><br><span class="line">        <span class="comment"># response.xpath()  # 通过xpath方式提取</span></span><br><span class="line">        <span class="comment"># response.css()  # 通过css方式提取</span></span><br><span class="line">        <span class="comment"># response.json() # 提取json数据</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用我们最熟悉的方式: xpath提取游戏名称, 游戏类别, 发布时间等信息</span></span><br><span class="line">        li_list = response.xpath(<span class="string">&quot;//ul[@class=&#x27;n-game cf&#x27;]/li&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            name = li.xpath(<span class="string">&quot;./a/b/text()&quot;</span>).extract_first()</span><br><span class="line">            category = li.xpath(<span class="string">&quot;./em/a/text()&quot;</span>).extract_first()</span><br><span class="line">            date = li.xpath(<span class="string">&quot;./em/text()&quot;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            dic = &#123;</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: name,</span><br><span class="line">                <span class="string">&quot;category&quot;</span>: category,</span><br><span class="line">                <span class="string">&quot;date&quot;</span>: date</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将提取到的数据提交到管道内.</span></span><br><span class="line">            <span class="comment"># 注意, 这里只能返回 request对象, 字典, item数据, or None</span></span><br><span class="line">            <span class="keyword">yield</span> dic</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意: </p><p>&#x3D;&#x3D;spider返回的内容只能是字典, requestes对象, item数据或者None. 其他内容一律报错&#x3D;&#x3D;</p><p>运行爬虫: </p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl 爬虫名字</span><br></pre></td></tr></table></figure><p>实例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl youxi</span><br></pre></td></tr></table></figure></li><li><p>编写pipeline.对数据进行简单的保存</p><p>数据传递到pipeline, 我们先看一下在pipeline中的样子. </p><p>首先修改settings.py文件中的pipeline信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 前面是pipeline的类名地址               </span></span><br><span class="line">    <span class="comment"># 后面是优先级, 优先级月低越先执行</span></span><br><span class="line">   <span class="string">&#x27;mySpider_2.pipelines.Myspider2Pipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后我们修改一下pipeline中的代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Myspider2Pipeline</span>:</span><br><span class="line">    <span class="comment"># 这个方法的声明不能动!!! 在spider返回的数据会自动的调用这里的process_item方法. </span></span><br><span class="line">    <span class="comment"># 你把它改了. 管道就断了</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></li></ol><h2 id="六-自定义数据传输结构item"><a href="#六-自定义数据传输结构item" class="headerlink" title="六, 自定义数据传输结构item"></a>六, 自定义数据传输结构item</h2><p>​在上述案例中, 我们使用字典作为数据传递的载体, 但是如果数据量非常大. 由于字典的key是随意创建的. 极易出现问题,  此时再用字典就不合适了. Scrapy中提供item作为数据格式的声明位置. 我们可以在items.py文件提前定义好该爬虫在进行数据传输时的数据格式. 然后再写代码的时候就有了数据名称的依据了. </p><p>item.py文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GameItem</span>(scrapy.Item):</span><br><span class="line">    <span class="comment"># 定义数据结构</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    category = scrapy.Field()</span><br><span class="line">    date = scrapy.Field()</span><br></pre></td></tr></table></figure><p>spider中. 这样来使用:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mySpider_2.items <span class="keyword">import</span> GameItem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下代码在spider中的parse替换掉原来的字典</span></span><br><span class="line">item = GameItem()</span><br><span class="line">item[<span class="string">&quot;name&quot;</span>] = name</span><br><span class="line">item[<span class="string">&quot;category&quot;</span>] = category</span><br><span class="line">item[<span class="string">&quot;date&quot;</span>] = date</span><br><span class="line"><span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h2 id="七-scrapy使用小总结"><a href="#七-scrapy使用小总结" class="headerlink" title="七, scrapy使用小总结"></a>七, scrapy使用小总结</h2><p>至此, 我们对scrapy有了一个非常初步的了解和使用. 快速总结一下. scrapy框架的使用流程: </p><ol><li>创建爬虫项目.   <code>scrapy startproject xxx     </code></li><li>进入项目目录.    <code>cd xxx  </code></li><li>创建爬虫            <code>scrapy genspider 名称 抓取域</code></li><li>编写<code>item.py</code> 文件, 定义好数据item</li><li>修改spider中的parse方法. 对返回的响应response对象进行解析. 返回item</li><li>在pipeline中对数据进行保存工作. </li><li>修改<code>settings.py</code>文件, 将pipeline设置为生效, 并设置好优先级</li><li>启动爬虫   <code>scrapy crawl 名称</code></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="爬虫开发" scheme="http://blog.ioimp.top/categories/%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Scrapy爬虫" scheme="http://blog.ioimp.top/tags/Scrapy%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>搭建github博客教程</title>
    <link href="http://blog.ioimp.top/2023/12/03/%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/"/>
    <id>http://blog.ioimp.top/2023/12/03/%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/</id>
    <published>2023-12-03T03:47:04.000Z</published>
    <updated>2023-12-03T03:52:10.585Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="【2023最新版】Hexo-github搭建个人博客并绑定个人域名"><a href="#【2023最新版】Hexo-github搭建个人博客并绑定个人域名" class="headerlink" title="【2023最新版】Hexo+github搭建个人博客并绑定个人域名"></a>【2023最新版】Hexo+github搭建个人博客并绑定个人域名</h1><h2 id="Hexo-github搭建个人博客并绑定个人域名"><a href="#Hexo-github搭建个人博客并绑定个人域名" class="headerlink" title="Hexo+github搭建个人博客并绑定个人域名"></a><a href="https://so.csdn.net/so/search?q=Hexo&spm=1001.2101.3001.7020">Hexo</a>+github搭建个人博客并绑定个人域名</h2><h4 id="安装并配置Node-js"><a href="#安装并配置Node-js" class="headerlink" title="安装并配置Node.js"></a>安装并配置Node.js</h4><p>Node.js下载:【它让JavaScript成为与PHP、Python、Perl、Ruby等服务端语言平起平坐的脚本语言。】</p><p>教程：<a href="https://blog.csdn.net/weixin/_52799373/article/details/123840137%EF%BC%88%E8%BF%87%E7%A8%8B%E8%AF%A6%E7%BB%86%EF%BC%8C%E8%BF%98%E8%A6%86%E7%9B%96win11%EF%BC%8C%E8%AF%84%E8%AE%BA%E4%B8%8B%E9%9D%A2%E8%BF%98%E6%9C%89%E5%B8%88%E5%8F%94%E7%9A%84%E8%B6%B3%E8%BF%B9%EF%BC%89">https://blog.csdn.net/weixin\_52799373/article/details/123840137（过程详细，还覆盖win11，评论下面还有师叔的足迹）</a></p><p>注意一</p><p>全局安装最常用的 express 模块 进行测试命令如下:</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">npm</span> install express -g</span><br></pre></td></tr></table></figure><p>报错图片：</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/566631a93202e6841e3b9728d4181c78.png"></p><p>解决方法：</p><ul><li><p>【亲测有效】</p></li><li><p>需要删除 npmrc 文件。</p></li><li><p>**强调：**不是nodejs安装目录npm模块下的那个npmrc文件</p></li><li><p>而是在 C:\Users\（你的用户名）\下的.npmrc文件</p></li><li><p><em><strong>聪明的你，一定想到了直接用evering搜索，省的还要调用文件管理器在一点一点的找</strong></em></p></li></ul><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/c55ce90256466fb4321c7ceec2174333.png"></p><p>注意二</p><p><strong>在文章第四歩测试上查看安装结果</strong></p><p>可能会出现下面照片结果，更改了目录为什么还是C盘目录下，这时候只需要以管理员身份运行命令即可。</p><p>在下面路径下找到cmd.exe并且管理员身份运行即可。</p><p>推测：出像这种现象的原因就是执行权限不够，推荐大家在桌面建立一个快捷方式（管理员命令的）cmd</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">C:</span>\Windows\System32\cmd.exe</span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/910c8ab64ab09363b6746b621bc8055a.png"></p><p>创建管理员权限的cmd桌面快捷方式</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/a24b65ce36754df5b84ebd74dcae3937.png"></p><h4 id="安装并配置Git"><a href="#安装并配置Git" class="headerlink" title="安装并配置Git"></a>安装并配置Git</h4><p>git是一个并源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理</p><p>Windows系统Git安装教程：<a href="https://www.cnblogs.com/xueweisuoyong/p/11914045.html">https://www.cnblogs.com/xueweisuoyong/p/11914045.html</a></p><h4 id="生成SSH-Keys"><a href="#生成SSH-Keys" class="headerlink" title="生成SSH Keys"></a>生成SSH Keys</h4><p>生成ssh</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;你的邮箱地址&quot;</span></span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/ffb1c86562ad1f7c9e38918c6a71ac24.png"></p><p>找到秘钥位置并复制</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/40764e8f2ea3b220e1492173880c71b4.png"></p><p>测试ssh是否绑定成功</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git<span class="meta">@github</span>.<span class="property">com</span></span><br></pre></td></tr></table></figure><p>如果问你（yes or no）,直接 yes 就可以得到下面这段话</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/0b809bb5e4c84157c139e010e1bc7917.png"></p><h4 id="本地访问博客"><a href="#本地访问博客" class="headerlink" title="本地访问博客"></a>本地访问博客</h4><p>1、创建一个名为 Blog 的文件，在里面启用 Git Bash Here</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/124885ee5a5be2c2605f30b880329825.png"></p><p>2、初始化hexo</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo <span class="keyword">init</span></span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/93962986201290891b09b0266420f301.png"></p><p>3、生成本地的hexo页面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/7c03fe7e8d60be5cf82963e8103f9f6b.png"></p><p>4、访问</p><p>打开本地服务区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:4000/</span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/975e56860c24c8076fb91ad2ec24e4f2.png"></p><blockquote><p>长按 Ctrl + c 关闭服务器</p></blockquote><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/745143e1d8f6411d54566506d555c313.png"></p><h4 id="上传到Github"><a href="#上传到Github" class="headerlink" title="上传到Github"></a>上传到Github</h4><p>修改-config.yml文件</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/5dad89898d2144898261ea18aefaa30f.png"></p><p>把图片上位置更换成</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">deploy</span>:  <span class="class"><span class="keyword">type</span>: git  repository: 你的github地址  branch: main</span></span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/85937e8781a64d4a893c4981e00e6a26.png"></p><p>安装hexo-deployer-git 自动部署发布工具</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo<span class="operator">-</span>deployer<span class="operator">-</span>git <span class="comment">--save</span></span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/681b76b969aa195e15d44c8bfc71565c.png"></p><p>生成页面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/412c15c15d8987484a32f9546e4f9095.png"></p><p>注意一</p><p>如果报错如下：（无报错，请忽略此条）</p><p>报错信息是提示hexo的yml配置文件 冒号后面少了空格解决方案：到提示行将对应的空格补上即可</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/5f5f79045917c6d093df24b22e641516.png"></p><p>本地文件上传到Github上面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>中间会出现一个登录界面，可以用令牌登录。（令牌及时保存，就看不到了）</p><p>结束以后就上传 Github 就成功了！！！</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/15bc2a357a6eac25ec4719dcec9c5007.png"></p><p>注意二</p><p>如果出现如图错误网络报错，再次尝试，多次尝试，直到更换WiFi~~~~</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/5a2a4dabd744ba6a750102dfc623993e.png"></p><h4 id="访问GitHub博客"><a href="#访问GitHub博客" class="headerlink" title="访问GitHub博客"></a>访问GitHub博客</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/aa9870ef4369263b6560c13aa5d753c9.png"></p><p>访问博客，开始的页面是初始化页面，没有做美化和增加内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://wushishu.github.io/</span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/c05cd48fac0243ff9963413b078d2fcc.png"></p><h3 id="第二部分-文档学习"><a href="#第二部分-文档学习" class="headerlink" title="第二部分 文档学习"></a>第二部分 文档学习</h3><h4 id="撰写博客"><a href="#撰写博客" class="headerlink" title="撰写博客"></a>撰写博客</h4><p><em><strong>电脑要必须有Typora！电脑要必须有Typora！电脑要必须有Typora！</strong></em>（重要的事情说三遍）</p><p>文本教程：<a href="https://dhndzwxj.vercel.app/3276806131.html">https://dhndzwxj.vercel.app/3276806131.html</a></p><p>hexo标签教程：<a href="http://haiyong.site/post/cda958f2.html%EF%BC%88%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3%E7%9C%8B%E9%9C%80%E6%B1%82%E5%8A%A0%E4%B8%8D%E5%8A%A0%EF%BC%89">http://haiyong.site/post/cda958f2.html（参考文档看需求加不加）</a></p><p>我们打开自己的博客根目录，跟着我一个个了解里面的这些文件（夹）都是干什么的：</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/d12390a33a7bc45be0582ac20092c28b.png"></p><ul><li><p><code>_config.yml</code>：俗称站点配置文件，很多与博客网站的格式、内容相关的设置都需要在里面改。</p></li><li><p><code>node_modules</code>:存储Hexo插件的文件，可以实现各种扩展功能。一般不需要管。</p></li><li><p><code>package.json</code>：别问我，我也不知道干嘛的。</p></li><li><p><code>scaffolds</code>：模板文件夹，里面的<code>post.md</code>文件可以设置每一篇博客的模板。具体用起来就知道能干嘛了。</p></li><li><p><code>source</code>：非常重要。所有的个人文件都在里面！</p></li><li><p><code>themes</code>：主题文件夹，可以从<a href="https://hexo.io/themes/" title="Hexo主题官网">Hexo主题官网</a>或者网上大神的Github主页下载各种各样美观的主题，让自己的网站变得逼格高端的关键！</p></li></ul><p>接下来重点介绍<code>source</code>文件夹。新建的博客中，<code>source</code>文件夹下默认只有一个子文件夹——<code>_posts</code>。我们写的博客都放在这个子文件夹里面。我们还可以在<code>source</code>里面新建各种子文件夹满足自己的个性化需求，对初学者而言，我们先把精力放在主线任务上，然后再来搞这些细节。</p><blockquote><p>hexo官方文档：<a href="https://hexo.io/zh-cn/docs/commands.html">https://hexo.io/zh-cn/docs/commands.html</a></p></blockquote><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/8389594494d846358792082d4096fce7.png"></p><p>写好内容后，在命令行一键三连：</p><blockquote><p>‘hexo cl’命令用于清除缓存文件（db.json）和已生成的静态文件（public）。</p><p>例如：在更换主题后，如果发现站点更改不生效，可以运行该命令。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo cl</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>然后随便打开一个浏览器，在网址栏输入<code>localhost:4000/</code>，就能发现自己的网站更新了！不过这只是在本地进行了更新，要想部署到网上（Github上），输入如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>然后在浏览器地址栏输入<code>https://yourname.github.io</code>，或者<code>yourname.github.io</code>就能在网上浏览自己的博客了！</p><p>以上，我们的博客网站1.0版本就搭建完成了，如果没有更多的需求，做到这里基本上就可以了。如果有更多的要求，还需要进一步的精耕细作！</p><h4 id="精耕细作"><a href="#精耕细作" class="headerlink" title="精耕细作"></a>精耕细作</h4><p>**海拥\Butterfly 主题美化：**<a href="http://haiyong.site/post/22e1d5da.html">http://haiyong.site/post/22e1d5da.html</a></p><p><strong>Butterfly参考文档（小白慎入，但是他也是你走向DIY必须迈出的一歩）</strong>:<a href="https://butterfly.js.org/posts/dc584b87/#Post-Front-matter">https://butterfly.js.org/posts/dc584b87/#Post-Front-matter</a></p><p>文章中要更改的文件（.yml .bug 等）可以要用viscode打开！！！</p><p>Butterfly 主题安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure><p>这里面如果报错，如下图所示（长路漫漫，bug满满）</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/e28a8a9ed9eb2848f84075e0e0aeba0e.png"></p><p>只需要在命令行中执行</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --<span class="keyword">global</span> --<span class="keyword">unset</span> http.proxy git config --<span class="keyword">global</span> --<span class="keyword">unset</span> https.proxy</span><br></pre></td></tr></table></figure><p>再次安装主题即可成功</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/8e0ff6ac2ae7b9712214f13438a40f27.png"></p><p><strong>应用主题</strong></p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">theme:</span> butterfly</span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/1a1fed2db4bbb066f43e879fb70cf5c5.png"></p><p><strong>安装插件</strong></p><p>如果你没有 pug 以及 stylus 的渲染器，请下载安装：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo<span class="operator">-</span>renderer<span class="operator">-</span>pug hexo<span class="operator">-</span>renderer<span class="operator">-</span>stylus <span class="comment">--save</span></span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/cee71aa9a5c2766541aac4d5aa03c48a.png"></p><h4 id="Butterfly-主题美化"><a href="#Butterfly-主题美化" class="headerlink" title="Butterfly 主题美化"></a>Butterfly 主题美化</h4><p>生成文章唯一链接</p><p>Hexo的默认文章链接格式是年，月，日，标题这种格式来生成的。如果你的标题是中文的话，那你的URL链接就会包含中文，</p><p>复制后的URL路径就是把中文变成了一大堆字符串编码，如果你在其他地方用这边文章的url链接，偶然你又修改了改文章的标题，那这个URL链接就会失效。为了给每一篇文章来上一个属于自己的链接，写下此教程，利用 hexo-abbrlink 插件，A Hexo plugin to generate static post link based on post titles ,来解决这个问题。 参考github官方： hexo-abbrlink 按照此教程配置完之后如下：</p><p>1、安装插件，在博客根目录 [Blogroot] 下打开终端，运行以下指令：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo<span class="operator">-</span>abbrlink <span class="comment">--save</span></span><br></pre></td></tr></table></figure><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/6af8bde01cd64d3a7e38d3e4c2fd9816.png"></p><p>2、插件安装成功后，在根目录 [Blogroot] 的配置文件 _config.yml 找到 permalink：</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/img_convert/34cc88e45553f0dad679ca75f96168c2.png"></p><h4 id="发布博客"><a href="#发布博客" class="headerlink" title="发布博客"></a>发布博客</h4><p>这次了解我上面只有一个HelloWord的时候，为什么不让右键新建，<strong>因为需要命令生成啊，铁汁！</strong></p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">npm</span> <span class="selector-tag">i</span> <span class="selector-tag">hexo-deployer-git</span></span><br></pre></td></tr></table></figure><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> post <span class="string">&quot;新建博客文章名&quot;</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo cl &amp;&amp; hexo g  &amp;&amp; hexo s</span><br></pre></td></tr></table></figure><h4 id="hexo更换背景图片"><a href="#hexo更换背景图片" class="headerlink" title="hexo更换背景图片"></a>hexo更换背景图片</h4><p>背景图片参考网址：</p><ul><li><p><a href="https://wallhaven.cc/">https://wallhaven.cc/</a></p></li><li><p><a href="https://wall.alphacoders.com/">https://wall.alphacoders.com/</a></p></li><li><p><a href="https://bz.zzzmh.cn/index">https://bz.zzzmh.cn/index</a></p></li></ul><p><em>本方法解决的是多次同步到GitHub上背景图片未成功的情况</em></p><p>直接更改原文件</p><p>图片所在目录：<code>hexo/themes/landscape/source/css/images/</code></p><p>图片名称：<code>banner.jpg</code></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="第三部分-绑定自己的域名"><a href="#第三部分-绑定自己的域名" class="headerlink" title="第三部分 绑定自己的域名"></a>第三部分 绑定自己的域名</h3><p>博客地址：<a href="https://www.likecs.com/show-30474.html">https://www.likecs.com/show-30474.html</a></p><p><strong>绑定之后你就有有一个自己专属的博客了。</strong></p><p>买一个域名，可以一块钱白嫖，但是续费贵的飞天！！！</p><p><em><strong>注意请谨慎绑定，想我就会出现提交一次 (hexo d) ,需要重新绑定域名</strong></em></p><blockquote><p>声明：如果遇到什么不懂的可以先百度，在不懂可以微信我wushibo0820</p></blockquote><h2 id="问题：解决-103-x69-x74-x40-103-105-116-104-x75-x62-46-x63-111-109-Permission-denied-publickey-fatal-Could-not-read-from-remote-repository-Pleas"><a href="#问题：解决-103-x69-x74-x40-103-105-116-104-x75-x62-46-x63-111-109-Permission-denied-publickey-fatal-Could-not-read-from-remote-repository-Pleas" class="headerlink" title="问题：解决&#103;&#x69;&#x74;&#x40;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#x63;&#111;&#109;: Permission denied (publickey). fatal: Could not read from remote repository. Pleas"></a>问题：解决<a href="mailto:&#103;&#x69;&#x74;&#x40;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#x63;&#111;&#109;">&#103;&#x69;&#x74;&#x40;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#x63;&#111;&#109;</a>: Permission denied (publickey). fatal: Could not read from remote repository. Pleas</h2><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603101902230.png"></p><h4 id="一-原因分析"><a href="#一-原因分析" class="headerlink" title="一:原因分析"></a>一:原因分析</h4><p>Permission denied (publickey) 没有权限的publickey ，出现这错误一般是以下两种原因</p><ul><li>客户端与服务端未生成 ssh key</li><li>客户端与服务端的ssh key不匹配</li></ul><p>找到问题的原因了，解决办法也就有了，重新生成一次ssh key ，服务端也重新配置一次即可。</p><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><h4 id="二-客户端生成ssh-key"><a href="#二-客户端生成ssh-key" class="headerlink" title="二:客户端生成ssh key"></a>二:客户端生成ssh key</h4><p>在cmd里面输入</p><p>ssh-keygen -t rsa -C “<a href="mailto:&#x78;&#x78;&#120;&#x78;&#120;&#120;&#120;&#x78;&#64;&#113;&#x71;&#46;&#99;&#111;&#x6d;">&#x78;&#x78;&#120;&#x78;&#120;&#120;&#120;&#x78;&#64;&#113;&#x71;&#46;&#99;&#111;&#x6d;</a>“</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;youremail@example.com&quot;</span></span><br></pre></td></tr></table></figure><p>xxxxxx<a href="mailto:youremail@example.com">@qq.com</a>改为自己的邮箱即可，途中会让你输入密码啥的，不需要管，一路回车即可，会生成你的ssh key。（如果重新生成的话会覆盖之前的ssh key。）</p><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/202006031025357.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="三-输入箭头处路径"><a href="#三-输入箭头处路径" class="headerlink" title="三:输入箭头处路径"></a>三:输入箭头处路径</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603102554725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="四-打开id-rsa-pub文件-并且复制内容"><a href="#四-打开id-rsa-pub文件-并且复制内容" class="headerlink" title="四:打开id_rsa.pub文件,并且复制内容"></a>四:打开id_rsa.pub文件,并且复制内容</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603102735768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="配置服务端"><a href="#配置服务端" class="headerlink" title="配置服务端"></a>配置服务端</h4><h4 id="五-在github上打开箭头处-点击Setting"><a href="#五-在github上打开箭头处-点击Setting" class="headerlink" title="五:在github上打开箭头处,点击Setting"></a>五:在github上打开箭头处,点击Setting</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603102157756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="六-点击SSH-and-GPG-keys"><a href="#六-点击SSH-and-GPG-keys" class="headerlink" title="六:点击SSH and GPG keys"></a>六:点击SSH and GPG keys</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603102223280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="七-打开你刚刚生成的id-rsa-pub，将里面的内容复制，进入你的github账号，在settings下，SSH-and-GPG-keys下new-SSH-key，然后将id-rsa-pub里的内容复制到Key中，完成后Add-SSH-Key。"><a href="#七-打开你刚刚生成的id-rsa-pub，将里面的内容复制，进入你的github账号，在settings下，SSH-and-GPG-keys下new-SSH-key，然后将id-rsa-pub里的内容复制到Key中，完成后Add-SSH-Key。" class="headerlink" title="七:打开你刚刚生成的id_rsa.pub，将里面的内容复制，进入你的github账号，在settings下，SSH and GPG keys下new SSH key，然后将id_rsa.pub里的内容复制到Key中，完成后Add SSH Key。"></a>七:打开你刚刚生成的id_rsa.pub，将里面的内容复制，进入你的github账号，在settings下，SSH and GPG keys下new SSH key，然后将id_rsa.pub里的内容复制到Key中，完成后Add SSH Key。</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/2020060310174263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="八-然后添加后入下图所示"><a href="#八-然后添加后入下图所示" class="headerlink" title="八:然后添加后入下图所示"></a>八:然后添加后入下图所示</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603101823216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p><h4 id="九-用idea再次提交文件到-github上-显示提交成功"><a href="#九-用idea再次提交文件到-github上-显示提交成功" class="headerlink" title="九:用idea再次提交文件到 github上,显示提交成功"></a>九:用idea再次提交文件到 github上,显示提交成功</h4><p><img src="https://proxy.iximp.top/https://img-blog.csdnimg.cn/20200603103159683.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dfMzE3,size_16,color_FFFFFF,t_70"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="杂类学习" scheme="http://blog.ioimp.top/categories/%E6%9D%82%E7%B1%BB%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="博客搭建教程" scheme="http://blog.ioimp.top/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
</feed>
